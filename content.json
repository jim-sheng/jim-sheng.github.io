[{"title":"Lapis-数据库连接和查询","date":"2018-10-26T05:31:53.000Z","path":"/blog/2018/10/26/lapis-database-access-and-query/","text":"【原文】 http://leafo.net/lapis/reference/database.html Lapis 有一系列的 class 和 function 用于 PostgreSQL 和 MySQL 的操作。未来将会支持更多的数据库。与此同时，你也可以使用 OpenResty 的数据库驱动，而不使用 Lapis 的查询 API。 这里的每一个查询都是基于 OpenResty cosocket API 实现的异步查询。yield 和 resume 这些操作都是自动处理的；同时如果是异步环境，查询也可以顺序写入。另外会创建连接池以获得更好的性能。 具体细节看你使用的是什么数据库，以及使用的是哪个三方库： pgmoon 是 PostgreSQL 的驱动。它的优势是除了命令行使用 LuaSocket 的同步 API，其它的都使用 OpenResty cosocket API。 在服务器的上下文中，lua-resty-mysql 是 MySQL 的驱动。当在命令行中是 LuaSQL。 建立连接你先需要创建你的数据库的配置 PostgreSQL如果你使用的是 PostgreSQL ，你需要在 config.lua 中创建一个 postgres 块。 12345678910-- config.lualocal config = require(\"lapis.config\")config(\"development\", &#123; postgres = &#123; host = \"127.0.0.1\", user = \"pg_user\", password = \"the_password\", database = \"my_database\" &#125;&#125;) host 默认值是 127.0.0.1， user 默认值是 postgres，所以你看你的配置都默认值没有区别的话可以直接去掉。如果没有使用默认的端口号，你可以直接跟在 host 的后面，语法如下：my_host:1234 （否则 5432， 这是 PostgreSQL 的默认值）。 MySQL如果你使用的是 MySQL ，和上面是类似的；你需呀定义一个 mysql 块： 12345678910-- config.lualocal config = require(\"lapis.config\")config(\"development\", &#123; mysql = &#123; host = \"127.0.0.1\", user = \"mysql_user\", password = \"the_password\", database = \"my_database\" &#125;&#125;) 现在你可以开始查询操作了。 创建一个查询这是两种查询的方式： 使用原生的 SQL 查询，也就是我们常说的裸写 SQL。 Model 类里面封装了常见的查询，可以直接使用。 优先选择使用 Model 里面的方法。当然有些复杂的操作还是选择使用原生的 SQL 查询更加的方便。 以下是一个裸写 SQL 的事例： 1234567891011local lapis = require(\"lapis\")local db = require(\"lapis.db\")local app = lapis.Application()app:match(\"/\", function() local res = db.query(\"select * from my_table where id = ?\", 10) return \"ok!\"end)return app 下面是使用 Model 实现同样的功能： 12345678910111213local lapis = require(\"lapis\")local Model = require(\"lapis.db.model\").Modellocal app = lapis.Application()local MyTable = Model:extend(\"my_table\")app:match(\"/\", function() local row = MyTable:find(10) return \"ok!\"end)return app 默认情况下，所有的查询都会被记录日志。你可以直接通过日志查看具体的操作。 查询接口1local db = require(\"lapis.db\") 这个 db 模块提供了如下的方法： query(query, params...)执行原生的查询。如果查询成功会返回一个结果集，如果失败会返回一个 nil。 第一个参数就是要被执行的 SQL 语句。如果 SQL 语句中包含 ? 会使用后面的参数的值依次替换。后面的参数在赋值 SQL 语句之前会进行 escape_literal 转换操作，避免 SQL 注入的问题。 12345local resres = db.query(\"SELECT * FROM hello\")res = db.query(\"UPDATE things SET color = ?\", \"blue\")res = db.query(\"INSERT INTO cats (age, name, alive) VALUES (?, ?, ?)\", 25, \"dogman\", true) 123SELECT * FROM helloUPDATE things SET color = 'blue'INSERT INTO cats (age, name, alive) VALUES (25, 'dogman', TRUE) 如果查询失败会向上抛出一个 Lua 错误。错误信息包含查询的错误信息。 select(query, params...)几乎和 query 的功能一样除了在查询语句前面的 &quot;SELECT&quot;。 1local res = db.select(\"* from hello where active = ?\", db.FALSE) 1SELECT * from hello where active = FALSE insert(table, values, returning...)向表里插入一行数据， values 就是列名和值。 1234db.insert(\"my_table\", &#123; age = 10, name = \"Hello World\"&#125;) 1INSERT INTO \"my_table\" (\"age\", \"name\") VALUES (10, 'Hello World') 当然也可以指定插入行的数据的某一列作为返回值： 123local res = db.insert(\"some_other_table\", &#123; name = \"Hello World\"&#125;, \"id\") 1INSERT INTO \"some_other_table\" (\"name\") VALUES ('Hello World') RETURNING \"id\" 注意：RETURNING 这个是 PostgreSQL 的特性，MySQL 没有。 update(table, values, conditions, params...)更新表中满足 conditions 条件的所有的值。 123456db.update(\"the_table\", &#123; name = \"Dogbert 2.0\", active = true&#125;, &#123; id = 100&#125;) 1UPDATE \"the_table\" SET \"name\" = 'Dogbert 2.0', \"active\" = TRUE WHERE \"id\" = 100 conditions 也可以是字符串，params 将要替换掉其中需要替换的值： 123db.update(\"the_table\", &#123; count = db.raw(\"count + 1\")&#125;, \"count &lt; ?\", 10) 1UPDATE \"the_table\" SET \"count\" = count + 1 WHERE count &lt; 10 当 conditions 是一个 table 的时候，所有的其它的参数会被用于 &quot;RETURNING&quot;： 12345db.update(\"cats\", &#123; count = db.raw(\"count + 1\")&#125;, &#123; id = 1200&#125;, \"count\") 1UPDATE \"cats\" SET \"count\" = count + 1, WHERE \"id\" = 1200 RETURNING count 注意：RETURNING 这个是 PostgreSQL 的特性，MySQL 没有。 delete(table, conditions, params...)删除表中的符合 conditions 条件的数据。 1db.delete(\"cats\", &#123; name = \"Roo\" &#125;) 1DELETE FROM \"cats\" WHERE \"name\" = 'Roo' conditions 也可以是一个字符串 1db.delete(\"cats\", \"name = ?\", \"Gato\") 1DELETE FROM \"cats\" WHERE name = 'Gato' raw(str)返回一个原始的数据，不会被转换： 12345db.update(\"the_table\", &#123; count = db.raw(\"count + 1\")&#125;)db.select(\"* from another_table where x = ?\", db.raw(\"now()\")) 12UPDATE \"the_table\" SET \"count\" = count + 1SELECT * from another_table where x = now() list({values...})会按照 SQL 的 list 的语法转换成指定的数据。 这个函数通常在查询时使用。同时里面的数据在传递给 SQL 之前会经过 escape_literal 进行转义操作。 同时我们也可以用在数据库更新的场景下： 12345678local ids = db.list(&#123;3,2,1,5&#125;)local res = db.select(\"* from another table where id in ?\", ids)db.update(\"the_table\", &#123; height = 55&#125;, &#123; id = ids&#125;) 12SELECT * from another table where id in (3, 2, 1, 5)UPDATE \"the_table\" SET \"height\" = 55 WHERE \"ids\" IN (3, 2, 1, 5) array({values...})在 PostgreSQL 中将数据转换成数组进行插入／更新操作的。MySQL 里面没有这个功能。 可以在任意的常规的SQL传值查询操作中。在查询前所有的数据都会被 escape_literal 进行转义操作。 参数会被转换，不是单纯的拷贝。在使用过程中需要注意这一点。 123db.insert(\"some_table\", &#123; tags = db.array(&#123;\"hello\", \"world\"&#125;)&#125;) 1INSERT INTO \"some_table\" (\"tags\") VALUES (ARRAY['hello','world']) escape_literal(value)数据转义功能。任何数据都可以使用进行转义。Number 、 string 、 boolean 都会被相应的转义。 12local escaped = db.escape_literal(value)local res = db.query(\"select * from hello where id = \" .. escaped) escape_literal 不适合表名、列名。具体想对表名操作可以看 escape_identifier。 escape_identifier(str)用于转换一个字符串用于查询中的标识符。标识符通常是列名、表名等。 12local table_name = db.escape_identifier(\"table\")local res = db.query(\"select * from \" .. table_name) escape_identifier 不适合转义值。想对值进行转义可以看 escape_literal。 interpolate_query(query, ...)用于替换查询语句中的 ?，剩下的参数的转义通过 escape_literal。 123local q = \"select * from table\"q = q .. db.interpolate_query(\"where value = ?\", 42)local res = db.query(q) 常量以下是常见的常量： NULL – 代表 SQL 里面的 NULL TRUE – 代表 SQL 里面的 TRUE FALSE – 代表 SQL 里面的 FALSE 123db.update(\"the_table\", &#123; name = db.NULL&#125;) 数据库模式Lapis 在 lapis.db.schema 模块中提供了一系列的创建数据的模式。 创建和drop表create_table(table_name, { table_declarations... })第一个参数是需要创建的表名称，第二个参数一个 table 里面存储着这张表的细节。 12345678910local schema = require(\"lapis.db.schema\")local types = schema.typesschema.create_table(\"users\", &#123; &#123;\"id\", types.serial&#125;, &#123;\"username\", types.varchar&#125;, \"PRIMARY KEY (id)\"&#125;) 注意：在 MySQL 中你可以用 types.id 去设置自增主键 ID。不可以使用 PRIMARY KEY (id)。 上面的例子会被解析成下面的 SQL： 12345 CREATE TABLE IF NOT EXISTS \"users\" ( \"id\" serial NOT NULL, \"username\" character varying(255) NOT NULL, PRIMARY KEY (id)); 第二个参数可以是字符串，也可以是table。如果是一个 table 的话，会默认以 column / type 的格式进行解析： 1&#123; column_name, column_type &#125; 它们都是普通的字符串。列名会被自动进行转义。列类型会被 toString 处理后进行传输。schema.types 有一系列的类型可选。例如，schema.types.varchar 等同于 character varying(255) NOT NULL。更多例子下面会继续详细阐述。 如果第二次参数是字符串会被直接插入CREATE TABLE 语句中，比如上面的创建主键的例子。 drop_table(table_name)drop 一张表。 1schema.drop_table(\"users\") 1DROP TABLE IF EXISTS \"users\"; 索引create_index(table_name, col1, col2..., [options])create_index 用于常见表的索引。第一个参数是表名，其余的参数就是需要创建索引的列。最后一个参数可选，可以是一个 table 类型。 有两个可选值 unique: BOOL, where: clause_string。 create_index 创建索引之前会去检查这个索引是否存在。如果存在就什么都不做。 下面就是一个创建索引的例子: 1234567local create_index = schema.create_indexcreate_index(\"users\", \"created_at\")create_index(\"users\", \"username\", &#123; unique = true &#125;)create_index(\"posts\", \"category\", \"title\")create_index(\"uploads\", \"name\", &#123; where = \"not deleted\" &#125;) 解析成 SQL 语句就是： 1234CREATE INDEX ON \"users\" (created_at);CREATE UNIQUE INDEX ON \"users\" (username);CREATE INDEX ON \"posts\" (category, title);CREATE INDEX ON \"uploads\" (name) WHERE not deleted; drop_index(table_name, col1, col2...)删除表的索引。跟创建索引几乎类似。 1234local drop_index = schema.drop_indexdrop_index(\"users\", \"created_at\")drop_index(\"posts\", \"title\", \"published\") 解析成 SQL 如下： 12DROP INDEX IF EXISTS \"users_created_at_idx\"DROP INDEX IF EXISTS \"posts_title_published_idx\" 修改表结构add_column(table_name, column_name, column_type)给表添加一个列。 1schema.add_column(\"users\", \"age\", types.integer) 解析成 SQL 就如下： 1ALTER TABLE \"users\" ADD COLUMN \"age\" integer NOT NULL DEFAULT 0 drop_column(table_name, column_name)删除列 1schema.drop_column(\"users\", \"age\") 解析成 SQL 为： 1ALTER TABLE \"users\" DROP COLUMN \"age\" rename_column(table_name, old_name, new_name)列名的重命名操作 1schema.rename_column(\"users\", \"age\", \"lifespan\") 解析成 SQL 为： 1ALTER TABLE \"users\" RENAME COLUMN \"age\" TO \"lifespan\" rename_table(old_name, new_name)表名重命名操作 1schema.rename_table(\"users\", \"members\") 解析成 SQL 为： 1ALTER TABLE \"users\" RENAME TO \"members\" 列类型所有的列类型都存储在 schema.types 中。所有的类型都是特殊的对象，不但可以通过 tostring 转换成一个类型声明的字符串，还可以像自定义函数进行调用。 以下是所有的默认值： 1234567891011121314local types = require(\"lapis.db.schema\").typesprint(types.boolean) --&gt; boolean NOT NULL DEFAULT FALSEprint(types.date) --&gt; date NOT NULLprint(types.double) --&gt; double precision NOT NULL DEFAULT 0print(types.foreign_key) --&gt; integer NOT NULLprint(types.integer) --&gt; integer NOT NULL DEFAULT 0print(types.numeric) --&gt; numeric NOT NULL DEFAULT 0print(types.real) --&gt; real NOT NULL DEFAULT 0print(types.serial) --&gt; serial NOT NULLprint(types.text) --&gt; text NOT NULLprint(types.time) --&gt; timestamp without time zone NOT NULLprint(types.varchar) --&gt; character varying(255) NOT NULLprint(types.enum) --&gt; smallint NOT NULL 你会发现所有的类型的默认都是 NOT NULL，同时数字类型默认 0 布尔类型默认 false。 当类型当作函数一样调用的时候，以下是可选值： default: value – 设置默认值 null: boolean – 定义列是否是 NOT NULL unique: boolean – 定义列是否有唯一索引 primary_key: boolean – 定义列是否是主键 array: bool|number– 仅限 PostgreSQL ，设置一个几维的数组， true 等同于 1 以下是具体的事例： 12345types.integer(&#123; default = 1, null = true &#125;) --&gt; integer DEFAULT 1types.integer(&#123; primary_key = true &#125;) --&gt; integer NOT NULL DEFAULT 0 PRIMARY KEYtypes.text(&#123; null = true &#125;) --&gt; texttypes.varchar(&#123; primary_key = true &#125;) --&gt; character varying(255) NOT NULL PRIMARY KEYtypes.real(&#123; array = true &#125;) --&gt; real[] 注意：MySQL 的类型集和 PostgreSQL 完全不一样，具体请查看 MySQL 类型 数据库 Migration为了迎合业务逻辑的变更，我们需要有一个机制可以同步修改我们的数据库。 我们通常会定义一个函数的 table ，table 的 key 就是 migration 的名称。我们可以随意定义 migration 的名称，当然还是建议用时间戳定义 migration 的名字： 1234567891011local schema = require(\"lapis.db.schema\")return &#123; [1368686109] = function() schema.add_column(\"my_table\", \"hello\", schema.types.integer) end, [1368686843] = function() schema.create_index(\"my_table\", \"hello\") end&#125; 一个 migration 函数表面看就是一个普通的函数。通常它们会调用上面的 schema 函数，但是实际上有些是没有必要的。 当启动 migration 时，只有没有被执行过的会被调用成功。所有已经被执行的 migration 会存储在 migrations 表中，这个表就用于存储哪些已经执行过了的 migration 的名字。同时所有的 migration 会被升序排列依次执行。 启动 MigrationLapis 命令行工具又一个特殊的命令 lapis migrate 可以直接执行 migration。 这个命令将会调用 migrations 模块将上面的数据格式进行数据库操作。 现在我们创建一个仅有一个 migration 的文件: 12345678910111213141516-- migrations.lualocal schema = require(\"lapis.db.schema\")local types = schema.typesreturn &#123; [1] = function() schema.create_table(\"articles\", &#123; &#123; \"id\", types.serial &#125;, &#123; \"title\", types.text &#125;, &#123; \"content\", types.text &#125;, \"PRIMARY KEY (id)\" &#125;) end&#125; 创建完毕之后，可以执行 lapis migrate 确保可以编译为 Lua。这个命令首先会去判断这个表是不是存在，如果不存在，会去创建这个表，如果存在会去执行没有被执行的 migration。 后续会做进一步的展开。 自定义启动 Migration我们可以创建一个 migration 的表，具体的代码如下： 12local migrations = require(\"lapis.db.migrations\")migrations.create_migrations_table() 会被解析成如下的 SQL： 1234CREATE TABLE IF NOT EXISTS \"lapis_migrations\" ( \"name\" character varying(255) NOT NULL, PRIMARY KEY(name)); 然后我们可以自定义启动 migration 了： 12local migrations = require(\"lapis.db.migrations\")migrations.run_migrations(require(\"migrations\")) 数据库辅助功能这些 db 模块里面的辅助功能不能直接在查询接口里使用。 format_date(time)返回一个数据库格式的时间字符串。 time 参数是可选的，默认是 UTC 时间。 12local date = db.format_date()db.query(\"update things set published_at = ?\", date)","tags":[{"name":"lapis","slug":"lapis","permalink":"https://www.shengguocun.com/tags/lapis/"},{"name":"Lua","slug":"Lua","permalink":"https://www.shengguocun.com/tags/Lua/"}]},{"title":"Lapis-Lua版本的配置语法","date":"2018-10-25T06:29:59.000Z","path":"/blog/2018/10/25/lapis-lua-configuration-syntax/","text":"【原文】http://leafo.net/lapis/reference/lua_creating_configurations.html 配置事例Lapis 的配置模块支持递归合并 table。 比如我们可以先定义一个基础配置，然后里面的值可以后期覆盖： 12345678910111213141516171819-- config.moonlocal config = require(\"lapis.config\")config(&#123;\"development\", \"production\"&#125;, &#123; host = \"example.com\", email_enabled = false, postgres = &#123; host = \"localhost\", port = \"5432\", database = \"my_app\" &#125;&#125;)config(\"production\", &#123; email_enabled = true, postgres = &#123; database = \"my_app_prod\" &#125;&#125;) 以下是上面的配置的解析出来的结果（默认值省略）： 1234567891011-- \"development\"&#123; host = \"example.com\", email_enabled = false, postgres = &#123; host = \"localhost\", port = \"5432\", database = \"my_app\", &#125;, _name = \"development\"&#125; 123456789101112-- \"production\"&#123; host = \"example.com\", email_enabled = true, postgres = &#123; host = \"localhost\", port = \"5432\", database = \"my_app_prod\" &#125;, _name = \"production\"&#125; 你可以通过 config 函数自定义配置你的应用配置，最终这些数据都会和配置的数据合并。","tags":[{"name":"lapis","slug":"lapis","permalink":"https://www.shengguocun.com/tags/lapis/"},{"name":"Lua","slug":"Lua","permalink":"https://www.shengguocun.com/tags/Lua/"}]},{"title":"Lapis-配置和环境","date":"2018-10-25T06:08:46.000Z","path":"/blog/2018/10/25/lapis-creating-configuration/","text":"【原文】http://leafo.net/lapis/reference/configuration.html Lapis 可以通过运行不同的环境获取不同的配置。比如在开发环境，你需要连接本地的数据库，关闭缓存以及单线程。线上环境连接线上数据库，开启缓存，开启8个 worker。 通过 Lapis 的命令行工具的第二个参数启动指定的环境： 1$ lapis server [environment] 上面的 environment 默认是 development 。这个名称决定加载不同的配置。当然只有你创建了指定环境名称的配置之后你的相关的环境才会生效。 创建配置当 Lapis 运行时加载的配置依赖 &quot;config&quot; 模块。这个 &quot;config&quot; 模块用于定义你各个环境中的配置。这是一个标准的 Lua/MoonScript 文件。 注意：如果没有找到 config 模块也不会报错，但是只有默认的配置可以使用。 1234567891011local config = require(\"lapis.config\")config(\"development\", &#123; port = 8080&#125;)config(\"production\", &#123; port = 80, num_workers = 4, code_cache = \"on\"&#125;) 我们可以使用 &quot;lapis.config&quot; 下的说明创建我们的配置。它有一套自己的语法。在上面的例子中，我们定义了两套配置，分别设置了它们的端口。 配置是一个普通的 table。但是需要使用特定的语法构建这个配置 table。 当然我们也可以批量设置相同的配置： 123config(&#123;\"development\", \"production\"&#125;, &#123; session_name = \"my_app_session\"&#125;) 访问嵌套 table 的语法 Lua 和 MoonScript 存在一定的差异，后续会继续介绍。 构建配置大多数的配置的 key 都是可以直接使用的，但是也有部分会有限制。哪些能用哪些不能用这取决于服务器。 注意：为了避免后期可能存在的冲突，配置的作用域尽量控制在一个项目内。 名称 描述 默认值 服务器 server 你代码运行的服务器 nginx/cqueues nginx Any port 端口 8080 Any bind_host 服务器接口 0.0.0.0 cqueues secret 用于签名的字符串 please-change-me Any hmac_digest 用于Hash, SHA1/SHA256 SHA1 Any session_name session 名称 lapis_session Any code_cache 缓存，关系性能 off Any num_workers 进程数 1 nginx logging 关闭的话 false 就可以，开启的话配置有点多是个 table 后续介绍 Any max_request_args 控制请求参数的个数。可以参考 get_uri_args 里面的 max_args nil Any measure_performance 性能指标收集 false Any postgres postgres数据库连接配置 后面会介绍 Any mysql mysql数据库配置 后面会介绍 Any 日志配置日志配置的信息存放在全局配置的 logging 下的 table 里。当然如果这个值设置为 false 所有的日志将被禁用。 注意：这个配置仅是控制 Lapis 应用下面的。OpenResty 的日志还是在 nginx 配置文件中。 名称 描述 默认值 服务器 server 记录信息开始的服务器 true queues queries 记录发送数据库的查询 true any requests 记录每个请求的路径以及状态 true Any 对于 OpenResty 而言，所有的日志将会使用 OpenResty 的 print 函数打印出所有的 notice 日志。默认的 notice 日志会存储到 Nginx 的 error 日志位置。 日志的写入标准将采用 Lua 的 print 函数的。 配置和Nginx这些配置的值将会在编译 nginx.conf 文件时塞入配置中。可插入的 Nginx 配置变量不区分大小写。但是通常我们会用大写，因为在配置检查之前还有 Shell 环境检查。 比如，这是一个 Lapis 的 Nginx 配置块： 123events &#123; worker_connections $&#123;&#123;WORKER_CONNECTIONS&#125;&#125;;&#125; 覆盖环境变量你可以覆盖任意的环境变量。当然需要加变量全部大小，同时加上 LAPIS_ 前缀。比如，覆盖上面的 worker_connections 变量： 1$ LAPIS_WORKER_CONNECTIONS=5 lapis server 这些配置变量就可以使用了。但是需要注意的是，这些都是字符串类型，在你使用的位置可能需要做一些类型强制转换。 获取应用中的配置以下是获取配置 table 里数据的事例： 12local config = require(\"lapis.config\").get()print(config.port) -- shows 环境的名称存储在 _name 中，获取方式为： 1print(config._name) -- development, production, etc... 性能分析如果 measure_performance 配置变量设置为 true 的话，Lapis 会对 action 进行计时、计数的行为。 数据会存储在 ngx.ctx.performance 中。以下字段的数据会被收集： view_time – 渲染视图花费的时间 layout_time – 渲染布局花费的时间 db_time – 执行查询话费的时间 db_count – 执行查询的次数 http_time – 执行的 HTTP 请求的时间 http_count – 发送的 HTTP 请求的次数 如果一个请求中没有相应的指标数据的话，这个字段会被设置为 nil。最好是在它们请求结束以确保所有的数据是可用的。after_dispatch 可以确保是在请求进程结束时派上用场。 下面的这个例子中，在请求结束后会打印性能数据到日志中: 12345678910111213141516171819202122local lapis = require(\"lapis\")local after_dispatch = require(\"lapis.nginx.context\").after_dispatchlocal to_json = require(\"lapis.util\").to_jsonlocal config = require(\"lapis.config\")config(\"development\", &#123; measure_performance = true&#125;)local app = lapis.Application()app:before_filter(function(self) after_dispatch(function() print(to_json(ngx.ctx.performance)) end)end)-- ...return app","tags":[{"name":"lapis","slug":"lapis","permalink":"https://www.shengguocun.com/tags/lapis/"},{"name":"Lua","slug":"Lua","permalink":"https://www.shengguocun.com/tags/Lua/"}]},{"title":"Lapis-Request和Action","date":"2018-10-23T08:56:47.000Z","path":"/blog/2018/10/23/Lapis-request-and-action/","text":"【原文】 http://leafo.net/lapis/reference/actions.html 每一个 Lapis 的 Http 请求都会遵循 Nginx 的基础流程。第一步：路由；一个路由必须有一个匹配的 URL 与之对应。从语法角度，你定义一个路由同时你需要绑定一个关联的 Action 。当一个请求匹配到你之前定义的路由的时候，对应的 Action 的方法就会被调用。 所有 Action 被调用时都会传入一个 Request 对象参数。这个 Request 对象主要用于 Action 和 view 的数据传输。另外，Request 对象还充当着 WebServer 返回 Client 结果的接口。 这些 Action 的返回结果通常会被用于渲染输出。字符串的返回结果通常直接交由浏览器直接解析。table 的返回类型通常是会被当作渲染的可选参数。如果返回值不止一个，后期会将它们合并成一个结果集。所以输出结果可以返回字符串加 table。 如果路由文件内没有定义与当前请求匹配的路由，会进入到默认的路由，在后面的 application callback 中会继续介绍。 路由路由定义有它自己的语法规则。下面用一段简单的事例做一下介绍： 123456local lapis = require(\"lapis\")local app = lapis.Application()app:match(\"/\", function(self) end)app:match(\"/hello\", function(self) end)app:match(\"/users/all\", function(self) end) 上面的路由规则是一个精确匹配的路由定义。比如：一个 /hello/world 不会匹配到 /hello 的路由上。 当然你可以指定一个命名参数和 : 跟着这个名称。这个参数会匹配除了 / 之外的任意字符（一般情况下）： 12345app:match(\"/page/:page\", function(self) print(self.params.page)end)app:match(\"/post/:post_id/:post_name\", function(self) end) 注意： 我们可以调用 print 进行 debug 。在 OpenResty 内运行的时候，print 的输出会发送到 Nginx 的 notice 日志。 捕获的路由参数的值会被存储到 Request 对象的 params 字段中。当然每个命名参数至少包含一个字符，否则会匹配失败。 splat 是另外一种匹配模式，它可以匹配所有甚至包含 / 字符。所有通过 splat 规则匹配到的数据会被存储到 Request 对象的名叫 params 的 table 中的 splat 的参数中。它的语法上就是一个 * ： 123456app:match(\"/browse/*\", function(self) print(self.params.splat)end)app:match(\"/user/:name/file/*\", function(self) print(self.params.name, self.params.splat)end) 如果你直接把长文本直接拼在地址后面，将不会匹配成功。当然有其他的办法，你可以在URL参数的最后加上 .zip 后缀以及加上 /files/:filename.zip 的路由规则。 路由可选组件括号可以让路由规则变得可选： 1/projects/:username(/:project) 上面的路由规则可以匹配 /projects/leafo 也可以匹配 /projects/leafo/lapis 。可选项如果没有匹配到数据的话会是一个 nil 值。 当然路由的可选规则还可以嵌套，比如： 1/settings(/:username(/:page))(.:format) 路由参数字符类一个字符类可以像 Lua 语法一样限制一个参数的规则。下面的这路由例子就是为了确保 user_id 是一个数字： 1/user/:user_id[%d]/posts 下面这个路由就是限制是一个 16进制 的参数。 1/color/:hex[a-fA-F%d] 路由优先级首先第一步会把所有的匹配到的路由都匹配进来，然后进行从高到低排序： 精确路由 /hello/world 可变参路由 /hello/:variable 每添加一个可变参数会降低一下路由的优先级 模糊路由 /hello/* 每加一个模糊匹配的规则它的优先级就会升高一级 比如：/hello/*spat 和 /hello/*spat/world/*rest 第二个的优先级要比第一个更高。 以上就是路由的优先级排序：精确路由 &gt; 可变参数路由 &gt; 模糊路由 路由名称路由名称不再是一个硬编码的 URL 结构的一部分，而是可以通过路由的名称可以直观的知道路由对应的 Action 是干嘛的，同时可以方便重定向到其它的路由。 在定义路由的时候的第一个参数就是用于命名路由的： 12345678910local lapis = require(\"lapis\")local app = lapis.Application()app:match(\"index\", \"/\", function(self) return self:url_for(\"user_profile\", &#123; name = \"leaf\" &#125;)end)app:match(\"user_profile\", \"/user/:name\", function(self) return \"Hello \" .. self.params.name .. \", go home: \" .. self:url_for(\"index\")end) 我们可以用 self:url_for() 用于重定向操作。第一个参数为重定向的路由的名称，第二个参数为可选参数可以用于传路由的参数。 注意：后续会继续介绍 url_for 的不同的生成 URL 的用法。 Http的请求方式通常一个 URL 地址可以通过定义不同的 Http 请求方式来定义出不同的 Action 。Lapis 内部的方法 respond_to 可以完成上述的目标。 12345678910111213local lapis = require(\"lapis\")local respond_to = require(\"lapis.application\").respond_tolocal app = lapis.Application()app:match(\"create_account\", \"/create-account\", respond_to(&#123; GET = function(self) return &#123; render = true &#125; end, POST = function(self) do_something(self.params) return &#123; redirect_to = self:url_for(\"index\") &#125; end&#125;)) respond_to 也可以设置一个前置过滤器用于在请求前的一些操作。我们可以定义一个 before 函数。同时这个和前置过滤器有相同的语义，如果你调用了 self:write() 此调用往后的逻辑讲不会继续被执行。 12345678910111213141516171819local lapis = require(\"lapis\")local respond_to = require(\"lapis.application\").respond_tolocal app = lapis.Application()app:match(\"edit_user\", \"/edit-user/:id\", respond_to(&#123; before = function(self) self.user = Users:find(self.params.id) if not self.user then self:write(&#123;\"Not Found\", status = 404&#125;) end end, GET = function(self) return \"Edit account \" .. self.user.name end, POST = function(self) self.user:update(self.params.user) return &#123; redirect_to = self:url_for(\"index\") &#125; end&#125;)) 当然还有一个特殊情况：任意的 POST 请求如果它的 Content-type 头信息被设置为 application/x-www-form-urlencoded ，不管有没有 respond_to ，所有的请求体会被转义同时所有的参数会赋值给 self.params。 在此之前你可以看到过调用 app:get() 和 app:post() 方法的例子。它们都是基于 respond_to 做了一些封装，这样你可以快速的定义一个 Http 请求。比如 ：get 、post 、delete 、put 。 1234567app:get(\"/test\", function(self) return \"I only render for GET requests\"end)app:delete(\"/delete-account\", function(self) -- do something destructiveend) 前置过滤器有时候你需要在执行某个 Action 之前运行一段代码。一个很常见的例子，比如：设置用户的 session 。我们可以定义一个前置过滤器或者一个函数在 Action 之前，比如： 1234567891011local app = lapis.Application()app:before_filter(function(self) if self.session.user then self.current_user = load_user(self.session.user) endend)app:match(\"/\", function(self) return \"current user is: \" .. tostring(self.current_user)end) 这样就相当于调用了 app:before_filter。这样里面的逻辑就会按照既定的顺序执行。 如果在前置过滤器中调用了 self:write() 方法，然后这个 action 的逻辑就会运行至此结束。比如我们可以结束某个 Action 的后续逻辑或者没有满足某个条件是重定向到其他的页面： 1234567891011local app = lapis.Application()app:before_filter(function(self) if not user_meets_requirements() then self:write(&#123;redirect_to = self:url_for(\"login\")&#125;) endend)app:match(\"login\", \"/login\", function(self) -- ...end) 注意： self:write() 是一个常规的 Action 返回结果的过程，所以在 self:write() 中你可以返回你过去在 Action 里面的返沪的数据。 Request 对象每个 Action 的第一个参数就是 Request 对象。也就是上面例子中的 self 。 Request 对象有如下的参数： self.params – 一个 table ，包含所有 GET 、POST 的请求参数 self.req – 原生的 request table （由 ngx 生成） self.res – 原生的 response table (用于更新 ngx) self.app – 应用的实例 self.cookies – cookies 的 table ，可用于设置 Cookies 数据，且值仅支持字符串 self.session – 和 Cookie 对应的，可以存储任何可以被 JSON 编码的类型 self.route_name – 与请求匹配的路由名称 self.options – 控制请求的选项，底层都通过 write self.buffer – 输出的缓冲，不需要通过人为的干涉，底层依然通过 write Request 对象还有其他的方法： write(options, ...) – 告知请求如何渲染结果 url_for(route, params, ...) – 获取一个命名的路由的URL 地址，或者一个对象 build_url(path, params) – build 一个完全限定的 URL 地址 html(fn) – 通过 Html 构造器的语法生成一个字符串 @req这是对 ngx 中的原生的 self.req 进行的一次封装。以下是它的相关的特性。 self.req.headers – Request 的 header 的 table self.req.parsed_url – 请求的 URL 的转义的结果。包含 scheme 、path 、host 、port 和 query 这些属性。 self.req.params_post – 存储所有的 POST 请求的参数 self.req.params_get – 存储所有的 GET 请求的参数 Cookies你可以通过 self.cookies 进行 cookie 的读写操作。当然需要注意的是，当你遍历 cookie 内部的数据的时候需要判断空的情况： 12345app:match(\"/my-cookies\", function(self) for k,v in pairs(self.cookies) do print(k, v) endend) 现有的 cookie 会存储在 metatable 的 __index 中。因为所有的数据都会存储在 self.cookies 中，所以我们可以直接在 action 中就使用。 因此，操作 cookie 的代码就会变得下面这么简洁： 123app:match(\"/sets-cookie\", function(self) self.cookies.foo = \"bar\"end) 通常情况下所有的 cookie 还有其它的属性 Path=/; HttpOnly （这会创建一个 Session Cookie）。你可以通过 cookie_attributes 函数配置你应用里面的 Cookie 设置。下面是一个简单的设置过期时间的例子： 1234567local date = require(\"date\")local app = lapis.Application()app.cookie_attributes = function(self) local expires = date(true):adddays(365):fmt(\"$&#123;http&#125;\") return \"Expires=\" .. expires .. \"; Path=/; HttpOnly\"end 这个 cookie_attributes 方法将 Request 对象作为它的第一个参数，然后下面就是具体的 Cookie 的设置操作。 Sessionself.session 是一个更高级的请求方式。session 的内容会被序列化成 JSON 然后存储到特定的 cookie 中。这些序列化的 cookie 通常是经过签名的，所以通常这些数据不能随意篡改的。 session 的读写方式和 cookie 的方式很像： 12345app.match(\"/\", function(self) if not self.session.current_user then self.session.current_user = \"Adam\" endend) 默认 session 的名称会存储在叫 lapis_session 的 cookie 中。当然可以通过修改配置文件中的 session_name 变量来修改 session 的名称。session 是通过你的应用的密钥进行签名，它存储在你的配置文件变量 secret 中。强烈建议替换掉这个默认值。 1234567-- config.lualocal config = require(\"lapis.config\").configconfig(\"development\", &#123; session_name = \"my_app_session\", secret = \"this is my secret string 123456\"&#125;) Request 对象的方法write(things...)写所有的参数。不同的 action 根据参数的类型进行区分。 string – 字符串附加到输出缓冲区 function(或者可以调用的 table) – 在输出缓冲区被调用，同时结果递归传给 write table – 键值对会分配给 self.options，其它的值会递归传给 write 大多数的情况下，将调用 write 作为 action 的返回值传给 write 这样的方式没有必要。在前置过滤器中，write 有双重作用，不但可以输出内容，还可以取消正在运行的 action。 url_for(name_or_obj, params, query_params=nil, ...)给 name_or_obj 生成一个 URL。 注意：url_for 命名上有点不太恰当，因为通常它会生成一个页面的路径。如果你想得到一个完整的路径，你可以使用 build_for 函数。 如果 name_or_obj 是一个字符串，然后会去查找这个名称的 route ，参数就是二个参数的值。如果没有指定名称的路由，会抛出一个错误。 事例如下： 1234567app:match(\"index\", \"/\", function() -- ...end)app:match(\"user_data\", \"/data/:user_id/:data_field\", function() -- ...end) 具体的 url_for 的使用如下： 12345-- returns: /self:url_for(\"index\")-- returns: /data/123/heightself:url_for(\"user_data\", &#123; user_id = 123, data_field = \"height\"&#125;) 如果第三个参数 query_params 有值。将会转成具体的 URL 参数拼接在地址后面。如果 route 没有任何的参数，第二个参数仍要传一个 nil： 12345-- returns: /data/123/height?sort=ascself:url_for(\"user_data\", &#123; user_id = 123, data_field = \"height\"&#125;, &#123; sort = \"asc\" &#125;)-- returns: /?layout=newself:url_for(\"index\", nil, &#123;layout = \"new\"&#125;) 当然 route 的所有的可选组件只有在被传值之后才会引入进来。如果没有被赋值就会被忽略。 比如，给出的 route 规则如下： 123app:match(\"user_page\", \"/user/:username(/:page)(.:format)\", function(self) -- ...end) 以下是 URL 的生成逻辑： 1234567891011-- returns: /user/leafoself:url_for(\"user_page\", &#123; username = \"leafo\" &#125;)-- returns: /user/leafo/projectsself:url_for(\"user_page\", &#123; username = \"leafo\", page = \"projects\" &#125;)-- returns: /user/leafo.jsonself:url_for(\"user_page\", &#123; username = \"leafo\", format = \"json\" &#125;)-- returns: /user/leafo/code.jsonself:url_for(\"user_page\", &#123; username = \"leafo\", page = \"code\", format = \"json\" &#125;) 如果一个 route 包含一个通用匹配符，在传值的过程中你可以将数据赋值给 splat 参数： 123app:match(\"browse\", \"/browse(/*)\", function(self) -- ...end) 12345-- returns: /browseself:url_for(\"browse\")-- returns: /browse/games/recentself:url_for(\"browse\", &#123; splat = \"games/recent\" &#125;) url_for 的第一个参数为对象如果 name_or_obj 是一个 table，然后在这个 table 中调用了 url_params 方法，最终返回值传递给 url_for。 url_params 方法里面的 request 对象参数以及其它的参数都会传递给 url_for。 我们常见的方式是在 model 中实现 url_params，同时赋予相关的功能。比如：一个 User model 定义了一个 url_params 方法，实现查看用户详情页的功能： 12345local Users = Model:extend(\"users\", &#123; url_params = function(self, req, ...) return \"user_profile\", &#123; id = self.id &#125;, ... end&#125;) 结合上面的 url_for 实例演示一下： 123local user = Users:find(100)self:url_for(user)-- could return: /user-profile/100 你可能注意到传递给 url_params 一个 ... 参数以及返回值里面也有 ...。意思是可以传递 query_params 参数： 123local user = Users:find(1)self:url_for(user, &#123; page = \"likes\" &#125;)-- could return: /user-profile/100?page=likes 使用 url_key 方法如果 params 的参数的值是一个字符串类型，会直接赋值到生成的地址中。如果是一个 table 类型，在 table 中会调用 url_key 方法，然后返回值同样会赋值到生成的地址中。 举个例子，在一个 user model中使用 url_key 方法： 12345local Users = Model:extend(\"users\", &#123; url_key = function(self, route_name) return self.id end&#125;) 如果我们想要生成一个用户详情页的路径，通常会这么写： 12local user = Users:find(1)self:url_for(\"user_profile\", &#123;id = user.id&#125;) 因为上面的 url_key 的例子中 User 对象等同于 id 参数，所以写法上可以变换一下： 12local user = Users:find(1)self:url_for(\"user_profile\", &#123;id = user&#125;) 注意：url_key 方法的第一个参数是路径名称，所以我们可以根据自己的需求修改相应的 route 的句柄。 build_for(path, [options])构建一个绝对地址。 比如，我们的服务运行在 localhost:8080 上面： 1234self:build_url() --&gt; http://localhost:8080self:build_url(\"hello\") --&gt; http://localhost:8080/helloself:build_url(\"world\", &#123; host = \"leafo.net\", port = 2000 &#125;) --&gt; http://leafo.net:2000/world 渲染(render)的可选项当一个 table 被写入时，它们的键值对（仅是字符串类型的key）会被拷贝到 self.options 中。比如，下面的例子中的 render 和 status 属性会被拷贝。这个 table 仅会在 action 生命周期结束的时候使用，用于返回数据。 123app:match(\"/\", function(self) return &#123; render = \"error\", status = 404&#125;end) 以下就是可选值清单： status – 设置一个 Http 状态值 (例如：200、404、500 …) render – 视图的名称，必须是一个字符串或者是一个视图类 content_type – 用于设置 Content-type头信息 headers – 返回数据的 header, table 类型 json – 返回的 json 字符串 layout – 修改应用的默认的 layout redirect_to – 重定向到其它的地址，支持相对路径和绝对路径 当使用 json 渲染的时候，需要确保内容的类型，以及应用的 layout 属性会被禁用： 123app:match(\"/hello\", function(self) return &#123; json = &#123; hello = \"world\" &#125; &#125;end) 应用回调应用回调是一个特殊的方法，在我们的应用中处理某些特定类型的请求的时候可以覆盖相应的方法。这些函数在我们的应用中可以正常的调用，这也意味着这些函数的第一个参数是 request 对象的实例。 默认 action当一个请求不能匹配给定的所有的路由规则时，它会去运行一个默认的 action 。Lapis 会预定义一个 action ，事例如下： 1234567891011121314function app:default_route() -- strip trailing / if self.req.parsed_url.path:match(\"./$\") then local stripped = self.req.parsed_url:match(\"^(.+)/+$\") return &#123; redirect_to = self:build_url(stripped, &#123; status = 301, query = self.req.parsed_url.query, &#125;) &#125; else self.app.handle_404(self) endend 在上面的例子中，以 / 为后缀的请求会被重定向到没有斜杠的位置，其他的请求会调用应用的 handle_404 方法。 default_route 方法也是应用中的一个普通的方法。你可以根据你的实际的业务需求覆盖这个方法。比如，添加日志： 123456function app:default_route() ngx.log(ngx.NOTICE, \"User hit unknown path \" .. self.req.parsed_url.path) -- call the original implementaiton to preserve the functionality it provides return lapis.Application.default_route(self)end 你会注意到除了 default_route 还有另外一个方法 handle_404 也可以进行预定义操作： 123function app:handle_404() error(\"Failed to find route: \" .. self.req.cmd_url)end 上面的代码会触发一个 500 的错误和一个无效请求的堆栈的跟踪记录。如果你想让 404 页面变得更友好一点，你需要按照下面的操作进行重写。 通过覆盖 handle_404 方法进行自定义 404 页面。 下面是一个简单的 404 页面，仅输出 &quot;Not Found!&quot;。 123function app:handle_404() return &#123; status = 404, layout = false, \"Not Found!\" &#125;end 错误处理每个 Lapis 的 action 的执行都会被 xpcall 进行封装。这样可以确保那些致命错误可以输出一些可读性更高的信息，而不是一些 Nginx 的默认的错误信息。 错误处理主要处理那些意想不到的错误，该知识点后面还会进一步展开。 Lapis 的预定义了错误处理相关的操作，比如所有的额错误信息会被渲染到 &quot;lapis.views.error&quot; 中。错误页面包含调用栈以及错误信息。 如果你想自定义错误信息，你可以覆盖 handle_error 方法： 12345678-- config.custom_error_page is made up for this examplefunction app:handle_error(err, trace) if config.custom_error_page then return &#123; render = \"my_custom_error_page\" &#125; else return lapis.Application.handle_error(self, err, trace) endend request 对象或者 self 在系统异常的时候会传递失败。Lapis 提供了一个其他的方式获取 request 对象。 你可以使用 self.original_request 获取原始的 request 对象。 因为在错误页面里面会把全部的调用栈全部打出来，所以在线上环境建议设置自己的自定义错误页面，同时在日志记录相关的异常信息。 lapis-exception 模块增加了错误记录数据库的功能，同时可以发送通知邮件。","tags":[{"name":"lapis","slug":"lapis","permalink":"https://www.shengguocun.com/tags/lapis/"},{"name":"Lua","slug":"Lua","permalink":"https://www.shengguocun.com/tags/Lua/"}]},{"title":"创建一个Lua版本的Lapis项目","date":"2018-10-23T08:51:53.000Z","path":"/blog/2018/10/23/lapis-getting-started-with-lua/","text":"【原文】http://leafo.net/lapis/reference/lua_getting_started.html 生成一个新的项目你可以在当前目录下运行下面的命令创建一个新的 Lua 项目： 1$ lapis new --lua 默认的 nginx.conf 文件会引入 app.lua ，这个基础文件也是通过 lapis new 命令生成的。 app.lua 是整个项目的主入口，你可以引入其他的模块。事例如下： 123456789-- app.lualocal lapis = require(\"lapis\")local app = lapis.Application()app:get(\"/\", function() return \"Welcome to Lapis \" .. require(\"lapis.version\")end)return app 这时候再启动服务器： 1$ lapis server 打开浏览器就可以访问 http://localhost:8080 这个地址了。 如果你想要改变访问的端口，可以创建一个 config.lua 文件。 在这个例子中，比如我想要 development 环境的访问端口改为 9090 ： 123456-- config.lualocal config = require(\"lapis.config\")config(\"development\", &#123; port = 9090&#125;) 注意 ： 后面我们会展开讲解如何配置一套完整的配置文件。 如果没有携带其他的参数 lapis server 正在运行的话，同时 development 环境正在跑着的话，系统会自动重新加载。（前提是 lapis_environment.lua 文件不存在） Lapis 仅使用了少量的内建字段用于配置文件（比如：port）,除此之外的字段你都可以使用。例如： 123456-- config.lualocal config = require(\"lapis.config\")config(\"development\", &#123; greeting = \"Hello world\"&#125;) 你可以通过 get 方法获取当前的配置信息。它会返回一个 Lua 的 table 类型： 1234567891011-- app.lualocal lapis = require(\"lapis\")local config = require(\"lapis.config\").get()local app = lapis.Application()app:get(\"/\", function(self) return config.greeting .. \" from port \" .. config.portend)return app 创建一个 View现在我们可以创建一个基础页面或者复杂的需要渲染的页面。Lapis 支持 etlua ，这是一个 Lua 模板语言，支持 Lua 混合 HTML 使用。 视图通常需要你准备相关的数据给它，然后它会生成 HTML，最终呈现在你面前。 Lapis 的 view 的默认的路径是 views/ ，现在我们可以创建一个最普通的 view 文件 index.etlua 123&lt;!-- views/index.etlua --&gt;&lt;h1&gt;Hello world&lt;/h1&gt;&lt;p&gt;Welcome to my page&lt;/p&gt; 我们发现跟常见的页面文件有些不一样，没有 &lt;html&gt; 、&lt;head&gt; 、&lt;body&gt; 标签。这里我们需要解释一下，view 不简单的负责页面的呈现，同时还负责页面的布局。 下面我们结合逻辑呈现我们的 view ： 1234567891011-- app.lualocal lapis = require(\"lapis\")local app = lapis.Application()app:enable(\"etlua\")app:get(\"/\", function(self) return &#123; render = \"index\" &#125;end)return app etlua 默认是不开启的，如果你需要使用，需要通过方法将其打开。 我们可以在我们的 action 返回值中使用 render 参数去渲染指定的页面。在上面的例子中 &quot;index&quot; 会将自动加载 views/index.etlua 文件。 运行服务器后，在浏览器里输入指定的地址就可以查看刚刚渲染的页面了。 etlua 用法当有以下标签的时候 etlua 会将 Lua 的代码注入进模板： &lt;% lua_code %&gt; 常规的 Lua 代码引入，类似 PHP 里面的 &lt;?php xxxx ?&gt; &lt;%= lua_expression %&gt; 表达式输出结果，但是 HTML 会被转义 &lt;%- lua_expression %&gt; 和上面的功能一样，不过不会转义 HTML 注意 ：后续仍会继续介绍 etlua 下面我们会用一些事例来进一步了解上面的用法： 1234567891011121314151617-- app.lualocal lapis = require(\"lapis\")local app = lapis.Application()app:enable(\"etlua\")app:get(\"/\", function(self) self.my_favorite_things = &#123; \"Cats\", \"Horses\", \"Skateboards\" &#125; return &#123; render = \"list\" &#125;end)return app 1234567&lt;!-- views/list.etlua --&gt;&lt;h1&gt;Here are my favorite things&lt;/h1&gt;&lt;ol&gt; &lt;% for i, thing in pairs(my_favorite_things) do %&gt; &lt;li&gt;&lt;%= thing %&gt;&lt;/li&gt; &lt;% end %&gt;&lt;/ol&gt; 创建一个布局（Layout）在我们的页面当中 Layout 是一个独立的共享模板。你可以 DIY 你想要的效果。 下面我们创建一个 Layout 文件 views/layout.etlua : 123456789101112&lt;!-- views/layout.etlua --&gt;&lt;!DOCTYPE HTML&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;%= page_title or \"My Page\" %&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Greetings&lt;/h1&gt; &lt;% content_for(\"inner\") %&gt;&lt;/body&gt;&lt;/html&gt; content_for 是一个特殊的模板函数，你可以从视图里面向 Layout 发送数据。Lapis 会将渲染的结果塞进一个叫 inner 的 content 变量。 你会发现上面的例子中没有使用 etlua 的标签。因为 content_for 会将结果直接输出到缓冲区。 在视图（view）里面使用的变量和辅助函数在 Layout 里面也可以使用。 下面演示一下如何在 Lapis 应用中使用 Layout: 12345local app = lapis.Application()app:enable(\"etlua\")app.layout = require \"views.layout\"-- the rest of the application... 和 view 的使用上有一点语法上的区别，我们会通过名称引入进来，同时会赋值给一个模板对象。简单的讲 etlua 会将 .etlua 为后缀的文件转换成 Lua 可识别的文件。","tags":[{"name":"lapis","slug":"lapis","permalink":"https://www.shengguocun.com/tags/lapis/"},{"name":"Lua","slug":"Lua","permalink":"https://www.shengguocun.com/tags/Lua/"}]},{"title":"Lapis-快速开始","date":"2018-10-23T08:48:22.000Z","path":"/blog/2018/10/23/lapis-getting-started/","text":"【原文】 http://leafo.net/lapis/reference/getting_started.html Lapis 是一个 Lua/MoonScript 的 Web 框架，本译文主要翻译 Lua 部分；同时 Lapis 是基于章亦春的 OpenResty ，这样你的 web 应用可以直接运行在 Nginx 内部。Nginx 的事件循环可以让你轻松使用异步Http请求、数据库查询和其他 OpenResty 提供的模块。基于 Lua 的协程你可以编写在幕后事件驱动的同步代码。 lapis 除了提供你一个 Web 框架，同时还提供了一个可以在不同配置环境中控制 OpenResty 的工具。即使你不是用这个框架 Web 相关的模块，在基于 OpenResty 做开发过程中它也可以节省你的开发成本。 这个框架包含 URL 路由模块、模板、CSRF 和 Session ，同时支持 PostgreSQL 、MySQL 的 DB 的常规的操作，以及其他 Web 相关的其他功能。 希望本文档在你使用的过程中给你提供参考。 基本设置首先，需要在你的环境中安装 OpenResty ，然后使用 LuaRocks 安装 Lapis (记得 Lua 安装 5.1，这个框架不支持 5.3 版本) 1$ luarocks install lapis 安装完成之后，命令行敲一下 lapis 验证一下是否安装成功，如果有类似下面的输出代表你已经安装成功了 123456789101112131415161718/ # lapisLapis 1.7.0usage: lapis &lt;action&gt; [arguments]using nginx: /usr/local/openresty/nginx/sbin/nginxdefault environment: developmentAvailable actions: new create a new lapis project in the current directory server [environment] build config and start server build [environment] build config, send HUP if server running term sends TERM signal to shut down a running server exec &lt;lua-string&gt; execute Lua on the server migrate [environment] run migrations generate &lt;template&gt; [args...] generates a new file from template help show this text 通过 Lapis 创建一个 Lua 应用lapis 命令行工具Lapis 提供了一个命令行工具，可以创建新项目，也可以启动服务器。要是想看它都提供了哪些功能，你可以在命令敲下以下命令： 1$ lapis help 现在进入一个新创建的目录中，创建一个新的项目： 12345/srv/www # lapis new --luawrote nginx.confwrote mime.typeswrote app.luawrote models.lua 这时候 Lapis 会创建一个基础版本的 Nginx 配置文件和一个空的 Lapis 应用。 下面我们先来查看一下生成的配置文件（ nginx.conf 是唯一的核心文件）。以下会简单概述一下这个配置文件都做了什么： 所有的 /static/ 开头的请求都会到 static 目录里查找指定的内容 /favicon.ico 会从 static/favicon.ico 位置读取 其他的请求都会在落在你的 Lua 代码逻辑中 当你通过命令行工具启动指定的环境，nginx.conf 里面的变量会从指定的环境的配置文件里面查询指定的值。下面我们我们会进一步讨论里面的细节。 Nginx 配置文件让我们看下刚刚新建项目时创建的配置文件，这对于我们不管是做一个简单的发布操作还是后期开发更复杂的应用都是很有必要的。 下面是刚刚生成的 nginx.conf : 1234567891011121314151617181920212223242526272829303132worker_processes $&#123;&#123;NUM_WORKERS&#125;&#125;;error_log stderr notice;daemon off;pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; server &#123; listen $&#123;&#123;PORT&#125;&#125;; lua_code_cache $&#123;&#123;CODE_CACHE&#125;&#125;; location / &#123; default_type text/html; content_by_lua ' require(\"lapis\").serve(\"app\") '; &#125; location /static/ &#123; alias static/; &#125; location /favicon.ico &#123; alias static/favicon.ico; &#125; &#125;&#125; 需要注意的是，这和我们的常规的 Nginx 配置文件存在一定的差异。比如 $ 这样的语法，在启动服务器之前会使用 Lapis 应用里面的指定环境的配置文件中的值进行填充。 当然也有一些有趣的配置。 error_log stderr notice 和 daemon off 让服务运行在前台，以及可以在控制台打印出日志。这对于开发的过程中是非常友好的，不过在线上还是要关闭它们的。 lua_code_cache 在开发环境中尽量关闭这个开关，将其设置为 off 这在调试的过程中可以避免很多懵逼现象。当然线上对性能要求比较高的话，还是建议打开这个开关的，只要将其设置为 on 。不过该变量的默认值是 off. content_by_lua 里面的 Lua 代码逻辑处理不匹配其他 location 的剩余的请求。它会加载 Lapis 同时告诉服务器模块名称叫 app 。同时在执行 lapis new 命令之前会提供一个精简版的 app 模块。 启动服务Lapis 将 build 配置和启动服务器集成一个很简单的命令。 只需要在命令行之行 lapis server 。 Lapis 就会去查找你的 OpenResty 的安装目录，最后去查找 nginx 的二进制文件。（最后一个代表你的系统变量 PATH ） 1234\"/usr/local/openresty/nginx/sbin/\"\"/usr/local/opt/openresty/bin/\"\"/usr/sbin/\"\"\" 提醒 ：记得安装 OpenResty，而不是一个普通的 Nginx ， Lapis 会忽略掉普通的 Nginx 。 下面我们介绍一下如何启动服务器，只需要简单的一个命令： 1$ lapis server 那些默认的配置文件会在前台引入到服务器中，只需要 CTRL + C 就可以停止服务器。 如果服务器运行在后台可以使用 lapis term 停止服务器。当然这个命令必须运行在应用的根目录下。这个命令会去查找 PID 文件，如果这个进程存在的话，会向它发送一个 TERM 指令。","tags":[{"name":"Lua","slug":"Lua","permalink":"https://www.shengguocun.com/tags/Lua/"},{"name":"Lapis","slug":"Lapis","permalink":"https://www.shengguocun.com/tags/Lapis/"}]},{"title":"手把手教你创建OpenResty Docker镜像","date":"2018-10-10T02:59:10.000Z","path":"/blog/2018/10/10/create-openresty-docker-image/","text":"0、前言 什么是 Docker 镜像 ？ Docker 就像往集装箱里装货物的码头工人那样，它把应用打包成具有某种标准规格的集装箱，用计算机领域的语言来说，这种按照一定规格封装的集装箱叫 「镜像」 。 Docker 镜像又有什么优势呢 ？ 统一的管理服务、持续交付、弹性计算 等等… 如何创建一个镜像呢 ？ 下文会带你一起了解如何创建一个 Docker 镜像 1、准备工作 你需要申请一个 Docker hub 账号，了解相关的基本操作 创建一个你自己的 dockerfile 文件夹 一个 OpenResty 的 tar 包， openresty-1.11.2.1.tar.gz 2、步骤 为了避免机器的权限问题，本次演示的所有操作都在 root 下进行 2.1、创建glibc镜像 目的： 修改时区信息的修改 创建Dockerfile的文件夹 alpine_glibc_2.23 ，我暂且先起这个名字，为什么这么起后面我会介绍。 为了避免网络问题，我先把几个必要的 apk 包直接放到本地。 12345[root@freeipa101 alpine_glibc_2.23]# lltotal 11768-rw-r--r-- 1 root root 2943700 Oct 4 15:58 glibc-2.23-r3.apk-rw-r--r-- 1 root root 1751110 Oct 4 15:58 glibc-bin-2.23-r3.apk-rw-r--r-- 1 root root 7326212 Oct 4 15:58 glibc-i18n-2.23-r3.apk 然后创建一个 Dockerfile 文件 1vim Dockerfile 123456FROM alpine:latestMAINTAINER shengguocun&lt;hzshengguocun@corp.netease.com&gt;ENV LANG=C.UTF-8RUN apk update &amp;&amp; apk add tzdata &amp;&amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo \"Asia/Shanghai\" &gt; /etc/timezoneCOPY glibc-*.apk /tmp/RUN apk upgrade --update &amp;&amp; apk add --allow-untrusted /tmp/*.apk &amp;&amp; rm -f /tmp/*.apk /var/cache/apk/* 保存退出，进行 build 操作 123456789101112131415161718192021222324252627282930313233343536[root@freeipa101 alpine_glibc_2.23]# docker build .Sending build context to Docker daemon 12.03MBStep 1/6 : FROM alpine:latest ---&gt; 196d12cf6ab1Step 2/6 : MAINTAINER shengguocun&lt;hzshengguocun@corp.netease.com&gt; ---&gt; Using cache ---&gt; 87a5241dd00bStep 3/6 : ENV LANG=C.UTF-8 ---&gt; Using cache ---&gt; 5529e89cde7eStep 4/6 : RUN apk update &amp;&amp; apk add tzdata &amp;&amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo \"Asia/Shanghai\" &gt; /etc/timezone ---&gt; Running in 069c8e8cd948fetch http://dl-cdn.alpinelinux.org/alpine/v3.8/main/x86_64/APKINDEX.tar.gzfetch http://dl-cdn.alpinelinux.org/alpine/v3.8/community/x86_64/APKINDEX.tar.gzv3.8.1-22-g24d67bab3a [http://dl-cdn.alpinelinux.org/alpine/v3.8/main]v3.8.1-16-g96e1e57fed [http://dl-cdn.alpinelinux.org/alpine/v3.8/community]OK: 9539 distinct packages available(1/1) Installing tzdata (2018d-r1)Executing busybox-1.28.4-r1.triggerOK: 8 MiB in 14 packagesRemoving intermediate container 069c8e8cd948 ---&gt; 1af55928a1c5Step 5/6 : COPY glibc-*.apk /tmp/ ---&gt; 490259033dddStep 6/6 : RUN apk upgrade --update &amp;&amp; apk add --allow-untrusted /tmp/*.apk &amp;&amp; rm -f /tmp/*.apk /var/cache/apk/* ---&gt; Running in b8b7ef2ec402OK: 8 MiB in 14 packages(1/4) Installing glibc (2.23-r3)(2/4) Installing libgcc (6.4.0-r9)(3/4) Installing glibc-bin (2.23-r3)(4/4) Installing glibc-i18n (2.23-r3)Executing glibc-bin-2.23-r3.triggerOK: 24 MiB in 18 packagesRemoving intermediate container b8b7ef2ec402 ---&gt; 216a3982623dSuccessfully built 216a3982623d 现在查看一下刚刚 build 出来的镜像 12345[root@freeipa101 alpine_glibc_2.23]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; 216a3982623d 10 seconds ago 34.7MBnginx latest be1f31be9a87 37 hours ago 109MBalpine latest 196d12cf6ab1 3 weeks ago 4.41MB &lt;none&gt; 就是刚刚打出的镜像，这时候我们需要给他进行重命名，通过 docker tag --help 查看相关的使用 12345[root@freeipa101 alpine_glibc_2.23]# docker tag --helpUsage: docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE 1[root@freeipa101 alpine_glibc_2.23]# docker tag 216a3982623d docker.io/ricksheng/apline_glibc:2.23 最后一步，跟 GitHub 提交代码一样将镜像推到 Docker hub 上 12345678[root@freeipa101 alpine_glibc_2.23]# docker push docker.io/ricksheng/apline_glibc:2.23The push refers to repository [docker.io/ricksheng/apline_glibc]cad05933e86e: Pushing [========================&gt; ] 7.813MB/15.67MBa531be207876: Pushing [========================================&gt; ] 9.842MB/12.02MBcad05933e86e: Pushing [==========================================&gt; ] 13.31MB/15.67MBcad05933e86e: Pushed2.23: digest: sha256:1823a0b6171a4182416322e0360ef75230cb0491a3d70ab8cc370535c0c035d8 size: 1161 到这里为止，一个简单的镜像就创建完毕了。 2.2、创建gcc镜像和上面类似，创建一个 alpine_gcc 文件夹，然后创建一个 Dockerfile 文件 1[root@freeipa101 alpine_gcc]# vim Dockerfile 123FROM docker.io/ricksheng/apline_glibc:2.23MAINTAINER shengguocun&lt;hzshengguocun@corp.netease.com&gt;RUN apk --no-cahe add make g++ libevent openssl-dev libevent-dev linux-headers &amp;&amp; rm -rf /var/cache/apk/* 进行 build 操作 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@freeipa101 alpine_gcc]# docker build .Sending build context to Docker daemon 2.048kBStep 1/3 : FROM docker.io/ricksheng/apline_glibc:2.23 ---&gt; 216a3982623dStep 2/3 : MAINTAINER shengguocun&lt;hzshengguocun@corp.netease.com&gt; ---&gt; Running in 88133daefd42Removing intermediate container 88133daefd42 ---&gt; 622169df1d2dStep 3/3 : RUN apk --no-cahe add make g++ libevent openssl-dev libevent-dev linux-headers &amp;&amp; rm -rf /var/cache/apk/* ---&gt; Running in a0cade3d8d68apk: unrecognized option: no-cahefetch http://dl-cdn.alpinelinux.org/alpine/v3.8/main/x86_64/APKINDEX.tar.gzfetch http://dl-cdn.alpinelinux.org/alpine/v3.8/community/x86_64/APKINDEX.tar.gz(1/31) Installing libstdc++ (6.4.0-r9)(2/31) Installing binutils (2.30-r5)(3/31) Installing gmp (6.1.2-r1)(4/31) Installing isl (0.18-r0)(5/31) Installing libgomp (6.4.0-r9)(6/31) Installing libatomic (6.4.0-r9)(7/31) Installing pkgconf (1.5.3-r0)(8/31) Installing mpfr3 (3.1.5-r1)(9/31) Installing mpc1 (1.0.3-r1)(10/31) Installing gcc (6.4.0-r9)(11/31) Installing musl-dev (1.1.19-r10)(12/31) Installing libc-dev (0.7.1-r0)(13/31) Installing g++ (6.4.0-r9)(14/31) Installing libevent (2.1.8-r5)(15/31) Installing libbz2 (1.0.6-r6)(16/31) Installing expat (2.2.5-r0)(17/31) Installing libffi (3.2.1-r4)(18/31) Installing gdbm (1.13-r1)(19/31) Installing ncurses-terminfo-base (6.1_p20180818-r1)(20/31) Installing ncurses-terminfo (6.1_p20180818-r1)(21/31) Installing ncurses-libs (6.1_p20180818-r1)(22/31) Installing readline (7.0.003-r0)(23/31) Installing sqlite-libs (3.24.0-r0)(24/31) Installing python2 (2.7.15-r1)(25/31) Installing libevent-dev (2.1.8-r5)(26/31) Installing linux-headers (4.4.6-r2)(27/31) Installing make (4.2.1-r2)(28/31) Installing zlib-dev (1.2.11-r1)(29/31) Installing libcrypto1.0 (1.0.2p-r0)(30/31) Installing libssl1.0 (1.0.2p-r0)(31/31) Installing openssl-dev (1.0.2p-r0)Executing busybox-1.28.4-r1.triggerExecuting glibc-bin-2.23-r3.triggerOK: 255 MiB in 49 packagesRemoving intermediate container a0cade3d8d68 ---&gt; d7a938e82e4eSuccessfully built d7a938e82e4e 查看生成的镜像 123456[root@freeipa101 alpine_gcc]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; d7a938e82e4e 30 seconds ago 248MBricksheng/apline_glibc 2.23 216a3982623d 9 minutes ago 34.7MBnginx latest be1f31be9a87 37 hours ago 109MBalpine latest 196d12cf6ab1 3 weeks ago 4.41MB 1[root@freeipa101 alpine_gcc]# docker tag d7a938e82e4e docker.io/ricksheng/alpine_gcc:6.4.0 123456789[root@freeipa101 alpine_gcc]# docker push docker.io/ricksheng/alpine_gcc:6.4.0The push refers to repository [docker.io/ricksheng/alpine_gcc]c8cb354e6402: Pushing [======&gt; ] 25.93MB/213.2MBc8cb354e6402: Pushing [==========&gt; ] 44.56MB/2c8cb354e6402: Pushing 47.85MB/213.c8cb354e6402: Pushing [===============&gt; ] 67.65MB/213.2MBc8cb354e6402: Pushing [=============================&gt; ] 126.9MB/213.2MBc8cb354e6402: Pusheddf64d3292fd6: Mounted from ricksheng/apline_glibc6.4.0: digest: sha256:7da0e8489ff7d1e0041b3edfa57f1fb8039fb9cd98d01600471a2f29f9fdd0c6 size: 1373 到这里为止，创建 OpenResty 镜像的准备工作都OK了，下面开始吧。 2.3、创建openresty镜像老规矩，创建 alpine_openresty/1.11.2.1 目录，同时创建 Dockerfile 文件以及一个 nginx.conf 文件 12345[root@freeipa101 1.11.2.1]# lltotal 3852-rw-r--r-- 1 root root 570 Oct 4 16:31 Dockerfile-rw-r--r-- 1 root root 1114 Oct 4 16:23 nginx.conf-rw-r--r-- 1 root root 3930804 Oct 4 16:21 openresty-1.11.2.1.tar.gz 123456789101112131415161718worker_processes 1;error_log logs/error.log;events &#123; worker_connections 1024;&#125;http &#123; server &#123; listen 80; location / &#123; default_type text/html; content_by_lua_block &#123; ngx.say(\"HelloWorld\") &#125; &#125; &#125;&#125; 1vim Dockerfile 123456789FROM docker.io/ricksheng/alpine_gcc:6.4.0MAINTAINER shengguocun&lt;hzshengguocun@corp.netease.com&gt;RUN apk add --update perl openssl openssl-dev pcre-dev make gcc musl-devEXPOSE 80 443ENV VERSION=1.11.2.1ADD openresty-$VERSION.tar.gz /usr/local/srcRUN cd /usr/local/src/openresty-$VERSION &amp;&amp; ./configure --prefix=/usr/local --with-http_v2_module --with-http_ssl_module &amp;&amp; make -j4 &amp;&amp; make install &amp;&amp; rm -rf /usr/local/src/openresty-$VERSION &amp;&amp; rm -f /var/cache/apk/*ADD nginx.conf /usr/local/nginx/confENTRYPOINT [\"/usr/local/nginx/sbin/nginx\", \"-g\", \"daemon off;\"] 进行 Build 操作（ make的输出太长就不贴出来了 ）, 完成后查看一下 1234567[root@freeipa101 1.11.2.1]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; 65b5f5a29c4d 27 seconds ago 336MBricksheng/alpine_gcc 6.4.0 d7a938e82e4e 20 minutes ago 248MBricksheng/apline_glibc 2.23 216a3982623d 29 minutes ago 34.7MBnginx latest be1f31be9a87 37 hours ago 109MBalpine latest 196d12cf6ab1 3 weeks ago 4.41MB 1[root@freeipa101 1.11.2.1]# docker tag 65b5f5a29c4d docker.io/ricksheng/openresty:1.11.2.1 1[root@freeipa101 1.11.2.1]# docker push docker.io/ricksheng/openresty:1.11.2.1 到这里为止，我们的镜像就已经打完了，那如何验证呢？ 2.4、验证 &amp; 调试首先你需要做一下身份认证， docker login 12345[root@freeipa101 ~]# docker loginLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.Username (shengguocun@gmail.com): rickshengPassword:Login Succeeded 登录完成之后，你的用户名、密码会以一个 base64 的字符串记录在本地，然后我们需要将镜像拉到本地 1234[root@freeipa101 ~]# docker pull ricksheng/openresty:1.11.2.11.11.2.1: Pulling from ricksheng/openrestyDigest: sha256:12067a9651f3148f2f916c19681c1bd95783b172e65adc36dcb303903fede11bStatus: Image is up to date for ricksheng/openresty:1.11.2.1 运行这个镜像 12[root@freeipa101 ~]# docker run -d -p 8887:80 --name demo001 ricksheng/openresty:1.11.2.16b798d8b9cbf8393151766ab46bfad37342aaf793402841e36befc99c4a5c2c9 最后验证一下，请求宿主机的 IP + 端口 12[root@freeipa101 ~]# curl 127.0.0.1:8887HelloWorld 到这一个完整的创建 OpenResty 的 Docker 镜像的流程就结束了，当然在实际创建镜像的过程中会遇到各种各样的问题，我们需要进入到容器中进行调试。当然新手要注意的一件事 “容器就是容器，不要把容器当虚拟机” 。","tags":[{"name":"OpenResty","slug":"OpenResty","permalink":"https://www.shengguocun.com/tags/OpenResty/"},{"name":"Docker","slug":"Docker","permalink":"https://www.shengguocun.com/tags/Docker/"}]},{"title":"Vanilla （lua web framework）中文文档 [2018.09.19]","date":"2018-09-19T13:18:21.000Z","path":"/blog/2018/09/19/quick-start-Vanilla-lua-web-framework/","text":"0、前言香草/Vanilla是一个基于Openresty实现的高性能Web应用开发框架. 邮件列表 vanilla-en &#118;&#97;&#x6e;&#x69;&#x6c;&#108;&#97;&#x2d;&#x65;&#110;&#x40;&#103;&#111;&#x6f;&#x67;&#x6c;&#x65;&#x67;&#x72;&#x6f;&#x75;&#112;&#x73;&#46;&#99;&#x6f;&#x6d; vanilla-devel &#118;&#x61;&#110;&#105;&#x6c;&#x6c;&#x61;&#45;&#x64;&#x65;&#118;&#101;&#x6c;&#64;&#103;&#x6f;&#x6f;&#103;&#108;&#x65;&#x67;&#x72;&#111;&#x75;&#112;&#115;&#x2e;&#x63;&#111;&#109; vanilla中文邮件列表 &#118;&#x61;&#x6e;&#105;&#108;&#108;&#97;&#64;&#103;&#x6f;&#x6f;&#x67;&#x6c;&#x65;&#x67;&#x72;&#111;&#117;&#x70;&#x73;&#46;&#x63;&#111;&#x6d; 推荐始终使用最新版的Vanilla 当前Vanilla最新版本0.1.0.rc6，支持命令： vanilla-0.1.0.rc6（你没看错，自0.1.0.rc5起，vanilla的命令行和框架代码都带着版本号，方便多版本共存，也方便框架升级） v-console-0.1.0.rc6 特性 提供很多优良组件诸如：bootstrap、 router、 controllers、 models、 views。 强劲的插件体系。 多 Application 部署。 多版本框架共存，支持便捷的框架升级。 一键 nginx 配置、 应用部署。 便捷的服务批量管理。 你只需关注自身业务逻辑。 0.1、安装1$ ./setup-framework -v $VANILLA_PROJ_ROOT -o $OPENRESTY_ROOT #运行 ./setup-framework -h 查看更多参数细节 0.2、快速开始部署你的第一个Vanilla Application 1$ ./setup-vanilal-demoapp [-a $VANILLA_APP_ROOT -u $VANILLA_APP_USER -g $VANILLA_APP_GROUP -e $VANILLA_RUNNING_ENV] #运行 ./setup-vanilal-demoapp -h 查看更多参数细节 启动你的 Vanilla 服务 1$ ./$VANILLA_APP_ROOT/va-appname-service start 社区组织 QQ群&amp;&amp;微信公众号 Openresty/Vanilla 开发 1 群：205773855 Openresty/Vanilla 开发 2 群：419191655 Openresty 技术交流 1 群：34782325 Openresty 技术交流 2 群：481213820 Openresty 技术交流 3 群：124613000 Vanilla开发微信公众号:Vanilla-OpenResty(Vanilla相关资讯、文档推送) 1、快速上手1.1、Hello World1.1.1、Vanilla 的安装安装准备 安装好 OpenResty Vanilla Github 地址：https://github.com/idevz/vanilla 安装 123456789# 1.git clone 最新 Vanilla 版本（或者下载相应的 Vanilla release 版本）git clone https://github.com/idevz/vanilla.git# 2. 切换到 Vanilla 文件夹cd vanilla# 3.编译 vanilla： ./setup-framework -v $VANILLA_PROJ_ROOT -o $OPENRESTY_ROOT 其中 $VANILLA_PROJ_ROOT 为 vanilla 框架安装目录。 -o 为 openresty 安装目录./setup-framework -v /application/vanilla -o /application/openresty 经过这 3 步如果没有报错，则安装 vanilla 成功 创建 vanilla 项目 12345678910111213141516171819202122232425262728293031#1. 创建 vanilla 的运行用户useradd -s /sbin/nologin -M nginxid nginx # 可以查看到创建的用户# 2、创建 vanilla 项目, -a 为 项目路径，-u 为执行用户 -g 为用户组 （在根目录 /home/webserver 下创建名为 cms 的项目）./setup-vanilla-demoapp -a /home/webserver/cms -u nginx -g nginx# 3、删掉默认 Nginx 服务pkill -9 nginx# 4、切换到项目文件夹 编辑项目配置文件，改成你要的cd /home/webserver/cmscd nginx_confvim va-nginx.confvim va-nginx-development.conf# 5、同步配置文件到运行目录./va-cms-service initconf dev -f #开发模式./va-cms-service initconf -f #生产模式# 6、启动项目（2选1）./va-cms-service start dev # 启动开发模式./va-cms-service start # 启动生产模式 服务启动后，开发环境默认启动在 9110 端口，http://localhost:9110 即可访问 vanilla 常用命令 启动项目： ./va-cms-service start 或者 ./va-orcms-service start dev 重启项目 ./va-cms-service restart 或者 ./va-orcms-service restart dev 停止项目： ./va-cms-service stop 或者 ./va-orcms-service stop dev 创建配置文件 ./va-cms-service initconf dev -f 1.2、如何调试1.2.1、Vanilla 的 调试除了查看 nginx 错误日志辅助开发外，为了方便 Vanilla 项目的开发和调试，Vanilla 提供了诸如 print_r 之类的对象输出方法，以及详细友好的页面报错输出，你不需要到服务器日志去查看，就能所见即所得的开发调试代码. sprint_r，print_r，lprint_r，err_log sprint_r 将 LUA 对象等格式化为易读的字符串返回 print_r 类似 ngx.say 的效果，将对象、变量等以易读的格式进行输出，适用于 Vanilla 开发的 Web 服务 lprint_r print_r 的 CLI 版本，适用于 v-console 命令行环境 1234567891011╰─○ v-console-0.1.0.rc6Lua 5.1.4 Copyright (C) 1994-2008 Lua.org, PUC-Riov-console&gt;a=&#123;&#125;v-console&gt;a.v1='a_v1'v-console&gt;a.v2='a_v2'v-console&gt;lprint_r(a)&#123; v2 = \"a_v2\", v1 = \"a_v1\"&#125;v-console&gt; err_log err_log 方法是对 ngx.ERR 的封装，将 msg 记录到 nginx 错误日志 1.3、如何新增一个Controller1.3.1、Vanilla 的 controllervanilla 的 controller 是业务处理的关键，vanilla 通过对 URI 的路由，找到本次请求对应的 controller 和 action。 最简单的 Controller 自动生成的 demo 中默认生成了 IndexController 和 index action（function IndexController:index()），默认使用简单路由协议（vanilla.v.routes.simple）对 URI 进行路由 12345678910111213141516171819local IndexController = &#123;&#125;-- curl http://localhost:9110function IndexController:index() local view = self:getView() local p = &#123;&#125; p['vanilla'] = 'Welcome To Vanilla...' .. user_service:get() p['zhoujing'] = 'Power by Openresty' -- view:assign(p) do return view:render('index/index.html', p) end return view:display()end-- curl http://localhost:9110/index/action_bfunction IndexController:action_b() return 'index-&gt;action_b'endreturn IndexController 以上代码解释 关于上面的 controller 实例代码，我们只需关注下面几点 IndexController:index （index Controller 中的 index Action），通过 self:getView() 方法获取视图实例 可以通过先调用 view:assign(p) 将所需要的参数传入视图，再调用 view:display() 进行模板渲染，或者可以直接调用 view:render(&#39;index/index.html&#39;, p) 方法，指定需要渲染的模板，并同时传入相应的参数 模板参数都是与 LUA 数组的形式进行传递 每个 action 的返回值都必须是字符串，所以可以知道 view:display() 和 view:render() 方法都是返回字符串 IndexController:action_b （index Controller 中的 action_b Action，这里注意，action 的方法名必须小写），使用默认的简单路由协议，访问 URI 为 curl http://localhost:9110/index/action_b 注：目前 vanilla 所默认使用的模板引擎是 appo 老师开发的 resty-template，模板详细的使用文档请移步 appo 老师处参阅。 1.3.2、新添加一个 Controller给 Vanilla 添加一个新的 Controller 非常简单，只需要在项目的 controllers 目录，实现一个 LUA 包，包导入的函数即为各个 action， 文件名与 controller 同名。例如添加一个名为 idevz 的 controller， 且实现一个名为 dohello 的 action（）。 123456local IdevzController = &#123;&#125;-- curl http://localhost:9110/idevz/dohellofunction IdevzController:dohello() return 'do-hello-action.'endreturn IdevzController 1.4、如何使用Models/Dao1.4.1、Vanilla 的 DAOvanilla 的 DAO 预设为项目对数据源的封装，一切对数据源的操作都可以封装成 DAO，方便维护、管理、缓存等。 Vanilla 的 DAO 在项目的 models/dao 路径下，一般使用 LoadModel 方法进行加载 最简单的 DAO 由自动生成的 demo 中默认生成了 TableDao，可以看出 TableDao 只是一个普通的 LUA 包。 123456789101112131415161718192021local TableDao = &#123;&#125;function TableDao:set(key, value) self.__cache[key] = value return trueendfunction TableDao:new() local instance = &#123; set = self.set, __cache = &#123;&#125; &#125; setmetatable(instance, TableDao) return instanceendfunction TableDao:__index(key) local out = rawget(rawget(self, '__cache'), key) if out then return out else return false endendreturn TableDao 以上代码解释 DAO 可以是任何对数据层访问封装的 LUA 包，实现方式非常自由。 1.5、如何使用Models/Service1.5.1、Vanilla 的 Servicevanilla 的 Service 预设为项目对某些通用业务逻辑封装为独立的 Service，方便维护、管理、缓存等。 Vanilla 的 Service 在项目的 models/service 路径下，一般使用 LoadModel 方法进行加载 最简单的 Service 由自动生成的 demo 中默认生成了 UserService，可以看出 UserService 也只是一个普通的 LUA 包。不过 Service 一般调用更底层的 DAO ，并对之做必要封装，并将相关的 Service 暴露给 Controller 使用 123456789local table_dao = LoadApplication('models.dao.table'):new()local UserService = &#123;&#125;function UserService:get() table_dao:set('zhou', 'UserService res') return table_dao.zhouendreturn UserService 以上代码解释 Service 可以是任何对数据层访问封装的 LUA 包 2、APIs2.1、配置香草/Vanilla的配置由以下三个部分组成. App配置 Nginx配置 WAF配置 2.1.1、App配置应用基础配置（config/application.lua） 1234567891011121314151617Appconf.sysconf = &#123; --系统预加载配置文件 'v_resource',&#125;Appconf.name = 'app_name' --app名称，执行vanilla new命令时给定的应用名Appconf.route='vanilla.v.routes.simple' --路由器，指定URL路由方式，目的解析出需要执行的controller与actionAppconf.bootstrap='application.bootstrap' --初始化bootstrap（用来对应用进行初始化操作）Appconf.app=&#123;&#125; --app相关配置Appconf.app.root='./' --当前vanilla start命令执行路径Appconf.controller=&#123;&#125; --当前app的controller相关配置Appconf.controller.path=Appconf.app.root .. 'application/controllers/' --controller文件所在路径（使用默认生成路径即可）Appconf.view=&#123;&#125; --当前app的视图层相关配置Appconf.view.path=Appconf.app.root .. 'application/views/' --模板路径Appconf.view.suffix='.html' --模板后缀Appconf.view.auto_render=true --是否开启自动渲染 应用基础配置的引用 12-- 如上的配置，可以在代码中通过 Registry['APP_CONF'] 表来进行获取，比如获取 APP_NAMElocal app_name = Registry['APP_CONF']['name'] 错误处理配置（config/errors.lua） 根据errors.lua文件中实例，配置用户级别错误码. 123local Errors = &#123; [1000] = &#123; status = 500, message = \"Controller Err.\" &#125;,&#125; Restful 路由协议配置（config/restful.lua） 根据 URI 需要来自定义路由协议的配置 12345678910111213141516171819local restful = &#123; v1=&#123;&#125;, v=&#123;&#125;&#125;restful.v.GET = &#123; &#123;pattern = '/', controller = 'index', action = 'index'&#125;, &#123;pattern = '/:category', controller = 'index', action = 'list'&#125;&#125;restful.v.POST = &#123; &#123;pattern = '/post', controller = 'index', action = 'post'&#125;,&#125;restful.v1.GET = &#123; &#123;pattern = '/api', controller = 'index', action = 'api_get'&#125;,&#125;return restful 系统相关配置（sys/*） 比如DB、MC等资源配置，系统相关的分机房配置等（在某些大公司，这部分配置又运维人员统一管理和下发），文件格式目前使用相对更运维友好的 ini 文件，开发中可以方便的在 Registry[‘sys_conf’] 中获取相关数据，如 Registry[&#39;sys_conf&#39;][&#39;cache&#39;][&#39;lrucache&#39;] 获取 lrucache 相关配置 系统缓存相关配置 （sys/cache） 12345678910111213141516171819202122[shared_dict]dict=idevzexptime=100[memcached]instances=127.0.0.1:11211 127.0.0.1:11211exptime=60timeout=100poolsize=100idletimeout=10000[redis]instances=127.0.0.1:6379 127.0.0.1:6379exptime=60timeout=100poolsize=100idletimeout=10000[lrucache]items=200exptime=60useffi=false 目前这部分配置一般由 vanilla.v.libs.cache 来使用 目前支持的配置项如 poolsize（连接池大小）、timeout（数据获取超时等） 系统缓存相关配置 （sys/v_resource） 12345678910111213141516171819202122[mc]conf=127.0.0.1:7348 127.0.0.1:11211[redis]conf=127.0.0.1:7348 127.0.0.1:7349[redisq]conf=127.0.0.1:7348 127.0.0.1:7349[db.user.write]host =127.0.0.1port =3306dbname =user.infouser =idevzpasswd =idevz[db.user.read]host =127.0.0.1port =3306dbname =user.infouser =idevzpasswd =idevz 对所使用的数据资源做配置 Registry[&#39;sys_conf&#39;][&#39;v_resource）&#39;][&#39;db.user.write&#39;][&#39;host&#39;] 获取写库的 HOST 信息 2.1.2、Nginx配置自动生成的 Nginx 配置文件 初始化项目的时候会在项目目录下（nginx_conf/）自动生成这个项目所对应的两套（分别对应开发和线上环境）配置文件，生成的两套配置文件中，每套都包含 nginx.conf 和 vhost 两个配置文件 生产环境 va-nginx.conf 文件 va-nginx.conf 配置文件内容包含 nginx 配置主干（main、events、http 等重点配置段），包括用户、组的配置，工作进程等等通用配置，关键的还有 lua_package_path、lua_package_cpath 的配置，还有框架初始化文件（vanilla/framework/init.lua）的加载 vhost/app_name.conf 文件 vhost/app_name.conf 文件是当前应用的相关配置，包括 APP_NAME、VANILLA_VERSION、$template_root、$va_cache_status 等全局变量的初始化，$document_root，Server_name 等的设置，还有关键的应用入口（content_by_lua_file），lua_shared_dict 等的设置，不过这些设置都是自动生成的，开发人员没有特殊需求的话，并不需要关注这些 开发环境 va-nginx-development.conf 文件 va-nginx-development.conf 文件的内容跟开发环境类似，唯一的区别在于加载框架初始化文件（vanilla/framework/init.lua）的方式为 init_by_lua_file dev_vhost/app_name.conf 文件 默认的dev_vhost/app_name.conf 文件的配置同生产环境的配置基本一样，关键不同在于 lua_code_cache 的设置 注：所以初始化项目后，首先需要执行 sudo ./va-app_name-service initconf dev 命令，就是为了将自动生成的配置文件部署到 OpenResty 默认的配置文件路径下，如果需要更新 va-nginx（-development）.conf 则还需要在命令后面加上 -f 参数进行强行部署，每次如果需要修改配置，也只需修改这部分配置，然后执行 initconf 即可 nginx.lua( vanilla-0.1.0.rc5 后废弃此配置 ) 分为ngx_conf.common和ngx_conf.env两个部分，common是对Openresty指令集的配置如INIT_BY_LUA，可以是包或者文件(BY_LUA_FILE)，env是环境的部分，包括了开发环境，测试环境和生产环境端口和缓存配置等控制. 123456789ngx_conf.common = &#123; INIT_BY_LUA = 'nginx.init', CONTENT_BY_LUA_FILE = './pub/index.lua'&#125;ngx_conf.env = &#123;&#125;ngx_conf.env.development = &#123; LUA_CODE_CACHE = false, PORT = 7200&#125; 2.1.3、WAF配置waf.lua 包括WAF规则的配置，及各种规则参数的配置，相关使用方法详见 waf 2.2、Bootstrap2.2.1、使用 Bootstrap 来做服务初始化Vanilla 使用 Bootstrap 来做应用初始化的工作，用户可以在此对应用做一些配置（比如所使用的路由协议，使用何种视图引擎），对配置做一些初始化加载，初始化 WAF，初始化 Plugins 等操作，Vanilla 运行在 OpenResty content_by_lua\\这个 Phrase，使用 Bootstrap 可以很好的实现对请求的细粒度控制* Bootstrap 即类 application.bootstrap Bootstrap 的实现其实是一个名为 application.bootstrap 的 Vanilla 类，实现了构造器初始化的属性只有一个（当前请求所使用的 dispatcher），我们只需要关注根据需求实现各种 init 方法即可，最后只要在 boot_list 方法返回的列表中的 init 方法都会被顺序执行 12345678910111213function Bootstrap:boot_list() return &#123; -- Bootstrap.initWaf, -- Bootstrap.initErrorHandle, Bootstrap.initRoute, -- Bootstrap.initView, -- Bootstrap.initPlugin, &#125;endfunction Bootstrap:__construct(dispatcher) self.dispatcher = dispatcherend 上面的定义代表只有 initRoute 方法会被执行，而上面两个方法的实现我们并不需要关心和更改，只需要定义各种 init 方法，并更新 boot_list 返回的表元素即可，比如下面初始化路由协议的 initRoute 12345function Bootstrap:initRoute() local router = self.dispatcher:getRouter() local restful_route = restful:new(self.dispatcher:getRequest()) router:addRoute(restful_route, true)end 注：可以通过 self.dispatcher 获取当前请求相关的详细信息，并进行相关控制 2.3、Controllers2.3.1、Vanilla 的 controllervanilla 的 controller 是业务处理的关键，基本的用法请参考上文 (如何新增一个Controller) 。 关于 Controller Vanilla 的 Controller 可以是任何普通的 LUA 包，只不过导入的方法被用作处理请求的 Action。如下示例： 12345678910111213141516171819local IndexController = &#123;&#125;-- curl http://localhost:9110function IndexController:index() local view = self:getView() local p = &#123;&#125; p['vanilla'] = 'Welcome To Vanilla...' .. user_service:get() p['zhoujing'] = 'Power by Openresty' -- view:assign(p) do return view:render('index/index.html', p) end return view:display()end-- curl http://localhost:9110/index/action_bfunction IndexController:action_b() return 'index-&gt;action_b'endreturn IndexController 更面向对象的 Controller Vanilla 支持使用 Class 方法来声明一个 Controller，实例如下： 12345678local IndexController = Class('controllers.index')-- curl http://localhost:9110/index/action_bfunction IndexController:action_b() return 'index-&gt;action_b'endreturn IndexController 这种情况下，可以定义 Controller 的构造器来对其进行初始化。示例如下： 123456789101112local IndexController = Class('controllers.index')function IndexController:__construct() self.aa = aa(&#123;info='ppppp'&#125;)end-- curl http://localhost:9110/index/action_bfunction IndexController:action_b() return 'index-&gt;action_b'endreturn IndexController 甚至还可以声明一个 Controller 基类，处理某些通用的逻辑，相关的详细用法参见 Vanilla面向对象 相关章节。 关于 Action 的返回值 Vanilla 底层会将 Action 执行的结果，完全使用 ngx.print 进行输出，所以 Action 的返回值必须不能为空。而由于 Vanilla 的 Response 中，提供了给响应添加头尾的 Response:appendBody 和 Response:prependBody 方法，最终的结果会将这些部分合起来一起返回，所以 Action 的返回值要求如下： Action 返回值必须非空 Action 返回值可以为一维索引数组（不可以是多维 Hash 数组）或者字符串 2.4、模板引擎2.4.1、Vanilla 的视图引擎为去除模板运行时模板解析带来的不必要开销，从 vanilla-0.1.0.rc7 起 Vanilla 开始支持 OpenResty 官方的 Lemplate 模板引擎，下面将简要介绍 Vanilla 中 Lemplate 的用法，以及 Vanilla View 接口介绍 Vanilla 的视图渲染 Vanilla 在 vanilla.v.dispatcher 中导入了默认的模板引擎（local View = LoadV &#39;vanilla.v.views.rtpl&#39;），但是可以在 Bootstrap 中实现 initView 来修改所使用的视图引擎。而 Vanilla 的模板渲染，只需要在相应的 Action 中获取当前视图实例，注入数据，展示即可。下面就以 Lemplate 模板引擎为例，展示相关用法 首先在 Bootstrap 中实现 initView 方法，修改项目所使用的视图引擎 12345678910111213141516-- application/bootstrap.luafunction Bootstrap:initView() local view = LoadV('vanilla.v.views.lemplate'):new(self.dispatcher.application.config.view) self.dispatcher:setView(view)end-- boot_list 中打开 Bootstrap.initView 方法调用function Bootstrap:boot_list() return &#123; -- Bootstrap.initWaf, -- Bootstrap.initErrorHandle, -- Bootstrap.initRoute, Bootstrap.initView, -- Bootstrap.initPlugin, &#125;end 运行 ./va-{app_name}-service ltpl 命令调用 Lemplate 编译你的 TT2 模板 下面是 TT2 模板示意 12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;[% title %]&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt;[% FOREACH userinfo IN userlists %]&lt;p&gt; &lt;h6&gt;姓名：[% userinfo.name %] / 地址：[% userinfo.addr %]&lt;/h6&gt;&lt;/p&gt;[% END %]&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 在 Vanilla Action 中调用编译好的模板 12345678function IndexController:index() local view = self:getView() local users = &#123; &#123;name='idevz', addr='yunnan'&#125;, &#123;name='vanilla', addr='beijing'&#125;, &#125; return view:assign(&#123;userlists=users, title = 'Vanilla-Lemplate'&#125;)end 注： local view = self:getView() 获取当前视图实例 view:assign({userlists=users, title = &#39;Vanilla-Lemplate&#39;}) 将数据注入视图 注：以上为 Lemplate 所使用的 TT2 模板实例，关于 Lemplate 的详细使用，可参考其详细 文档 2.5、插件2.5.1、Vanilla 的插件体系为了减少运行占用的系统资源，使开发更简便，Vanilla 默认只运行在 content_by_lua 这个 phrase，但是为了支持业务开发有层次化的请求控制，Vanilla 实现了便捷的插件机制，提供了六个钩子，给请求的细粒度控制提供了可能。下面我们来看看如何使用 Vanilla Plugin 的简单使用 在 Vanilla 项目中使用插件是非常简单的，只需要在 application/plugins/ 路径下实现 Vanilla 的插件 LUA 包即可，插件包可以按需实现 6 个钩子的方法。默认生成的 demo 项目中自动生成了一个 admin plugin，见 application/plugins/admin.lua。六个钩子方法按需实现，空方法可去掉，如下所示： 123456789101112local AdminPlugin = LoadV('vanilla.v.plugin'):new()function AdminPlugin:routerStartup(request, response) print_r('&lt;pre&gt;') if request.method == 'GET' then print_r('-----------' .. sprint_r(request.headers) .. '----------') else print_r(request.headers) endendreturn AdminPlugin Vanilla Plugin 的调用 Vanilla Plugins 的调用非常简单，只需要在 application/bootstrap.lua 中实现 initPlugin 方法，并调用 dispatcher 的插件注册方法将插件注入项目（ self.dispatcher:registerPlugin(admin_plugin)），即能在对应的时机执行相关钩子对应的方法 123456789101112131415161718local Bootstrap = Class('application.bootstrap')function Bootstrap:initPlugin() local admin_plugin = LoadPlugin('plugins.admin'):new() self.dispatcher:registerPlugin(admin_plugin);endfunction Bootstrap:boot_list() return &#123; Bootstrap.initPlugin, &#125;endfunction Bootstrap:__construct(dispatcher) self.dispatcher = dispatcherendreturn Bootstrap Vanilla 支持的插件钩子 以下列出 Vanilla 支持的 6 中插件钩子 123456function Plugin:routerStartup(request, response) -- 开始路由function Plugin:routerShutdown(request, response) -- 路由结束function Plugin:dispatchLoopStartup(request, response) -- 开始请求分发function Plugin:preDispatch(request, response) -- 预分发（载入相关的 controller）function Plugin:postDispatch(request, response) -- 请求响应function Plugin:dispatchLoopShutdown(request, response) -- 请求分发执行结束 2.6、路由2.6.1、Vanilla 的路由体系Vanilla 实现的路由体系有一个路由器（vanilla.v.router）和若干路由协议构成（Vanilla 默认实现了 vanilla.v.routes.simple 和 vanilla.v.routes.restful 两种路由协议，默认使用 simple 路由来路由请求），请求处理的开始阶段，Vanilla 通过调用路由器协议栈中的各种路由协议，计算出处理当前请求的 controller 和 action，这就是 Vanilla 路由体系的职责所在。如果默认的两种路由协议不能满足你的 URI 路由需求，你可以参考我的一篇《如何给Vanilla(OpenResty)添加一个路由协议》的博文 Vanilla 路由器 Vanilla 的路由器 vanilla.v.router 是请求路由的基础，路由器提供了对路由协议的添加 addRoute(route, only_one)，删除 removeRoute(route_name)，获取路由列表 getRoutes() 等方法，用户可以调用这些方法来管理路由协议栈并使用路由器，不过用户不需要关心路由器的实现，而只需要关注路由协议的实现。 给路由器添加一条路由协议 路由器只有唯一一个 vanilla.v.router，但路由协议可以有多个，通过 addRoute(route, only_one) 方法的调用可以向路由协议栈添加一条路由协议，第二个参数为可选参数，当设置为 true 时，代表将清空路由协议栈，只使用当前添加的这条路由协议，因为 Vanilla 路由请求的方式是路由器根据路由协议栈中的路由协议挨条解析，直到找到匹配的 controller 和 action 为止，太多的路由协议栈可能影响路由性能。 删除一条路由协议 Vanilla 的每条路由协议都有 route_name 属性，删除时只需要调用 removeRoute(route_name) 获取当前所使用的路由协议 Vanilla 支持获取当前请求所使用的路由协议，只需调用 getCurrentRoute() 方法，调用 getCurrentRouteName() 方法可以获取当前路由协议名 路由协议 路由协议非常的简单，因为路由协议的关键功能在于为当前请求找到对应的 controller 和 action，核心在于根据当前请求实例 request，通过实现 match 方法，来获取结果，下面是根据 vanilla.v.routes.simple 路由协议提炼出来的路由协议简单骨架： 12345678910111213141516171819local Simple = &#123;&#125;function Simple:new(request) local instance = &#123; route_name = 'vanilla.v.routes.simple', request = request &#125; setmetatable(instance, &#123; __index = self, __tostring = function(self) return self.route_name end &#125;) return instanceendfunction Simple:match()endreturn Simple 注：我们需要关注以下两点 route_name 这是路由协议栈索引的关键，协议栈中的路由协议依靠 route_name 进行管理 request 是当前请求的实例，包含了当前请求携带的 URI，http_header 等数据，是请求路由的依据 2.7、异常处理2.7.1、Vanilla 的错误处理Vanilla 的错误处理分为框架系统错误和应用错误两种类型，系统错误由框架控制，一般导致致命错误，直接抛出 500 内部错误，切不再往下执行，而应用错误则可以通过定义 errorController 来自定义处理 Vanilla 应用错误 Vanilla 提供了方便的错误处理方式，避免当代码运行报错后，页面只显示一个 500 错误的白页，没有详细报错信息，影响开发效率，Vanilla 的应用错误处理非常简单，在业务开发中，我们所关注的各个组件比如 DAO、Service、Controller、Action、Library 等都可能报错，Controller Action 作为 Vanilla 项目处理请求的执行体，一切业务组件的错误都可以通过一个统一的处理口径 errorController 来方便的处理。在业务组件开发过程中的错误，或者用户自定义的错误，都可以在 errorController 中得到捕获和处理，默认初始化的 demo 项目中，application/controllers/ 路径下，默认定义了一个 error.lua 文件，这就是前面所说的 errorController，下面我们具体来看看这段代码： 12345678910111213141516171819local ErrorController = &#123;&#125;local ngx_log = ngx.loglocal ngx_redirect = ngx.redirectlocal os_getenv = os.getenvfunction ErrorController:error() local env = os_getenv('VA_ENV') or 'development' if env == 'development' then local view = self:getView() view:assign(self.err) return view:display() else local helpers = require 'vanilla.v.libs.utils' ngx_log(ngx.ERR, helpers.sprint_r(self.err)) -- return ngx_redirect(\"http://sina.cn?vt=4\", ngx.HTTP_MOVED_TEMPORARILY) return helpers.sprint_r(self.err) endendreturn ErrorController 代码释意：（你只需要关注以下几点，即可随意，按需定义适合你的 errorController） 这是一个普通的 LUA 包，一个普通的 Vanilla Controller，唯一需要注意的一点就是需要实现一个 error 方法，注意方法名小写 可以通过对运行环境的判断来，对不同的运行环境进行不同的错误处理，比如开发环境可能需要直接将错误打印到页面，而生产环境可能需要出错误页面等 Vanilla 框架系统错误（致命错误） 当有些 Vanilla 项目所必须的配置或者关键步骤执行异常而影响项目往下运行的情况下，会抛出致命错误，并结束当前请求，目前有以下几种情况 关键配置缺少 项目未配置项目名 name，或者未指定项目根路径 root，Vanilla 有很多地方依赖项目名，比如缓存的 KEY 设置，项目的各类包加载依赖于项目根路径做全局加载，多 APP 支持也依赖与此。如果 config/application.lua 中缺少这两个配置，则会如下错误： 1234Sys Err: Please set app name and app root in config/application.lua like: Appconf.name = 'idevz.org' Appconf.app.root='/data1/VANILLA_ROOT/idevz.org/' bootstrap 报错 Bootstrap 中的各种 init 方法并不是必须的，但是如果这部分方法定义后，执行错误，将影响整体项目的正常运行，所以 application/bootstrap.lua 中的运行报错也会报出系统致命错误，举例如下： 123456function Bootstrap:initRoute() local router = self.dispatcher:getRouter() local restful_route = restful:new(self.dispatcher:getRequest()) router:addRoute(restful_route, true) print_r('xx' .. false)end 注：以上代码，最后一行操作试图将字符串与 bool 值 false 连接，会报出致命错误，如下： 12&lt;pre /&gt;\"...g/idevz/code/www/vanilla/orcon/application/bootstrap.lua:18: attempt to concatenate a boolean value\" dispatch 执行报错 dispatch 属于框架的请求分发操作，请求分发执行出错直接导致致命错误，不过这个错误由框架自己处理，用户不需要关注 2.8、内建类2.8.1、Vanilla 的內建变量和方法为方便业务开发，Vanilla 提供了一些比较实用的內建方法和变量，这里我们说明如下，随着框架的更新，本页面会及时更新，欢迎随时关注。 Vanilla 的內建变量 Vanilla 的內建变量很多来自于 nginx.conf，其他则来自于 ngx.var，Vanilla 将这些变量都缓存在了 Registry 中 Registry 变量 Registry 是 Vanilla 中为了全局数据共享，及高效数据访问而封装的一个全局表，这里缓存了刻画当前请求比较全的数据，具体列表说明如下： 12345678910111213141516171819-- 以下数据以 \"curl http://domain.org/?arg1=aa1&amp;arg2=aa2\" 访问为例进行说明Registry['APP_CONF'] -- 当前应用的配置数据，来自于（config/application.lua）Registry['sys_conf'] -- 当前应用的系统配置，来自于（sys/*路径，比如可以使用 Registry['sys_conf']['cache'] 获取 sys/cache 文件中关于 cache 的配置）Registry['REQ_URI'] -- 当前请求的 URI ，为 \"/\"Registry['REQ_ARGS'] -- 当前请求的参数字符串，即 Query_String，为 \"arg1=aa1&amp;arg2=aa2\"Registry['REQ_ARGS_ARR'] -- 当前请求的参数列表，为一个 LUA 数组Registry['REQ_HEADERS'] -- 当前请求的请求头数组Registry['APP_NAME'] -- 应用名称Registry['APP_ROOT'] -- 应用所在根目录Registry['APP_HOST'] -- 当前请求的 HOST 信息Registry['APP_PORT'] -- 当前请求的 PORT 信息Registry['VANILLA_ROOT'] -- VANIALLA 框架的根目录Registry['VANILLA_VERSION'] -- 当前所使用的 VANILLA 版本号Registry['VANILLA_APPLICATION'] -- 'vanilla.v.application' LUA 包Registry['VANILLA_UTILS'] -- 'vanilla.v.libs.utils' LUA 包Registry['VANILLA_CACHE_LIB'] -- 'vanilla.v.cache' LUA 包Registry['VANILLA_COOKIE_LIB'] -- 'vanilla.v.libs.cookie' LUA 包Registry['APP_BOOTS'] -- 应用 'application.bootstrap' LUA 包Registry['APP_PAGE_CACHE_CONF'] -- 应用 Page Cache 相关配置 注：上面很多全局变量是从 ngx.var. 获取来的结果缓存的，这样避免每次都请求 ngx.var 而减少这部分性能开销，并且其中有些信息比如 APP_NAME，APP_ROOT 等服务一经启动就不会更改，而像 `REQ_相关的数据则是每次请求都不一样，好在一次请求可能对这部分数据会多次调用，所以将其缓存在Registry` 表中* Vanilla 的內建函数 Vanilla 有很多内建的函数，这些函数有些来自于 Vanilla 框架本身功能性的一些 LUA 包中，比如 vanilla.v.controller、vanilla.v.request、vanilla.v.response 等，另一些比如通用的方法，比如 print_r、 page_cache 和 vanilla_init，再有比如 Vanilla 定义的各种包加载函数，列表如下： 1234567LoadLibrary -- 加载项目 library 路径下的 LUA 包LoadController -- 加载项目 controllerLoadModel -- 加载项目 model 路径下的包，包括 DAO 和 ServiceLoadPlugin -- 加载项目 plugins 路径下所定义的插件LoadApplication -- 加载项目 application 路径下的 LUA 包LoadApp -- 加载项目根目录下面的 LUA 包LoadV -- 加载 Vanilla 框架相关的 LUA 包 注：以上有些加载器功能重复，目的在于减短所传递参数的长度，比如加载 Index Controller， 使用 LoadController 方法是，只需要写 LoadController(&#39;index&#39;)， 而如果使用方法 LoadApp 则应该写成LoadApp(‘application.controllers.index’)` 方法 page_cache 该方法调用 Vanilla 封装的页面缓存逻辑，详细内容参见 (进阶/页缓存) 单步调试方法 print_r、sprint_r 等 调试系列方法主要为了开发时能清晰方便的查看变量状态，记录开发日志等功能，详细内容参见 (快速上手/如何调试) 方法 init_vanilla 方法 init_vanilla 主要完成框架基础功能的初始化，比如 Registry 的初始化，各种 Loader 的定义，页面缓存的实现等，本方法默认在应用请求处理入口的第一句语句执行 3、Libs3.1、Cookie3.1.1、Vanilla 中使用 CookieVanilla 中封装了 vanilla.v.libs.cookie 包，源至 lua-resty-cookie，提供了简单的 get、set、getAll 等方法来控制 Cookie，下面具体使用举例如下： vanilla.v.libs.cookie 包使用 一例胜千言： 1234567891011121314151617181920local IndexController = &#123;&#125;-- 载入 vanilla.v.libs.cookie 包local vcookie_lib = LoadV('vanilla.v.libs.cookie')function IndexController:index() -- 实例化 vanilla.v.libs.cookie 类 local cookie = vcookie_lib() -- 调用 set 方法，设置 cookie cookie:set('idevz', 'kkkk', &#123;expires=1000&#125;) cookie:set('idevz_api', 'kkkk', &#123;expires=1000,path='/'&#125;) -- 调用 getAll 方法，获取所有 cookie，也可以调用 get 获取单个cookie print_r(cookie:getAll()) do return '' endendreturn IndexController 注： vanilla.v.libs.cookie 支持以下 cookie 选项 1234567pathdomainmax_agesecurehttponlysamesiteextension 4、进阶4.1、页缓存4.1.1、Vanilla 的 Page Cachevanilla 的 Page Cache 实现了类似 Nginx 的 FastCGICache 或者 ProxyCache 的访问结果整体缓存，以 URI 的一定规则作为缓存的 KEY，属于内存型 Cache，存储位置可配置，默认存储在 OpenResty 共享字典（Share Dict）中，默认生成的项目中 Page Cache 为关闭状态 Page Cache 相关配置 Page Cache 相关的所有配置见项目的 config/application.lua 中， Appconf.page_cache 相关配置段，如下所示： 12345678Appconf.page_cache = &#123;&#125;Appconf.page_cache.cache_on = true-- Appconf.page_cache.cache_handle = 'lru'Appconf.page_cache.no_cache_cookie = 'va-no-cache'Appconf.page_cache.no_cache_uris = &#123; 'uris'&#125;Appconf.page_cache.build_cache_key_without_args = &#123;'rd'&#125; 配置释意 cache_on 缓存开关，true 为开启 Page Cache，false 则为关闭 cache_handle 设置 Page Cache 的存储介质，目前支持 Memcache、Redis、resty.lrucache、OpenResty Share Dict，默认为 OpenResty Share Dict no_cache_cookie 设置不缓存的 cookie KEY，Vanilla Page Cache 使用这个设置所指的 cookie KEY 来对某些特殊页面不缓存，默认当页面中有 KEY 为 va-no-cache 这个 COOKIE 的时候，当前页面不缓存 no_cache_uris 设置不缓存的 URI 列表，默认配置例如 http://app.com/uris 命中 uris 则，当前页面不缓存 build_cache_key_without_args 设置在缓存 KEY 中去除某些参数，比如某些 API 的版本号，或者随机数等，默认配置中的 rd 设置代表，当 URI 中有 rd 参数时，则生成的 Page Cache KEY 中清除这个参数 注：缓存的清理，只需要在请求的 URL 中，添加参数 vapurge 4.2、面向对象4.2.1、面向对象的 VanillaLua 提供了部分面向对象的语法糖，这仅仅能在开发中提供一个功能不完备的独立 Class 的使用，有 self 可以来引用 LUA 表的某些属性和方法，但是更多的面向对象特性，比如继承，比如类的构造等，LUA 支持的并不是非常好，日常的业务开发中，我们确实有些通用的逻辑可能需要复用，或者数据需要共享，需要有父子关系等等。所以我们在 Vanilla 中，简单封装了部分面向对象的特性，这里我们简单介绍其使用方法。 一个简单的 Vanilla 类 下面我们看一个例子： 类定义 12345678910111213local LibA = Class(\"LibA\")function LibA:idevzDo(params) local params = params or &#123; lib_bb = 'idevzDo LibA'&#125; return paramsendfunction LibA:__construct( data ) self.name = 'name--&gt;' .. data.name self.sex = 'sex--&gt;' .. data.sexendreturn LibA 代码释意： Class(&quot;LibA&quot;) 声明一个 Vanilla 类，类名为 LibA LibA:__construct( data ) 提供了一个类 LibA 的构造器，并对相应的属性进行初始化 类使用 123local LibA = LoadLibrary('aa')local liba_instance = LibA(&#123;name='idevz',sex='man'&#125;)print_r(liba_instance.sex) 执行结果 sex--&gt;man 代码释意：（类使用的时候需要注意，类的使用分为类文件的加载 Load( 如这里的 LoadLibrary ) 和实例化 LibA()） 两个步骤 local LibA = LoadLibrary(&#39;aa&#39;) 载入类名为 LibA 的类 local liba_instance = LibA({name=&#39;idevz&#39;,sex=&#39;man&#39;}) 传入表 {name=&#39;idevz&#39;,sex=&#39;man&#39;} 对类进行相关的实例化 liba_instance.sex 是对实例属性的引用 注：载入和实例化也可以一步达成 local liba_instance = LoadLibrary(&#39;aa&#39;)({name=&#39;idevz&#39;,sex=&#39;man&#39;}) 类继承 下面我么定义一个类 LibB，并使之集成于 LibA 类定义 123456789local LibB = Class(\"LibB\", LoadLibrary('LibA'))function LibB:__construct( data ) local data = data or &#123;name='kk', sex='xxx'&#125; data.sex = data.sex .. '--&gt;son' self.parent:__construct(data)endreturn LibB 代码释意： Class(&quot;LibB&quot;, LoadLibrary(&#39;LibA&#39;)) 声明一个 Vanilla 类，类名为 LibB 继承自类 LibA self.parent:__construct(data) 构造器中调用父类的构造器 类使用 123local LibB = LoadLibrary('LibB')local libb_instance = LibB(&#123;name='idevz',sex='man'&#125;)print_r(libb_instance:idevzDo(&#123;doo='xxx'&#125;)['doo']) 执行结果 xxx 代码释意： libb_instance:idevzDo 调用父类的 idevzDo 方法 4.3、Vanilla 包开发4.3.1、Vanilla 的包开发可以使用任意 LUA 包的开发方式来开发 Vanilla 包（Controllers，Library，Dao，Services等），也可以使用 Vanilla 所提供的 (面向对象) 方式进行开发 对 Controller 使用继承和构造器 下面我们看一个例子： 12345678local IndexController = Class('controllers.index', LoadApplication('controllers.base'))function IndexController:__construct() self.parent:__construct()endreturn IndexController 5、OpenResty5.1、OR文档精炼OR文档精炼 感谢春哥给我们带来这么好的平台，在这里希望能通读 OR 文档，把自己的理解记录下来，并与时俱进的更新 5.1.1、描述 / Descriptionlua-nginx-module 模块通过标准的 Lua 5.1 解释器，或者 LuaJIT 2.0/2.1 在 Nginx 运行环境中嵌入 Lua，并利用 Nginx 的子请求，允许在 Nginx 的时间模块中集成强大的 Lua 线程（Lua 协程）。 与 Apache 的 mod_lua 和 Lighttpd 的 mod_magnet 不同的是，只要使用 lua-nginx-module 模块为 Lua 提供的 Nginx API 来处理上游服务的请求，诸如 MySQL、PostgreSQL、Memcached、Redis 或者上游的 HTTP Web 服务，网络传输都是 100% 非阻塞的。 至少下面列举的这些 Lua 包，和 Nginx 模块可以与 ngx_lua 模块完美结合使用： 5.1.2、ngx.timer ngx.timer.at 语法： ok, err = ngx.timer.at(delay, callback, user_arg1, user_arg2, ...) 上下文： init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* 使用一个自定义函数以及可选的自定义参数创建一个 Nginx 计时器 第一个参数 delay 以秒为单位指定计时器的延迟时间，支持分秒设置，比如 0.001 在这里表示 1 毫秒延迟。delay 同样可以设置为 0 ，此时如果当前句柄正被唤醒则计时器将立即获得执行。（in which case the timer will immediately expire when the current handler yields execution.//TODO yields） 第二个参数 callback 可以是任何 Lua 函数，后期延迟时间到了，该函数将被以一个后台 “轻线程” 的形式被调用。这个自定义的回调函数将被 Nginx 核心使用 premature 参数、user_arg1、user_arg2 等参数自动调用，参数 premature 是一个 boolean 值，表示当前定时器是否过期以后，而 user_arg1、user_arg2 等参数就是调用 ngx.timer.at 时所传递的余下参数列表。 当 Nginx 工作进程尝试关闭，比如在 Nginx 由于收到 HUP 信号而触发了 Nginx 配置重载的时候，或者 Nginx 服务正在关闭的时候，将会出现无效的计时器（//TODO Premature timer）。当 Nginx 工作进程尝试关闭，将无法通过调用 ngx.timer.at 来创建一个新的非零延迟的计时器，并且此时 ngx.timer.at 将返回 nil 和 “process exiting” 错误。 这个 API 从 v0.9.3 版本开始，即使 Nginx 工作进程开始关闭的时候，仍然允许创建零延迟计时器。 当一个计时器到期时，计时器中用户定义回调的 Lua 代码将在一个与创建这个计时器的源请求完全隔离的 “轻线程” 中运行，所以，源请求生命周期内的对象，比如 cosockets 并不能与回调函数共享。 下面来看一个简单的例子： 1234567891011121314151617location / &#123; ... log_by_lua_block &#123; local function push_data(premature, uri, args, status) -- push the data uri, args, and status to the remote -- via ngx.socket.tcp or ngx.socket.udp -- (one may want to buffer the data in Lua a bit to -- save I/O operations) end local ok, err = ngx.timer.at(0, push_data, ngx.var.uri, ngx.var.args, ngx.header.status) if not ok then ngx.log(ngx.ERR, \"failed to create timer: \", err) return end &#125;&#125; 还可以创建一个无限执行的计时器，例如，一个每 5 秒触发执行一次的计时器，在它的回调方法中递归的调用 ngx.timer.at ，这里给出这样的一个例子。 12345678910111213141516171819local delay = 5local handlerhandler = function (premature) -- do some routine job in Lua just like a cron job if premature then return end local ok, err = ngx.timer.at(delay, handler) if not ok then ngx.log(ngx.ERR, \"failed to create the timer: \", err) return endendlocal ok, err = ngx.timer.at(delay, handler)if not ok then ngx.log(ngx.ERR, \"failed to create the timer: \", err) returnend 因为定时器的回调函数都是运行在后端，而且他们的运行时间不会叠加到客户端请求的相应时间中，它们可能会因为 Lua 语法错误，或者过多的客户端请求而很容易在服务端造成累积，或者耗尽系统资源。为了防止出现像 Nginx 服务器宕机这种极端结果，在一个 Nginx 工作进程中提供了对 “等待中的计时器” 和 “运行中的计时器” 这两种计时器的数量限制。这里 “等待中的计时器” 是指还没有过期的计时器，而 “运行中的计时器” 是指那些用户回调方法当前正在运行的计时器。 一个 Nginx 进程中所允许的 “等待中的计时器” 允许的最大数量由 lua_max_pending_timers 指令控制。而允许的 “运行中的计时器” 允许的最大数量由 lua_max_running_timers 指令控制。 目前的实现，每个 “运行中的计时器” 都会从 nginx.conf 配置中 worker_connections 指令配置的全局连接列表中占用一个 （虚） 连接记录，所以必须确保 worker_connections 指令设置了一个足够大的值能同时包含真正的连接数和计时器回调函数运行所需要的虚连接数（这个连接数是有 lua_max_running_timers 指令设限的）。 许多 Nginx 的 Lua API 能在计时器回调函数的上下文中使用，比如操作流和数据包的 cosockets API（ngx.socket.tcp 和 ngx.socket.udp），共享内存字典（ngx.shared.DICT），用户协程函数（coroutine.*），用户“轻线程”（ngx.thread.*），ngx.exit，ngx.now/ngx.time，ngx.md5/ngx.sha1_bin等都是可用的，但是相关子请求的 API （诸如ngx.location.capture），ngx.req.* API，下游输出 API （诸如 ngx.say，ngx.print 和 ngx.flush）都是明确在此上下文中不支持的。 你可以给计时器的回调函数传递大部分的标准 Lua 值类型（nils、布尔、数字、字符串、表、闭包、文件句柄等），要么显示的使用用户参数或者隐式的使用回调函数闭包的上游值。然而有一些例外诸如：你不能传递任何由 coroutine.create 和 ngx.thread.spawn 返回的线程对象，或者任何由 ngx.socket.tcp、ngx.socket.udp 和 ngx.req.socket 返回的 cosocket 对象，因为这些对象的生命周期是与创建他们的请求上下文绑定的，而计时器的回调函数（设计时）是与创建他们的请求上下文分离的，并且运行在它自己的（虚）请求上下文中。如果你试图跨越创建这些线程和 cosocket 的请求上下文边界来共享这些线程和 cosocket 对象，将会报错，对线程将报错 no co ctx found，对 cosocket 将报错 bad request，然而在计时器回调函数内部来创建这些对象则是没问题的。 这个 API 在 v0.8.0 版本第一次释出。 ngx.timer.running_count 语法： count = ngx.timer.running_count() 上下文： init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* 返回当前正在运行的计时器数量。这个指令在 v0.9.20 版本第一次释出。 ngx.timer.pending_count 语法： count = ngx.timer.pending_count() 上下文： init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* 返回当前正在等待的计时器数量。这个指令在 v0.9.20 版本第一次释出。 5.1.3、ngx.config ngx.config.subsystem 语法： subsystem = ngx.config.subsystem 上下文： set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua* 这个字符串字段表示了当前基于哪个 Nginx 子系统，对当前模块（ngx_stream_lua_module），这个字段始终返回 “http”，而对 ngx_stream_lua_module 模块，这个字段将返回 “stream” 这个字段在 v0.10.1 版本第一次释出。 ngx.config.debug 语法： debug = ngx.config.debug 上下文： set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua* *这个布尔字段表示了当前 Nginx 是否打开 debug 编译选项，如编译时配置为 ./configure option --with-debug。 这个字段在 v0.8.7 版本第一次释出。 5.1.4、coroutine coroutine.create 语法： co = coroutine.create(f) 上下文： rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua* 使用 Lua 函数创建一个用户态 Lua 协程， 并返回一个协程对象。与标准 Lua 中的协程创建的 API coroutine.create 类似，但是工作在 ngx_lua 模块创建的 Lua 协程上下文中，这个 API 第一次是被使用在 0.9.2 版本的 `init_by_lua` 上下文中。* 这个 API 在 v0.6.0 版本第一次释出。 5.1.5、ngx.thread ngx.config.subsystem 语法： co = ngx.thread.spawn(func, arg1, arg2, ...) 上下文： rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua* 使用 Lua 函数 func 以及可选的参数 arg1，arg2 等生成一个新的用户“轻线程”，返回一个 Lua 线程（或者 Lua 协程）对象代表这个 “轻线程”“轻线程”仅仅是一种特殊的由 ngx_lua 模块来调度的 Lua 协程。在 ngx.thread.spawn 返回之前， func 函数将会被使用响应的可选参数进行调用，直到此函数调用返回、或者因为错误而终止或是因为通过使用 Nginx 的 I/O 操作 API 导致请求挂起（如 tcpsock:receive 操作）。在 ngx.thread.spawn 返回后，新被创建的“轻线程”将在各种 I/O 事件中保持通常的异步运行。 所有在 rewrite_by_lua、access_by_lua 和 content_by_lua 运行的 Lua 代码块都在一个由 ngx_lua 自动创建的样板“轻线程”中，这些样板“轻线程”通常又叫“入口线程”。 默认情况下，相应的 Nginx 处理程序（例如 rewrite_by_lua 处理程序）不会终止直到“入口线程”和所有的用户“轻线程”都终止，一个“轻线程（要么是“入口线程”要么是“用户轻线程”因为调用 ngx.exit，ngx.exec，ngx.redirect 或者 ngx.req.set_uri(uri, true)）或者“入口线程”因为报错而终止。当一个用户“轻线程”因为报错而终止，他将不会像“入口线程”一样终止其他线程的运行。 因为 Nginx 子请求模块的限制，一般不允许中止一个正在运行中的 Nginx 子请求。所以同样禁止中止一个运行中的正在等待一个或多个 Nginx 子请求的“轻线程”。你应该调用 ngx.thread.wait 来在结束前等待这些“轻线程”结束。这里有个值得注意的例外是你可以通过使用而且只能使用 ngx.ERROR(-1),408,444或者499 状态调用 ngx.exit 来中止等待的子请求。 “轻线程”不是使用预先抢占的方式来调度的，换句话说，没有自动执行的时间片，一个“轻线程”将保持在 CPU 运行，直到一个（非阻塞）I/O 操作在一个单线程运行不能被完成。 The “light threads” are not scheduled in a pre-emptive way. In other words, no time-slicing is performed automatically. A “light thread” will keep running exclusively on the CPU untila (nonblocking) I/O operation cannot be completed in a single run,it calls coroutine.yield to actively give up execution, orit is aborted by a Lua error or an invocation of ngx.exit, ngx.exec, ngx.redirect, or ngx.req.set_uri(uri, true).For the first two cases, the “light thread” will usually be resumed later by the ngx_lua scheduler unless a “stop-the-world” event happens. User “light threads” can create “light threads” themselves. And normal user coroutines created by coroutine.create can also create “light threads”. The coroutine (be it a normal Lua coroutine or a “light thread”) that directly spawns the “light thread” is called the “parent coroutine” for the “light thread” newly spawned. The “parent coroutine” can call ngx.thread.wait to wait on the termination of its child “light thread”. You can call coroutine.status() and coroutine.yield() on the “light thread” coroutines. The status of the “light thread” coroutine can be “zombie” if the current “light thread” already terminates (either successfully or with an error),its parent coroutine is still alive, andits parent coroutine is not waiting on it with ngx.thread.wait.The following example demonstrates the use of coroutine.yield() in the “light thread” coroutines to do manual time-slicing: 6、Vanilla Change log6.1、0.1.0-rc36.1.1、创建应用12345678vanilla new app_namecd app_namevanilla start [--trace] -- 默认运行在development环境## 在linux的bash环境下：VA_ENV=production vanilla start [--trace] -- 运行在生产环境## 在BSD等tcsh环境下：setenv VA_ENV production;vanilla start [--trace] -- 运行在生产环境 6.1.2、代码目录结构1234567891011121314151617181920212223242526272829303132333435363738 /Users/zj-git/app_name/ tree ././├── application（应用代码主体目录）│ ├── bootstrap.lua（应用初始化 / 可选&lt;以下未标可选为必选&gt;）│ ├── controllers(应用业务代码主体目录)│ │ ├── error.lua（应用业务错误处理，处理本路径下相应业务报错）│ │ └── index.lua（hello world示例）│ ├── library（应用本地类包）│ ├── models（应用数据处理类）│ │ ├── dao（数据层业务处理）│ │ │ └── table.lua│ │ └── service（服务化业务处理，对DAO的再次封装）│ │ └── user.lua│ ├── nginx（*Openresty所封装Nginx请求处理各Phase）│ │ └── init.lua（*init_by_lua示例）│ ├── plugins（插件目录）│ └── views（视图层，与controllers一一对应）│ ├── error（错误模板）│ │ └── error.html│ └── index（index controller模板）│ └── index.html├── config（应用配置目录）│ ├── application.lua（应用基础配置 / 路由器、初始化等设置）│ ├── errors.lua（应用错误信息配置）│ ├── nginx.conf（nginx配置文件模板）│ ├── nginx.lua（服务各种运行环境配置 / 是否开启lua_code_cache等）│ ├── waf-regs（应用防火墙规则配置目录）│ │ ├── args│ │ ├── cookie│ │ ├── post│ │ ├── url│ │ ├── user-agent│ │ └── whiteurl│ └── waf.lua（服务防火墙配置）├── logs（日志目录）│ └── hack（攻击日志目录 / 保持可写权限）├── pub（应用Nginx配置根路径） └── index.lua（应用请求入口） 6.1.3、业务代码示例 IndexController123456789101112local IndexController = &#123;&#125;function IndexController:index() local view = self:getView() local p = &#123;&#125; p['vanilla'] = 'Welcome To Vanilla...' p['zhoujing'] = 'Power by Openresty' view:assign(p) return view:display()endreturn IndexController 6.1.4、模板示例 views/index/index.html1234567&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt; &lt;img src=\"http://m1.sinaimg.cn/maxwidth.300/m1.sinaimg.cn/120d7329960e19cf073f264751e8d959_2043_2241.png\"&gt; &lt;h1&gt;&lt;a href = 'https://github.com/idevz/vanilla'&gt;&#123;&#123;vanilla&#125;&#125;&lt;/a&gt;&lt;/h1&gt;&lt;h5&gt;&#123;&#123;zhoujing&#125;&#125;&lt;/h5&gt;&lt;/body&gt;&lt;/html&gt; 6.2、0.1.0-rc40_1_rc4 的安装使用与 0_1_rc3 没有本质区别，相关内容见 6.3、0.1.0-rc56.3.1、安装 通过 ./setup-framework 脚本安装 Vanilla ./setup-framework 脚本是对 make install 后面安装方式一个自动化封装，仅需要指定 OpenResty 的安装路径，即可简单安装 Vanilla 12345./setup-framework -hUsage: ./setup-framework -h show this help info -v VANILLA_PROJ_ROOT, vanilla project root, will contain vanilla framework and apps -o OPENRESTY_ROOT, openresty install path(openresty root) ./setup-framework 脚本参数选项说明： -v ： 指定 Vanilla 项目的根目录，此选项默认为 /data/vanilla，默认则将 Vanilla 安装到 /data/vanilla/framework/0_1_0_rc5/vanilla/ 目录下。 -o ： 指定 OpenResty 的安装目录， 此选项默认为 /usr/local/openresty， 如果你的 OpenResty 安装路径与此不同，则需要指定为正真的 OpenResty 安装目录。 安装目录结构如下： 12345tree /data/vanilla -L 2/data/vanilla├── framework│ ├── 0_1_0_rc5│ └── 0_1_0_rc5.old_2016_04_12_11_04_18 # 重复安装则会将之前的老版本按照时间自动备份 通过 make install 安装 Vanilla Vanilla 支持的选项都提供了默认值，如果你的环境与默认值不一样，请configure时指定成你自己的。 特别注意选项 --openresty-path ，默认为 /usr/local/openresty ，请确保设置正确。 可以在源码目录下执行 configure --help 来查看安装选项的使用方法。 下面是一个简单的安装示例： 123./configure --prefix=/usr/local/vanilla --openresty-path=/usr/local/openrestymake install （不需要make，直接make install） 6.3.2、Vanilla 使用 Vanilla命令 Vanilla-V0.1.0-rc5 目前依旧提供两个命令， 但是 rc5 以后提供的命令与安装的框架代码一样，都自动携带版本号，vanilla-0.1.0.rc5，和 v-console-0.1.0.rc5 这样做的好处在于方便多版本共存以及 Vanilla 的无痛升级* vanilla-0.1.0.rc5 用来初始化应用骨架，而 vanilla-0.1.0.rc5 之后，服务的停启不再通过 vanilla-0.1.0.rc5 命令管理，而是通过项目路径下面的 va-appname-service 脚本进行管理，使用细节见后面说明。 v-console-0.1.0.rc5 是一个交互式命令行，主要提供一种方便学习Lua入门的工具，可以使用一些 vanilla 开发环境下的包，比如table输出的 lprint_r 方法等。 创建应用 1234vanilla-0.1.0.rc5 new app_full_path #使用 vanilla-0.1.0.rc5 命令 自动生成应用骨架，注意这里需要传递应用的全路径，而不只是一个APP_NAMEchmod +x app_full_path/va-appname-service #给生成的项目骨架根目录下面的 va-appname-service 脚本添加执行权限app_full_path/va-appname-service initconf [dev] #初始化应用的nginx配置文件，此文件基于 app_full_path/nginx_conf 下面的配置文件生成，如果有特殊选项需要配置，可以先修改 app_full_path/nginx_conf 下面的配置文件，再进行 initconf 操作，[dev] 参数为可选项， 加上则表示执行开发环境相关操作，不加则默认为生产环境app_full_path/va-appname-service start [dev] #启动生成的服务，即可通过http://localhost访问服务，[dev] 参数如上。 上面创建应用的过程也可以通过脚本 ./setup-vanilal-demoapp 简单自动完成： 123456./setup-vanilal-demoapp -hUsage: ./setup-vanilal-demoapp -h show this help info -a VANILLA_APP_ROOT, app absolute path(which path to init app) -u VANILLA_APP_USER, user to run app -g VANILLA_APP_GROUP, user group to run app -e VANILLA_RUNNING_ENV, app running environment ./setup-vanilal-demoapp 脚本参数选项说明： -a ： 指定初始化应用的全路径（绝对路径），默认为 /data/vanilla/vademo -u ： 指定运行服务的用户名，默认为 idevz -g ： 指定运行服务的用户组，默认为 sina -e ： 指定运行服务的环境，默认为’’ 指生产环境 安装目录结构如下： 12345tree /data/vanilla/ -L 1/data/vanilla/├── framework # vanilla 框架安装目录├── vademo # 应用初始化目录└── vademo.old_2016_04_12_11_04_26 # 重复安装后会将之前版本按照时间进行备份 应用配置初始化与服务管理 通过脚本 /data/vanilla/vademo/va-vademo-service 管理 vademo 服务 12/data/vanilla/vademo/va-vademo-service -hUsage: ./va-ok-service &#123;start|stop|restart|reload|force-reload|confinit[-f]|configtest&#125; [dev] #dev 指定了运行的环境，不加 dev 则默认为生产环境。 注意： 如果没有使用 ./setup-vanilal-demoapp 脚本，而是手动 new 的 app， 则在启动服务之前需要先运行 /data/vanilla/vademo/va-vademo-service initconf [dev] 对相应环境的 nginx 配置文件进行初始化。 6.3.3、工程化的vanilla-0.1.0.rc5vanilla-0.1.0.rc5是vanilla-0.1.0.rc4在新浪移动全线推广过程中针对一些工程化部署问题改进版本，可以肯定的一点vanilla-0.1.0.rc4在功能、扩展性、使用方面表现良好，非常适合移动业务的场景，更不止于API，但是在集群部署、多App部署、Vanilla框架升级等方面vanilla-0.1.0.rc4存在短板，而vanilla-0.1.0.rc5极大程度的弥补了这些短板。 推荐始终使用最新版的Vanilla 当前Vanilla最新版本0.1.0.rc5，支持命令： vanilla-0.1.0.rc5（你没看错，自0.1.0.rc5起，vanilla的命令行和框架代码都带着版本号，方便多版本共存，也方便框架升级） v-console-0.1.0.rc5 6.3.4、如何从vanilla-0.1.0.rc4到vanilla-0.1.0.rc5升级步骤 安装最新的 vanilla-0.1.0.rc5 1234$ wget https://github.com/idevz/vanilla/archive/v0.1.0-rc5.0.tar.gz$ tar zxf v0.1.0-rc5.0.tar.gz$ cd vanilla-0.1.0.rc5$ ./setup-framework -v $VANILLA_PROJ_ROOT -o $OPENRESTY_ROOT #$VANILLA_PROJ_ROOT 为给 Vanilla 指定的安装目录， $OPENRESTY_ROOT 是当前 OpenResty 的安装目录 基于新的 Vanilla（vanilla-0.1.0.rc5） 初始化新版的 vatest 项目： 1$ sudo vanilla-0.1.0.rc5 new $VANILLA_APP_ROOT #$VANILLA_APP_ROOT 为新版 vatest 项目全路径 将新项目中的以下目录及文件直接覆盖至老版 vatest 的相关位置： pub/index.lua 文件（$VANILLA_APP_ROOT/pub/index.lua）直接覆盖 va-vasina-service 脚本（$VANILLA_APP_ROOT/va-vasina-service）直接复制，因为老版没有这个文件 注意确认脚本中 $OPENRESTY_NGINX_ROOT 的路径 注意确认脚本中 $VA_APP_PATH 的路径是否为项目的根路径 nginx_conf 目录（$VANILLA_APP_ROOT/nginx_conf）直接复制，因为老版没有这个目录 application/bootstrap.lua 文件（$VANILLA_APP_ROOT/application/bootstrap.lua）将老项目 bootstrap 中的相关 init* 方法拷贝到新的 bootstrap.lua 中，并用新的 bootstrap.lua 覆盖老版的 bootstrap.lua 文件 修改 $VANILLA_APP_ROOT/nginx_conf 中的 nginx 配置文件， 确保其中各种目录正确 确保 $VANILLA_APP_ROOT/nginx_conf/va-nginx{-development}.conf 文件中 lua_package_{c}path 中， 全路径的 Vanilla 框架目录正确 确保 $VANILLA_APP_ROOT/nginx_conf/{dev_}vhost/vasina.conf 文件中 Server 段的 root 配置为项目根目录， require 方法中 local VANILLA_ROOT 为框架根路径 使用 $VANILLA_APP_ROOT/va-vasina-service 脚本管理服务： 给 $VANILLA_APP_ROOT/va-vasina-service 脚本添加可执行权限 chmod +x $VANILLA_APP_ROOT/va-vasina-service 初始化 nginx 配置 $VANILLA_APP_ROOT/va-vasina-service initconf [dev] 启动服务 $VANILLA_APP_ROOT/va-vasina-service start [dev] 注： 添加 dev 参数，则管理 development 环境的服务， 默认为 production 生产环境服务 6.4、0.1.0-rc66.5、0.1.0-rc7 Add lemplate 模板引擎 Add dynamic dns for lib.http 7、Nginx执行阶段我的理解Openresty = Nginx + ngx_http_lua_module + lua_resty_* ；它是一个原生Nginx合上一个HTTP_LUA模块，在加上一系列Lua_resty模块组成的一个Ngx_Lua高性能服务生态。 7.1、Openresty处理HTTP请求的执行阶段Openrestry处理HTTP请求的执行阶段来自于Nginx，Nginx的HTTP框架依据常见的处理流程将处理阶段划分为11个阶段，其中每个处理阶段可以由任意多个HTTP模块流水式地处理请求，Openresty通过ngx_http_lua_module将Lua特性嵌入Nginx，ngx_http_lua_module属于一个Nginx的HTTP模块，为高性能服务开发封装了7个相应HTTP请求处理阶段如下： set_by_lua content_by_lua rewrite_by_lua access_by_lua header_filter_by_lua body_filter_by_lua log_by_lua 有同学会发现，Openresty所提供的LUA解析指令还有以下两个： init_by_lua init_worker_by_lua init_by_lua 作用在配置加载阶段，init_worker_by_lua作用在worker进程初始化阶段，并非HTTP请求处理阶段。 另外，需要重点提一下的是，Nginx输出过滤器是流式处理模型，一个数据块body filter就被调用一次。可以用以下简单的例子测试验证： nginx.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546http &#123; # use sendfile sendfile on; # Va initialization lua_package_path \"...;;\"; lua_package_cpath \"...;\"; lua_code_cache off; init_by_lua_block &#123;ngx.log(ngx.ERR, '=======&gt;init')&#125; init_worker_by_lua_block &#123;ngx.log(ngx.ERR, '=======&gt;init_worker')&#125; rewrite_by_lua_block &#123;ngx.log(ngx.ERR, '=======&gt;rewrite')&#125; access_by_lua_block &#123;ngx.log(ngx.ERR, '=======&gt;access')&#125; header_filter_by_lua_block &#123;ngx.log(ngx.ERR, '=======&gt;header_filter')&#125; body_filter_by_lua_block &#123;ngx.log(ngx.ERR, '=======&gt;body_filter')&#125; log_by_lua_block &#123;ngx.log(ngx.ERR, '=======&gt;log')&#125; server &#123; # List port listen 7200; set $template_root ''; set_by_lua_block $a &#123;ngx.log(ngx.ERR, '=======&gt;set'); return 'xxx'&#125; # Access log with buffer, or disable it completetely if unneeded access_log logs/development-access.log combined buffer=16k; # access_log off; # Error log error_log logs/development-error.log; # Va runtime location / &#123; content_by_lua_block &#123; ngx.log(ngx.ERR, '=======&gt;content') ngx.say('----------') ngx.say('---ccc-------') ngx.say('---vvvv-------') ngx.say('---vdddv-------') ngx.say('---ggvv-------') &#125; # content_by_lua_file ./pub/index.lua; &#125; &#125;&#125; logs/development-error.log截取 123456789101112set_by_lua:1: =======&gt;setrewrite_by_lua(development-nginx.conf:31):1: =======&gt;rewriteaccess_by_lua(development-nginx.conf:32):1: =======&gt;accesscontent_by_lua(development-nginx.conf:60):2: =======&gt;contentheader_filter_by_lua:1: =======&gt;header_filterbody_filter_by_lua:1: =======&gt;body_filterbody_filter_by_lua:1: =======&gt;body_filterbody_filter_by_lua:1: =======&gt;body_filterbody_filter_by_lua:1: =======&gt;body_filterbody_filter_by_lua:1: =======&gt;body_filterbody_filter_by_lua:1: =======&gt;body_filterlog_by_lua(development-nginx.conf:35):1: =======&gt;log while logging request 可以看出body_filter的执行次数等于ngx.say数量加一 8、GDB 调试 OpenResty8.1、使用 GDB 调试 Nginx1sudo gdb -q -tui # -q 安静模式启动 GDB -tui 显示代码界面 进入 GDB 运行 attach Nginx 子进程报错如下：issing separate debuginfos, use: debuginfo-install libgcc-4.8.5-4.el7.x86_64 zlib-1.2.7-17.el7.x86_64直接安装即可 8.2、断点 ngx_process_events_and_timers子进程即 worker 进程在运行后会停留在epoll_wait 处等待相应的事件发生，而这个函数调用被封装在 ngx_process_events_and_timers 中 123456789101112131415161718192021222324252627282930313233343536373839401 breakpoint keep y 0x000000000046c8f0 in ngx_process_events_and_timers at src/event/ngx_event.c:195 breakpoint already hit 39 times2 breakpoint keep y 0x000000000046c93e in ngx_process_events_and_timers at src/event/ngx_event.c:242 breakpoint already hit 36 times3 breakpoint keep y 0x000000000046c95a in ngx_process_events_and_timers at src/event/ngx_event.c:249 breakpoint already hit 35 times4 breakpoint keep y 0x000000000046ce7d in ngx_event_process_posted at src/event/ngx_event_posted.c:335 breakpoint keep y 0x0000000000475c24 in ngx_epoll_process_events at src/event/modules/ngx_epoll_module.c:793 breakpoint already hit 25 times6 breakpoint keep y 0x0000000000475d28 in ngx_epoll_process_events at src/event/modules/ngx_epoll_module.c:9267 breakpoint keep y 0x0000000000476022 in ngx_epoll_process_events at src/event/modules/ngx_epoll_module.c:900 breakpoint already hit 28 times8 breakpoint keep y 0x000000000048cd4a in ngx_http_wait_request_handler at src/http/ngx_http_request.c:497 breakpoint already hit 6 times9 breakpoint keep y 0x000000000048cd6a in ngx_http_wait_request_handler at src/http/ngx_http_request.c:504 breakpoint already hit 7 times10 breakpoint keep y 0x000000000048c900 in ngx_http_process_request_line at src/http/ngx_http_request.c:945 breakpoint already hit 6 times11 breakpoint keep y 0x000000000048c912 in ngx_http_process_request_line at src/http/ngx_http_request.c:952 breakpoint already hit 6 times12 breakpoint keep y 0x000000000048ca95 in ngx_http_process_request_line at src/http/ngx_http_request.c:101113 breakpoint keep y 0x000000000048cbce in ngx_http_process_request_line at src/http/ngx_http_request.c:1027 breakpoint already hit 6 times14 breakpoint keep y 0x000000000048c5ef in ngx_http_process_request_headers at src/http/ngx_http_request.c:1322 breakpoint already hit 7 times15 breakpoint keep y 0x000000000048c7ed in ngx_http_process_request_headers at src/http/ngx_http_request.c:1342 breakpoint already hit 2 times16 breakpoint keep y 0x000000000048c826 in ngx_http_process_request_headers at src/http/ngx_http_request.c:1348 breakpoint already hit 2 times17 breakpoint keep y 0x000000000048c231 in ngx_http_process_request at src/http/ngx_http_request.c:1916 breakpoint already hit 2 times18 breakpoint keep y 0x0000000000480757 in ngx_http_handler at src/http/ngx_http_core_module.c:839 breakpoint already hit 2 times19 breakpoint keep y 0x0000000000484ced in ngx_http_core_rewrite_phase at src/http/ngx_http_core_module.c:91020 breakpoint keep y 0x0000000000485e60 in ngx_http_core_content_phase at src/http/ngx_http_core_module.c:1372 breakpoint already hit 1 time21 breakpoint keep y 0x0000000000485eac in ngx_http_core_content_phase at src/http/ngx_http_core_module.c:138622 breakpoint keep y 0x0000000000485e7d in ngx_http_core_content_phase at src/http/ngx_http_core_module.c:1379 breakpoint already hit 1 time23 breakpoint keep y 0x0000000000504c19 in ngx_http_lua_content_handler at ../ngx_lua-0.10.6/src/ngx_http_lua_contentby.c:222 8.3、Lua 请求处理8.3.1、堆栈12345678910111213141516171819202122232425262728293031320 __libc_writev (fd=3, vector=0x7ffe08245dd0, count=14) at ../sysdeps/unix/sysv/linux/writev.c:681 0x00000000004717e9 in ngx_writev (c=c@entry=0x7ff03d02f730, vec=vec@entry=0x7ffe08245db0) at src/os/unix/ngx_writev_chain.c:1892 0x0000000000476a7e in ngx_linux_sendfile_chain (c=0x7ff03d02f730, in=0x7ff03d001418, limit=2147479551) at src/os/unix/ngx_linux_sendfile_chain.c:2153 0x00000000004a7d15 in ngx_http_write_filter (r=0x7ff03cfffcf0, in=0x7ff03d001b78) at src/http/ngx_http_write_filter_module.c:2544 0x00000000004a909d in ngx_http_chunked_body_filter (r=0x7ff03cfffcf0, in=&lt;optimized out&gt;) at src/http/modules/ngx_http_chunked_filter_module.c:2245 0x00000000004ac7dc in ngx_http_gzip_body_filter (r=0x7ff03cfffcf0, in=0x7ffe082466d0) at src/http/modules/ngx_http_gzip_filter_module.c:3266 0x00000000004afd95 in ngx_http_ssi_body_filter (r=0x7ff03cfffcf0, in=&lt;optimized out&gt;) at src/http/modules/ngx_http_ssi_filter_module.c:4117 0x00000000004b2cf0 in ngx_http_charset_body_filter (r=0x7ff03cfffcf0, in=0x7ffe082466d0) at src/http/modules/ngx_http_charset_filter_module.c:6478 0x0000000000506c7c in ngx_http_lua_capture_body_filter (r=0x7ff03cfffcf0, in=0x7ffe082466d0) at ../ngx_lua-0.10.6/src/ngx_http_lua_capturefilter.c:1339 0x0000000000453395 in ngx_output_chain (ctx=ctx@entry=0x7ff03d001428, in=in@entry=0x7ffe082466d0) at src/core/ngx_output_chain.c:7410 0x00000000004b4f95 in ngx_http_copy_filter (r=0x7ff03cfffcf0, in=0x7ffe082466d0) at src/http/ngx_http_copy_filter_module.c:15211 0x0000000000485a37 in ngx_http_output_filter (r=r@entry=0x7ff03cfffcf0, in=in@entry=0x7ffe082466d0) at src/http/ngx_http_core_module.c:197912 0x0000000000489e33 in ngx_http_send_special (r=r@entry=0x7ff03cfffcf0, flags=flags@entry=1) at src/http/ngx_http_request.c:335813 0x00000000004ffc38 in ngx_http_lua_send_special (flags=1, r=0x7ff03cfffcf0) at ../ngx_lua-0.10.6/src/ngx_http_lua_util.c:56914 ngx_http_lua_send_chain_link (r=0x7ff03cfffcf0, ctx=&lt;optimized out&gt;, in=0x0) at ../ngx_lua-0.10.6/src/ngx_http_lua_util.c:52315 0x0000000000501f5f in ngx_http_lua_run_thread (L=L@entry=0x40030378, r=r@entry=0x7ff03cfffcf0, ctx=ctx@entry=0x7ff03d000dc8, nrets=nrets@entry=0) at ../ngx_lua-0.10.6/src/ngx_http_lua_util.c:147616 0x00000000005050f0 in ngx_http_lua_content_by_chunk (L=L@entry=0x40030378, r=r@entry=0x7ff03cfffcf0) at ../ngx_lua-0.10.6/src/ngx_http_lua_contentby.c:12017 0x000000000050548d in ngx_http_lua_content_handler_file (r=0x7ff03cfffcf0) at ../ngx_lua-0.10.6/src/ngx_http_lua_contentby.c:28418 0x0000000000504c21 in ngx_http_lua_content_handler (r=0x7ff03cfffcf0) at ../ngx_lua-0.10.6/src/ngx_http_lua_contentby.c:22219 0x0000000000485e7f in ngx_http_core_content_phase (r=0x7ff03cfffcf0, ph=&lt;optimized out&gt;) at src/http/ngx_http_core_module.c:137920 0x0000000000480675 in ngx_http_core_run_phases (r=r@entry=0x7ff03cfffcf0) at src/http/ngx_http_core_module.c:85621 0x000000000048075c in ngx_http_handler (r=r@entry=0x7ff03cfffcf0) at src/http/ngx_http_core_module.c:83922 0x000000000048c249 in ngx_http_process_request (r=0x7ff03cfffcf0) at src/http/ngx_http_request.c:191623 0x000000000048cbf6 in ngx_http_process_request_line (rev=0x7ff03d069520) at src/http/ngx_http_request.c:102724 0x0000000000476029 in ngx_epoll_process_events (cycle=0x7ff03cffbce0, timer=&lt;optimized out&gt;, flags=&lt;optimized out&gt;) at src/event/modules/ngx_epoll_module.c:90025 0x000000000046c947 in ngx_process_events_and_timers (cycle=cycle@entry=0x7ff03cffbce0) at src/event/ngx_event.c:24226 0x0000000000473d35 in ngx_worker_process_cycle (cycle=cycle@entry=0x7ff03cffbce0, data=data@entry=0x0) at src/os/unix/ngx_process_cycle.c:75327 0x0000000000472820 in ngx_spawn_process (cycle=cycle@entry=0x7ff03cffbce0, proc=0x473cf0 &lt;ngx_worker_process_cycle&gt;, data=0x0, name=0x6e22f5 &quot;worker process&quot;, respawn=respawn@entry=0) at src/os/unix/ngx_process.c:19828 0x0000000000475216 in ngx_reap_children (cycle=0x7ff03cffbce0) at src/os/unix/ngx_process_cycle.c:62129 ngx_master_process_cycle (cycle=cycle@entry=0x7ff03cffbce0) at src/os/unix/ngx_process_cycle.c:17430 0x000000000044e139 in main (argc=&lt;optimized out&gt;, argv=&lt;optimized out&gt;) at src/core/nginx.c:367 8.3.2、断点1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768691 breakpoint keep y 0x000000000048c420 in ngx_http_process_request_headers at src/http/ngx_http_request.c:1185 breakpoint already hit 13 times2 breakpoint keep y 0x0000000000504ba0 in ngx_http_lua_content_handler at ../ngx_lua-0.10.6/src/ngx_http_lua_contentby.c:154 breakpoint already hit 13 times3 breakpoint keep y 0x0000000000504c98 in ngx_http_lua_content_handler at ../ngx_lua-0.10.6/src/ngx_http_lua_contentby.c:1894 breakpoint keep y 0x0000000000504c19 in ngx_http_lua_content_handler at ../ngx_lua-0.10.6/src/ngx_http_lua_contentby.c:222 breakpoint already hit 8 times5 breakpoint keep y 0x0000000000505482 in ngx_http_lua_content_handler_file at ../ngx_lua-0.10.6/src/ngx_http_lua_contentby.c:284 breakpoint already hit 8 times6 breakpoint keep y 0x0000000000505024 in ngx_http_lua_content_by_chunk at ../ngx_lua-0.10.6/src/ngx_http_lua_contentby.c:54 breakpoint already hit 8 times7 breakpoint keep y 0x00000000005050e0 in ngx_http_lua_content_by_chunk at ../ngx_lua-0.10.6/src/ngx_http_lua_contentby.c:120 breakpoint already hit 8 times8 breakpoint keep y 0x00000000005014d3 in ngx_http_lua_run_thread at ../ngx_lua-0.10.6/src/ngx_http_lua_util.c:1005 breakpoint already hit 22 times9 breakpoint keep y 0x0000000000501f58 in ngx_http_lua_run_thread at ../ngx_lua-0.10.6/src/ngx_http_lua_util.c:1476 breakpoint already hit 8 times10 breakpoint keep y 0x00000000004ffc4a in ngx_http_lua_send_chain_link at ../ngx_lua-0.10.6/src/ngx_http_lua_util.c:48411 breakpoint keep y 0x00000000004ffb63 in ngx_http_lua_send_chain_link at ../ngx_lua-0.10.6/src/ngx_http_lua_util.c:557 breakpoint already hit 7 times12 breakpoint keep y 0x00000000004ffb86 in ngx_http_lua_send_chain_link at ../ngx_lua-0.10.6/src/ngx_http_lua_util.c:523 breakpoint already hit 6 times13 breakpoint keep y 0x00000000004ffc2b in ngx_http_lua_send_chain_link at ../ngx_lua-0.10.6/src/ngx_http_lua_util.c:569 breakpoint already hit 6 times14 breakpoint keep y 0x0000000000489e1b in ngx_http_send_special at src/http/ngx_http_request.c:3358 breakpoint already hit 6 times15 breakpoint keep y 0x0000000000485a2b in ngx_http_output_filter at src/http/ngx_http_core_module.c:1979 breakpoint already hit 30 times16 breakpoint keep y 0x0000000000506c70 in ngx_http_lua_capture_body_filter at ../ngx_lua-0.10.6/src/ngx_http_lua_capturefilter.c:133 breakpoint already hit 30 times17 breakpoint keep y 0x00000000004b2ce1 in ngx_http_charset_body_filter at src/http/modules/ngx_http_charset_filter_module.c:647 breakpoint already hit 30 times18 breakpoint keep y 0x00000000004afd89 in ngx_http_ssi_body_filter at src/http/modules/ngx_http_ssi_filter_module.c:411 breakpoint already hit 25 times19 breakpoint keep y 0x00000000004ad41d in ngx_http_postpone_filter at src/http/ngx_http_postpone_filter_module.c:82 breakpoint already hit 25 times20 breakpoint keep y 0x00000000004ac7d0 in ngx_http_gzip_body_filter at src/http/modules/ngx_http_gzip_filter_module.c:326 breakpoint already hit 25 times21 breakpoint keep y 0x00000000004a908f in ngx_http_chunked_body_filter at src/http/modules/ngx_http_chunked_filter_module.c:224 breakpoint already hit 25 times22 breakpoint keep y 0x00000000004a7cff in ngx_http_write_filter at src/http/ngx_http_write_filter_module.c:254 breakpoint already hit 5 times23 breakpoint keep y 0x00000000004769e1 in ngx_linux_sendfile_chain at src/os/unix/ngx_linux_sendfile_chain.c:92 breakpoint already hit 4 times24 breakpoint keep y 0x0000000000476957 in ngx_linux_sendfile_chain at src/os/unix/ngx_linux_sendfile_chain.c:49 breakpoint already hit 4 times25 breakpoint keep y 0x00000000004b4f8a in ngx_http_copy_filter at src/http/ngx_http_copy_filter_module.c:152 breakpoint already hit 5 times26 breakpoint keep y 0x000000000045338b in ngx_output_chain at src/core/ngx_output_chain.c:74 breakpoint already hit 5 times27 breakpoint keep y 0x0000000000476a71 in ngx_linux_sendfile_chain at src/os/unix/ngx_linux_sendfile_chain.c:215 breakpoint already hit 1 time28 breakpoint keep y 0x0000000000476a71 in ngx_linux_sendfile_chain at src/os/unix/ngx_linux_sendfile_chain.c:215 breakpoint already hit 1 time29 breakpoint keep y 0x0000000000476a71 in ngx_linux_sendfile_chain at src/os/unix/ngx_linux_sendfile_chain.c:2130 breakpoint keep y 0x0000000000476a71 in ngx_linux_sendfile_chain at src/os/unix/ngx_linux_sendfile_chain.c:215 breakpoint already hit 1 time31 breakpoint keep y 0x0000000000476a71 in ngx_linux_sendfile_chain at src/os/unix/ngx_linux_sendfile_chain.c:215 breakpoint already hit 1 time32 breakpoint keep y 0x0000000000476a71 in ngx_linux_sendfile_chain at src/os/unix/ngx_linux_sendfile_chain.c:215 breakpoint already hit 1 time33 breakpoint keep y 0x0000000000476a71 in ngx_linux_sendfile_chain at src/os/unix/ngx_linux_sendfile_chain.c:215 breakpoint already hit 1 time34 breakpoint keep y 0x0000000000476a71 in ngx_linux_sendfile_chain at src/os/unix/ngx_linux_sendfile_chain.c:215 breakpoint already hit 1 time35 breakpoint keep y 0x0000000000476a71 in ngx_linux_sendfile_chain at src/os/unix/ngx_linux_sendfile_chain.c:215 breakpoint already hit 1 time36 breakpoint keep y 0x0000000000476a71 in ngx_linux_sendfile_chain at src/os/unix/ngx_linux_sendfile_chain.c:215 breakpoint already hit 1 time 8.4、使用 GDB 调试 OpenResty8.4.1、加断点比如 ngx_http_lua_ffi_worker_pid 123456789101112131415161718192021local ffi = require 'ffi'local C = ffi.Cffi.cdef[[int ngx_http_lua_ffi_worker_pid(void);]]local _M = &#123; _VERSION = '0.10' &#125;local mt = &#123; __index = _M &#125;function _M.new(self) local _m_name = 'weibo.com' return setmetatable(&#123; m_name = _m_name &#125;, mt)endfunction _M.getWorkerPid(self) return C.ngx_http_lua_ffi_worker_pid()endreturn _M 运行调用这个包的代码，则可以在 GDB 中加断点 ngx_http_lua_ffi_worker_pid 即可直接追踪 OpenResty 的大致运行过程。通过 c 继续下一步 breakpoints 12345678910111213141516171819ngx_http_process_request_headersngx_http_lua_content_handlerngx_http_lua_content_handler_filengx_http_lua_content_by_chunkngx_http_lua_run_threadngx_http_lua_send_chain_linkngx_http_send_specialngx_http_output_filterngx_http_lua_capture_body_filterngx_http_charset_body_filterngx_http_ssi_body_filterngx_http_postpone_filterngx_http_gzip_body_filterngx_http_chunked_body_filterngx_http_write_filterngx_linux_sendfile_chainngx_http_copy_filterngx_output_chainngx_linux_sendfile_chain 9、基于 OpenResty 安装 Luarocks基于 OpenResty 来安装 其实意在基于 OpenResty 自带的 Luajit 来安装 Luarocks， Luarocks 安装时需要指定 lua 目录和 lua 的 include 目录，而 OpenResty 自身带有的 Luajit 就包含所需的 Lua 解释器和头文件。 只不过 Luarocks 安装需要的是 Lua 而不是 Luajit，这就是关键的一步 12345678910# 我本机的 OpenResty 安装路径为 /usr/local/openresty-1.11.2.1/# OpenResty 本身带的 Lua 解释器 Luajit 在 /usr/local/openresty-1.11.2.1/luajit/bin/ 路径# OpenResty 本身带的 Lua 相关头文件 include 在 /usr/local/openresty-1.11.2.1/luajit/include/ 路径# 我们需要做的就是建一个软连接，给 Luarocks 使用cd /usr/local/openresty-1.11.2.1/luajit/binsudo ln -sf luajit-2.1.0-beta2 luacd /usr/local/openresty-1.11.2.1/luajit/includesudo ln -sf luajit-2.1 lua5.1 经过以上几步的准备工作，就可以进入正常的安装步骤，演示如下： 123./configure --with-lua-bin=/usr/local/openresty-1.11.2.1/luajit/bin --with-lua-include=/usr/local/openresty-1.11.2.1/luajit/include --prefix=/usr/local/luarocks-2.4.1sudo make buildsudo make install 安装完毕后，只需要将 Luarocks 安装路径的 bin 目录（/usr/local/luarocks-2.4.1/bin）加到 PATH 环境变量下，即可使用 luarocks 命令来管理标准 Lua 包，使用 Luarocks 安装的包将保存在 Luarocks 安装的 share 目录，而可执行文件（比如 Vanilla 的可执行命令 vanilla 和 v-console）都在 luarocks 命令同级目录。 10、Vanilla集成的一些优秀第三方包这里记录下vanilla中默认集成的一些优秀第三方包. Waf 模板引擎 工具包 10.1、Waf ngx_lua_waf 10.2、模板引擎 lua-resty-template openresty-lemplate vanilla-rc7 后默认使用此种模板引擎 10.3、工具包 Penlight 11、QCon 2015 Broken Performance Tools分享一个Brendan Gregg大神（QCon 2015分享）","tags":[{"name":"Lua","slug":"Lua","permalink":"https://www.shengguocun.com/tags/Lua/"},{"name":"Vanilla中文文档","slug":"Vanilla中文文档","permalink":"https://www.shengguocun.com/tags/Vanilla中文文档/"}]},{"title":"Nginx","date":"2018-08-01T10:51:04.000Z","path":"/blog/2018/08/01/nginx-book/","text":"","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.shengguocun.com/tags/Nginx/"},{"name":"基础概念","slug":"基础概念","permalink":"https://www.shengguocun.com/tags/基础概念/"}]},{"title":"基于Go语言的简易基金定投系统","date":"2018-05-18T13:30:07.000Z","path":"/blog/2018/05/18/automatic-investment-plan-by-golang/","text":"0、前言在平时基金定投的过程中，因为各家基金公司的系统定投系统功能太过单一，即使定期不定额的方式也不能满足多个梯度的自定义的需求，只能设置高于成本某个阈值或者低于成本某个阈值设置相应的定投值；但是我们想有梯度的定投而不是简单的三个点。为了满足当前我的简单的需求（希望能够有更灵活的自定义定投设置），靠人不如靠自己，下面就开始吧。 1、概念介绍净值估算净值估算每个交易日9：30-15：00盘中实时更新（QDII基金为海外交易时段），是按照基金持仓、指数走势和基金过往业绩估算，估算数据并不代表真实净值，仅供参考，请以基金管理人披露净值为准。 指数温度指数温度 = ( PE + PB ) / 2 PEPE就是我们一般所说的市盈率，即每股股价与每股收益的比率．用来反映投资该股票的风险，一般来说比率越低越安全； PBPB即市净率。市净率 = 股票市价 / 每股净资产，市净率越低的股票，其投资价值越高。","tags":[{"name":"Go语言","slug":"Go语言","permalink":"https://www.shengguocun.com/tags/Go语言/"},{"name":"基金","slug":"基金","permalink":"https://www.shengguocun.com/tags/基金/"},{"name":"定投","slug":"定投","permalink":"https://www.shengguocun.com/tags/定投/"}]},{"title":"A Bite of Golang","date":"2018-04-20T06:54:03.000Z","path":"/blog/2018/04/20/a-bite-of-golang/","text":"0. 前言A bite of GoLang（浅尝GoLang），本文只是Go语言的冰山一角，本文包含作者学习Go语言期间积累的一些小的经验，同时为了方便让读者了解到Go语言中的一些概念，文中包含了许多快速简洁的例子，读者后期可以去自行拓展。当然写这篇文章的灵感来源于GitHub上的 a bite of Python 1. 基础1.0、环境搭建1、下载安装包安装通过浏览器访问下面的地址 https://golang.org/dl/ 要是自己的网络不能翻墙的话，可以访问下面的Go语言中文网 https://studygolang.com/dl 下载指定的版本的安装包直接下一步就可以安装完成； 2、命令行安装Mac 利器 home brew 安装 go 1234brew update &amp;&amp; brew upgradebrew install gitbrew install mercurialbrew install go 安装完成之后 1vim ~/.bashrc 1234567891011#GOROOTexport GOROOT=/usr/local/Cellar/go/1.7.4/libexec#GOPATHexport GOPATH=$HOME/GoLangProject#GOPATH binexport PATH=$PATH:$GOPATH/bin#GOPATH root binexport PATH=$PATH:$GOROOT/bin 1source ~/.bashrc OK配合完成之后,输入go env验证一下是否配置成功 123456789101112131415~ sheng$ go envGOARCH=\"amd64\"GOBIN=\"\"GOEXE=\"\"GOHOSTARCH=\"amd64\"GOHOSTOS=\"darwin\"GOOS=\"darwin\"GOPATH=\"/Users/verton/GoLangProject\"GORACE=\"\"GOROOT=\"/usr/local/Cellar/go/1.7.4/libexec\"GOTOOLDIR=\"/usr/local/Cellar/go/1.7.4/libexec/pkg/tool/darwin_amd64\"CC=\"clang\"GOGCCFLAGS=\"-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/z2/h48yrw8131g824_bvtw6584r0000gn/T/go-build415367881=/tmp/go-build -gno-record-gcc-switches -fno-common\"CXX=\"clang++\"CGO_ENABLED=\"1\" 1.1、变量定义1、通过var关键字12var a intvar b string 在Go语言中在定义变量的时候，是变量在前类型在后，现在你暂时先不用考虑那么多为什么，就先知道Go是这样的定义形式就可以了；当然可以多个变量一起定义,同时可以一起赋初值 1234567var a,b,c boolvar m,n string = \"Hello\",\"World\"var ( aa = 1 bb = \"hello world\" cc = true) 当然也可以让编译器自动决定类型，比如 1var s,m,p,q = 1,\"hahah\",false,\"xixiix\" 2、使用 := 定义变量1s,m,p,q := 1,\"hahah\",false,\"xixiix\" 这样呢可以让代码写的更加简短一点，当然呢 := 只能在函数内使用，是不能在函数外使用的。（相关的函数的知识后面会做介绍） 1.2、内建变量类型1、bool 、string这两个类型就不做过多的介绍，因为基本每一门语言里面都有这两个类型，在Go语言里面也是一样的 2、(u)int、(u)int8、(u)int16、(u)int32、(u)int64、uintptr上面这些就是Go的整数类型，加u和不加u的区别就是有无符号的区别，Go语言中的整数类型还分为两个大类，一个是规定长度的，比如：int8、int16、int32…，还有一种就是不规定长度的，它是根据操作系统来，在32位系统就是32位，在64位系统就是64位的，Go语言中没有int、long 这些类型，你想要定义一个相对较长的定义int64就可以了，最后uintptr就是Go语言的指针，后面我会再来介绍它 3、byte、runebyte就不用过多介绍了，大家都知道字节类型，那rune是什么呢，这就是Go语言的“char”，因为char只有一个字节在使用中会有很多的坑，Go语言针对这点痛点做了一些优化 4、float32、float64、complex64、complex128前面两个不过多介绍，浮点数类型32位和64位的，后面两个是一个复数的类型，complex64实部和虚部都是32位的，complex128实部和虚部都是64位的 1.3、常量与枚举123456const a = 1const b,c = 2,3const ( d = 5 e,f = 6,7) 常量数值可以作为各种类型使用,比如以下代码 123var s,p = 3,4m := math.Sqrt(s*s + p*p)fmt.Println(m) 这段代码语法是编译不通过的，因为Sqrt的参数必须是一个浮点数类型；但是呢我们把是s、p定义成常量就可以编译通过了 123const s,p = 3,4m := math.Sqrt(s*s + p*p)fmt.Println(m) Go语言中的枚举类型就是通过const来实现，同时Go语言中还可以通过iota实现自增的功能 123456789func enums()&#123; const ( a = iota b c ) fmt.Println(a, b, c)&#125; 调用上面这个函数显而易见，会输出 10 1 2 1.4、条件语句1、if正常的条件判断我这边就不做过多的介绍，当然Go语言有它特别的地方，if的条件里可以赋值，比如： 举个读文件的例子，ioutil.ReadFile 这个方法有两个返回值，后面会详细的讲解，常规的写法是 1234567const filename = \"file.txt\"content,err := ioutil.ReadFile(filename)if err != nil &#123; fmt.Println(err)&#125;else &#123; fmt.Println(string(content))&#125; Go语言可以整合成下面的写法 123456const filename = \"file.txt\"if content,err := ioutil.ReadFile(filename); err != nil &#123; fmt.Println(err)&#125;else &#123; fmt.Println(string(content))&#125; 2、switch123456789101112131415161718func eval(a int, b int, op string) int &#123; var result int switch op &#123; case \"+\": result = a + b case \"-\": result = a - b case \"*\": result = a * b case \"/\": result = a / b default: panic(\"unsupported op\") &#125; return result&#125; 看上面的这段代码，你发现和别的语言不一样的地方是怎么没有break，是的，Go语言中switch会自动break，除非使用fallthrough 同时，Go语言的switch还有另外一种写法，结合一个最常见的Switch用法举个例子吧，比如通过考试分数判断是否合格 123456789101112131415func grade(score int) string &#123; switch &#123; case score &gt; 100 || score &lt; 0: panic(\"Wrong score\") case score &gt; 80: return \"A\" case score &gt; 70: return \"B\" case score &gt; 60: return \"C\" default: return \"D\" &#125;&#125; 上面的一个写法可以发现switch后面是可以没有表达式的 1.5、循环1、forfor关键字和其他语言有着共同的功能，同时还充当的Go语言中的 while 功能，Go语言中没有 while 关键字 123for scanner.Scan() &#123; fmt.Println(scanner.Text())&#125; 上面的循环代码省略了起始条件，省略了递增条件，就跟while的功能非常的类似 123for &#123; fmt.Println(\"hello world\")&#125; 上面其实就是一个死循环，因为Go语言中经常会用到，后面的并发编程 Goroutine 的时候还会给大家继续介绍。 1.6、函数1、普通函数普通的函数定义我这边不再过多阐述，跟变量定义类似，函数名在前，函数返回类型在后 2、多返回值这个是Go语言的不一样的地方，函数可以有多个返回值，比如 ioutil.ReadFile 这个函数就是有两个返回值，但是呢多返回值不要滥用，尽量贴合Go语言的风格，常规返回值和一个error，那我门这边可以将上面的加减乘除的例子做一下改造，因为panic之后程序就会终止了，我们可以将错误信息直接返回出来，让程序继续执行 12345678910111213141516func eval(a int, b int, op string) (int, error) &#123; switch op &#123; case \"+\": return a + b, nil case \"-\": return a - b, nil case \"*\": return a * b, nil case \"/\": return a / b, nil default: return 0, fmt.Errorf(\"unsupported op\") &#125;&#125; 3、函数可作为参数123func apply(op func(int, int) int, a, b int) int &#123; return op(a, b)&#125; Go语言定义这种函数在前，参数在后的复合函数非常的方便，只需要apply一个函数就可以了，当然在现实的过程中有时候也会了偷下懒，相关的op函数就直接写成一个匿名函数了 1234fmt.Println(\"sub(3, 4) is:\", apply( func(a int, b int) int &#123; return a - b &#125;, 3, 4)) 这样也是OK的 4、没有默认参数、没有可选参数Go语言中没有其他语言类似Lambda这种很花哨的用法，除了一个可变参数列表 1234567func sum(numbers ...int) int &#123; s := 0 for i := range numbers &#123; s += numbers[i] &#125; return s&#125; 上面就是一个参数求和函数 1.7、指针1、指针不能运算比如想对指针做加1运算，Go语言是不支持的；当然要是想在函数内部改变函数外面的变量的值，通过指针是如何实现的呢，如下图所示 2、Go语言只有值传递Go语言中想要改变变量的值，只能传一个指针进去，比如常见 a b 两个变量的值交换 123func swap(a, b int) &#123; *a, *b = *b, *a&#125; 当然呢，交换参数值是不建议上面的写法的 2. 内建容器2.0、数组1、定义1234var arr1 [5]intarr2 := [3]int&#123;1, 3, 5&#125;arr3 := [...]int&#123;2, 4, 6, 8, 10&#125;var grid [4][5]int 数组的定义和变量的定义类似，数组名在前类型在后；常规的遍历操作也是类似 123for i, v := range arr &#123; fmt.Println(i, v)&#125; i 是数组的下标，v是数组的值 2、数组是值类型和上面值传递的概念类似，通过传参在函数内部是改变不了数组的值的;当然要是想改变相关的数组的值，可以通过指针来改变的。接下来的Slice可以直接解决上述的问题。 2.1、Slice(切片)的概念1、Slice定义Slice是什么呢？其实呢就是数组的一个View（视图），先来段代码热个身 1234arr := [...]int&#123;0, 1, 2, 3, 4, 5, 6, 7&#125;fmt.Println(\"arr[2:6] =\", arr[2:6])fmt.Println(\"arr[:6] =\", arr[:6]) 结果输出： 12arr[2:6] = [2 3 4 5]arr[:6] = [0 1 2 3 4 5] 从上面的输出结果可以直接的看出，arr加一个下标区间都叫做Slice，Slice的区间是一个左闭右开的区间当然我们还需要知道一个概念，Slice是没有数据的，是对底层Array的一个View，如何理解这个概念呢？简单的用一个例子来理解它 1234567891011121314151617181920212223242526package mainimport \"fmt\"func updateSliceData(s []int) &#123; s[0] = 666&#125;func main() &#123; arr := [...]int&#123;0, 1, 2, 3, 4, 5, 6, 7&#125; s1 := arr[2:] fmt.Println(\"s1 =\", s1) s2 := arr[:] fmt.Println(\"s2 =\", s2) fmt.Println(\"更新Slice数据 s1\") updateSliceData(s1) fmt.Println(s1) fmt.Println(arr) fmt.Println(\"更新Slice数据 s2\") updateSliceData(s2) fmt.Println(s2) fmt.Println(arr)&#125; 结果输出为： 12345678s1 = [2 3 4 5 6 7]s2 = [0 1 2 3 4 5 6 7]更新Slice数据 s1[666 3 4 5 6 7][0 1 666 3 4 5 6 7]更新Slice数据 s2[666 1 666 3 4 5 6 7][666 1 666 3 4 5 6 7] 2、ReSlice就是在一个Slice上进一步slice，比如 1234arr := [...]int&#123;0, 1, 2, 3, 4, 5, 6, 7&#125;ss := arr[:6]ss = ss[:5]ss = ss[2:] 结果输出： 12[0 1 2 3 4][2 3 4] 3、Slice拓展首先我们先看一个例子 123arr := [...]int&#123;0, 1, 2, 3, 4, 5, 6, 7&#125;s1 := arr[2:6]s2 := s1[3:5] 大家或许会有疑问，这个s2不会报错么，要是不报错结果又是多少呢？ 12[2 3 4 5][5 6] 答案是可以，上述就是s1、s2的值，是不是跟你想的有点不一样。那么这又是为什么呢？ 这就是为什么能把 6 这个值取出来的原因，因为slice是array的底层的一个view，是不是依然还是有点懵，具体又是如何实现的呢？ 4、Slice实现 从上图是不是大体明白为什么上面那个例子能把6取出来了；看到这里大家也能大体明白Slice内部的ptr、len、cap是什么意思，ptr指向slice的开头的元素，len是slice的长度，cap代表底层的array从ptr开始到结束的长度，Slice是可以向后扩展的，但是不能向前扩展，所以只要不超过cap的长度slice都是可以扩展的，但是常规的s[i]取值是不可以超过len的。用一个例子来简单的理解一下 123arr := [...]int&#123;0, 1, 2, 3, 4, 5, 6, 7&#125;s1 := arr[2:6]fmt.Printf(\"len(s1): %d ; cap(s1): %d \", len(s1), cap(s1)) 输出结果： 1len(s1): 4 ; cap(s1): 6 2.2、Slice(切片)的操作1、向Slice添加元素12345s3 := append(s2, 8)s4 := append(s3, 9)s5 := append(s4, 10)fmt.Println(\"s3, s4, s5 =\", s3, s4, s5)fmt.Println(\"arr =\", arr) 上面的这个例子打印出来结果又是多少呢？ 12s3, s4, s5 = [5 6 8] [5 6 8 9] [5 6 8 9 10]arr = [0 1 2 3 4 5 6 8] 上面的9 ，10为什么不见了呢？因为Go语言在append数据超过cap长度的时候会分配一个更长的数组，如果arr不再使用的话就会被垃圾回收掉。在append的过程中，由于是值传递的关系，len、cap都有可能会改变，所以呢必须要用一个新的slice来接收这个slice，通常会写成 1s = append(s, value1) 2、创建slice当然slice也可以直接通过var关键字创建 1var s []int 这样创建的slice的初始值就是nil，别的语言中的null的意思，当然也是可以赋初值的，比如： 1s1 := []int&#123;2, 4, 6, 8&#125; 就上面的Zero Value的Slice的情况，要是我这个时候对这个slice进行append操作会怎么样呢？这个slice的内部的len以及cap又是如何变化的呢？ 12345var s []intfor i := 0; i &lt; 100; i++ &#123; fmt.Printf(\"%v, len = %d, cap = %d\\n\", s, len(s), cap(s)) s = append(s, 2*i+1)&#125; 结果我就不输出了，因为相对太长，我把相应的结果总结一下，就是len就是一个步长为1由1增至100，cap呢？当系统发现不够存储的时候会分配一个现有长度两倍的空间。 当然在实际生产过程中，大多是使用的make关键字来创建slice的 12s2 := make([]int, 4)s3 := make([]int, 8, 16) 3、Copy Slice数据1func Copy(dst Writer, src Reader) (written int64, err error) 文档中可以看的很清晰，直接将第二个参数直接拷贝进第一个参数 1234s1 := []int&#123;2, 4, 6, 8&#125;s2 := make([]int, 16)copy(s2, s1)fmt.Println(s2) 结果输出 1[2 4 6 8 0 0 0 0 0 0 0 0 0 0 0 0] 4、Slice删除元素123s1 := []int&#123;2, 4, 6, 8&#125;s2 := make([]int, 16)copy(s2, s1) 比如我要删除 s2 中的第 3 个元素该如何操作呢？ 1s2 = append(s2[:2], s2[3:]...) 当然现实的使用中还会从slice中pop一个值出来，下面分别演示一下从s2头部pop和从s2尾部pop数据 12front := s2[0]s2 = s2[1:] 12tail := s2[len(s2)-1]s2 = s2[:len(s2)-1] 2.3、Map1、创建map12var m1 map[string]intm2 := make(map[string]int) 上述就是常见的创建map的方式，但是m1、m2还是有区别的，m1是nil，m2是一个空map;常规的遍历map也是用 range 的方式就可以， 123for k, v := range m &#123; fmt.Println(k, v)&#125; 当然细心的会发现，在遍历的过程中是不能保证顺序的，当然要是想顺序遍历，需要自己手动对key进行排序，可以将key存进slice，然后再通过slice遍历相关的key获取map的值。 2、获取map元素m[key] 一般就是这样获取map的值 123456789var map1 = map[string]string&#123; \"name\" : \"shengguocun\", \"gender\" : \"male\", \"city\" : \"hangzhou\",&#125;value1 := map1[\"age\"]fmt.Println(value1) 先来猜测一下，上述这段代码可以运行么？会不会报错？ 答案是不会，这就是Go语言和别的语言不一样的地方，上述的例子中 value1 的值是一个空字符串，map中当key不存在时，会获取value类型的初始值。 1234567gender, ok := map1[\"gender\"]if ok &#123; fmt.Println(\"Gender 的值为 : \", gender)&#125;else &#123; fmt.Println(\"Key 不存在\")&#125; 既然Go语言的出现就是为了解决别的语言的痛点，所以在使用过程中不再需要每次获取某个 key 的时候都要去 isset 判断一下，Go的获取map的值的时候第二个返回值就是别的语言 isset 的功能；存在返回 true ，不存在返回 false。 3、删除元素delete函数，就可以直接删除指定的key的值 这是Go语言的官方文档，不难理解比如要删除上面的 map1 的 city 的值 1delete(map1, \"city\") 直接调用就可以 4、map的key为什么要把key单独拿出来说呢？因为map底层使用的是hash表，所以map的key必须可以比较相等；换句话说就是除了 slice、map、function的内建类型都可以作为key。 2.4、字符和字符串处理1、rune介绍rune就是Go语言的字符串类型，其实可以理解为是 int32 的一个別名，下面我们通过例子来深入理解一下rune 1234567891011121314s1 := \"你好,杭州\"fmt.Println(s1)for _, ch := range []byte(s1) &#123; fmt.Printf(\"%X \", ch)&#125;fmt.Println()for i, ch := range s1 &#123; fmt.Printf(\"(%d %X) \", i, ch)&#125; 输出结果 123你好,杭州E4 BD A0 E5 A5 BD 2C E6 9D AD E5 B7 9E(0 4F60) (3 597D) (6 2C) (7 676D) (10 5DDE) 从上述的例子我们可以直接的看出来，其实就是将UTF-8编码解码，然后再转成Unicode之后将它存放进一个rune（int32）中 2、字符串处理UTF-8编码的rune长度统计 12count := utf8.RuneCountInString(s1)fmt.Println(\"Rune Count :\", count) 输出结果为： 1Rune Count : 5 字符串的输出操作 123456bytes := []byte(s1)for len(bytes) &gt; 0 &#123; ch, size := utf8.DecodeRune(bytes) bytes = bytes[size:] fmt.Printf(\"%c \", ch)&#125; 用rune实现上述同样的功能 123for _, ch := range []rune(s1) &#123; fmt.Printf(\"%c \", ch)&#125; 3. 面向“对象”3.0、结构体和方法1、结构体的创建go语言仅支持封装，不支持继承和多态；这句话怎么理解呢？就是说在Go语言内部没有class，只有struct；也没有复杂的继承和多态，那继承和多态的任务又是通过什么实现的呢？Go是面向接口编程，可以通过接口来实现继承和多态的相关的任务，后面我会再进行介绍。下面先来介绍一下struct的创建： 1234type Node struct &#123; Value int Left, Right *Node&#125; 通过type、struct关键字创建结构体类型，当然在创建了结构体类型之后，就可以创建相关类型的变量 12345var root tree.Noderoot = tree.Node&#123;Value:1&#125;root.Value = 2root.Left = &amp;tree.Node&#123;Value:3&#125;root.Right = &amp;tree.Node&#123;&#125; 2、方法创建结构体的方法的创建和普通的函数创建没有太大的区别，只是在方法名前面添加一个接收者，就相当于其他语言的this 123func (node Node) Print() &#123; fmt.Print(node.Value, \" \")&#125; 上述就是一个值接收者打印出Node的Value的值的方法。当然要是需要改变Value的值的时候，就需要一个指针接收者。 123func (node *Node) SetValue(value int) &#123; node.Value = value&#125; 有一个疑问，要是对一个值为nil的Node进行 SetValue 操作会发生什么？ 12var pRoot *tree.NodepRoot.SetValue(1) 虽说nil指针可以调用方法，但是下面的Value是拿不到，自然就会报下面的错了 12345panic: runtime error: invalid memory address or nil pointer dereference[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x20c3]goroutine 1 [running]:panic(0x8f100, 0xc42000a070) 实际使用过程中可以添加相关的判断在做处理。结合上面的知识我们不难写出一个树的遍历的方法的代码 123456789func (node *Node) Traverse() &#123; if node == nil &#123; return &#125; node.Print() node.Left.Traverse() node.Right.Traverse()&#125; 3.1、包和封装1、命名规范 名字一般使用 CamelCase（驼峰式） 首字母大写：Public 首字母小写：Private 2、包的概念 每个目录一个包，但是包名和目录名不一定要一样的，但是每个目录只能包含一个包； main包是一个相对特殊的，main包包含一个可执行入口； 为结构体定义的方法必须放在同一个包内 当然上面的例子已经在不经意间提前引入了package的概念 3.2、扩展已有类型在面向对象中，我们想要扩展一下别人的类，我们通常继承一下就好了，但是Go语言中没有继承的概念，我们该如何处理呢？ 1、定义别名（1.9新特性）在大规模的重构项目代码的时候，尤其是将一个类型从一个包移动到另一个包中的时候，有些代码使用新包中的类型，有些代码使用旧包中的类型 基本语法就是： 1type identifier = Type 比如内建的byte类型，其实是uint8的类型别名，而rune其实是int32的类型别名。 12345678// byte is an alias for uint8 and is equivalent to uint8 in all ways. It is// used, by convention, to distinguish byte values from 8-bit unsigned// integer values.type byte = uint8// rune is an alias for int32 and is equivalent to int32 in all ways. It is// used, by convention, to distinguish character values from integer values.type rune = int32 通过别名的方式就可以拓展了，比如 12345678910111213type T1 struct&#123;&#125;type T3 = T1func (t1 T1) say()&#123;&#125;func (t3 *T3) greeting()&#123;&#125;func main() &#123; var t1 T1 // var t2 T2 var t3 T3 t1.say() t1.greeting() t3.say() t3.greeting()&#125; 当然要是T1也定义了 greeting 的方法，那么编译会报错的，因为有重复的方法定义。 2、使用组合比如我们想扩展上面的树的包，实现一个自己的中序遍历，该如何实现呢？通过代码来理解一下使用组合的概念 123456789101112131415type myNode struct &#123; node *tree.Node&#125;func (myNodeNode *myNode) Traverse() &#123; if myNodeNode == nil || myNodeNode.node == nil &#123; return &#125; left := myNode&#123;myNodeNode.node.Left&#125; right := myNode&#123;myNodeNode.node.Right&#125; left.ownFunc() myNodeNode.node.Print() right.ownFunc()&#125; 3.3、GOPATH以及目录结构 默认在 ～／go 目录下（unix或者Linux环境），%USERPROFILE%\\go 目录下（windows环境） 官方推荐：所有的项目和第三方库都放在同一个GOPATH下 当然也可以将每个项目放在不同的GOPATH下 如何查看自己的GOPATH呢？ 12~ sheng$ echo $GOPATH/Users/verton/GoLangProject 1、go get获取第三方库1go get url 这样是可以获取GitHub上面的三方的库，但是Golang.org上面要是不能翻墙是获取不了的，这里我给大家介绍一个新的工具 gopm 1sheng$ go get github.com/gpmgo/gopm 一行命令就可以装好了，这个时候再get三方的库就毫无压力了，因为这个国内有相关的镜像 1gopm get -g url 采用-g 参数，可以把依赖包下载到GOPATH目录中 2、目录结构 src git repo 1 git repo 2 pkg git repo 1 git repo 2 bin 执行文件 1 2 从上述的目录结构上我们可以看出来，src pkg 是对应的，src 是我们的代码的位置以及三方库的位置，pkg 是build的中间过程，可以暂时先不用关注，bin下面就是可执行文件。 4. 面向接口4.0、Duck Typing的概念很多语言都有duck typing的概念， 用一个简单的例子来描述一下这个概念 大黄鸭是鸭子么？这个答案是要看基于什么角度来看，从生物角度来看，那它当然不是鸭子，连基本的生命都没有；但是从duck typing的角度来看它就是一个鸭子，因为它外部长得像鸭子，通俗点概括一下duck typing的概念就是：描述事物的外部行为而非内部结构。 从严格意义上讲，go语言只能说是类似duck typing，go语言不是动态绑定的，go语言是编译时绑定的。 4.1、接口的定义和实现在Go语言中，接口interface其实和其他语言的接口意思也没什么区别。一个结构体必须实现了一个接口的所有方法，才能被一个接口对象接受，这一点和Java语言中的接口的要求是一样的。interface理解其为一种类型的规范或者约定。 1、接口的定义123type Retriever interface&#123; Get(url string) string&#125; 这样就定义了一个接口，它包含一个Get函数。 2、接口的实现现在我们就来实现一下这个接口。比如我们做一个拉取某个页面的操作 123456789101112131415161718192021222324package rickimport ( \"net/http\" \"net/http/httputil\")type Retriever struct &#123;&#125;func (r Retriever) Get(url string) string &#123; resp, err := http.Get(url) if err != nil &#123; panic(err) &#125; result, err := httputil.DumpResponse(resp, true) resp.Body.Close() if err != nil &#123; panic(err) &#125; return string(result)&#125; 123456789101112131415161718192021package mainimport ( \"shengguocun.com/retriever/rick\" \"fmt\")type Retriever interface&#123; Get(url string) string&#125;func download(r Retriever) string &#123; return r.Get(\"http://www.shengguocun.com\")&#125;func main() &#123; var r Retriever r = rick.Retriever&#123;&#125; fmt.Println(download(r))&#125; 上述rick.Retriever就实现了Retriever接口。 4.2、接口值的类型1、接口变量里面有什么继续使用上面的例子 1234var r Retrieverr = rick.Retriever&#123;&#125;fmt.Printf(\"\\n %T %v \\n\", r, r) 会输出什么呢？ 1rick.Retriever &#123;&#125; 这就是常规的值传递，没有什么特别的地方。要是 Retriever 这个struct很大，我们不希望通过传值的方法去拷贝，而是通过指针访问Get方法。 12345678910111213func (r *Retriever) Get(url string) string &#123; resp, err := http.Get(url) if err != nil &#123; panic(err) &#125; result, err := httputil.DumpResponse(resp, true) resp.Body.Close() if err != nil &#123; panic(err) &#125; return string(result)&#125; 1234var r Retrieverr = &amp;rick.Retriever&#123;&#125;fmt.Printf(\"\\n %T %v \\n\", r, r) 这时候的Type、Value又是什么？ 1*rick.Retriever &amp;&#123;&#125; 我们可以看到是一个指针，所以我们一般用到接口的指针，因为它的肚子里含有一个指针，通常我们会说“接口变量自带指针”，那我们现在用两个图来总结一下上面的概念 概括为：接口变量里面可以是实现者的类型和实现者的值，或者是接口类型里面可以是实现者的类型和实现者的指针，同时指向实现者。 2、查看接口变量说到这里要提到一个特殊的接口，空接口 interface{} ，对于空接口 interface{} 其实和泛型的概念很像，任何类型都实现了空接口。在方法需要返回多个类型的时候，返回值的类型我们一般定义为 interface{} 。 这时我们现在引入获取接口变量肚子里的类型的另外一种写法，叫 Type Assertion（断言）。比如 12var a interface&#123;&#125;fmt.Println(\"Are you ok?\", a.(string)) 然而上述的写法一旦断言失败，会报出panic错误，当然这样的程序就显得十分的不友好。我们需要在断言前进行一个判断。 123456value, ok := a.(string)if !ok &#123; fmt.Println(\"断言失败，这不是一个string类型\") return&#125;fmt.Println(\"值为：\", value) 另外我们可以结合switch进行类型判断 12345678var r interface&#123;&#125;r = balabalaFunction()switch v := r.(type) &#123; case bool: fmt.Println(\"type bool...\") case int: fmt.Println(\"type int...\")&#125; Tips:转换类型的时候如果是string可以不用断言，使用fmt.Sprint()函数可以达到想要的效果。 4.3、接口的组合1、定义什么叫接口的组合？当然这就是它的字面上的意思，接口可以组合其他的接口。这种方式等效于在接口中添加其他的接口的方法。在系统函数中就有很多这样的组合，比如：ReadWriter 12345// ReadWriter is the interface that groups the basic Read and Write methods.type ReadWriter interface &#123; Reader Writer&#125; 在常见的读写文件的时候，网络相关以及一些底层的东西经常会遇到 Reader 、Writer 2、实例演示为了更好的理解接口的组合的概念，下面用一个简单的例子来进一步了解 123456789101112131415161718192021222324252627282930313233343536373839404142434445// 定义Reader接口type Reader interface &#123; read()&#125;// 定义Writer接口type Writer interface &#123; write()&#125;// 实现上述两个接口type myReaderWriter struct &#123;&#125;func (mrw *myReaderWriter) read() &#123; fmt.Println(\"myReaderWriter read func...\")&#125;func (mrw *myReaderWriter) write() &#123; fmt.Println(\"myReadWriter writer func...\")&#125;// 定义一个接口，组合上述两个接口type ReaderWriterV1 interface &#123; Reader Writer&#125;// 等价于type ReaderWriterV2 interface &#123; read() write()&#125;func main() &#123; mrw := &amp;myReaderWriter&#123;&#125; //mrw对象实现了read()方法和write()方法，因此可以赋值给ReaderWriterV1和ReaderWriterV2 var rwv1 ReaderWriterV1 = mrw rwv1.read() rwv1.write() var rwv2 ReaderWriterV2 = mrw rwv2.write() rwv2.read() //同时，ReaderWriterV1和ReaderWriterV2两个接口对象可以相互赋值 rwv1 = rwv2 rwv2 = rwv1&#125; 4.4、常用的系统接口1、Stringer这个就是常见的 toString 的功能， 12345678// Stringer is implemented by any value that has a String method,// which defines the ``native'' format for that value.// The String method is used to print values passed as an operand// to any format that accepts a string or to an unformatted printer// such as Print.type Stringer interface &#123; String() string&#125; Stringer接口定义在fmt包中，该接口包含String()函数。任何类型只要定义了String()函数，进行Print输出时，就可以得到定制输出。比如： 123456789101112131415161718192021222324package mainimport \"fmt\"type Person struct&#123; age int gender string name string&#125;func (p Person) String() string &#123; return fmt.Sprintf(\"age:%d, gender:%s, name:%s\", p.age, p.gender, p.name)&#125;func main() &#123; var i Person = Person&#123; age: 25, gender: \"male\", name: \"sheng.guocun\", &#125; fmt.Printf(\"%s\\n\", i) fmt.Println(i) fmt.Printf(\"%v\", i)&#125; 结果输出为： 123age:25, gender:male, name:sheng.guocunage:25, gender:male, name:sheng.guocunage:25, gender:male, name:sheng.guocun 2、Reader、WriterReader Writer 上面有提到过，就是常见的读写文件的时候经常会用到，就是对文件的一个抽象，但是不仅这些，比如常见的 123456789// NewScanner returns a new Scanner to read from r.// The split function defaults to ScanLines.func NewScanner(r io.Reader) *Scanner &#123; return &amp;Scanner&#123; r: r, split: ScanLines, maxTokenSize: MaxScanTokenSize, &#125;&#125; 这的参数也是一个Reader，还有很多的底层的代码都是基于 Reader Writer 的，这里就不一一举例了。 5. 函数式编程5.0、函数式编程Go语言作为一个通用型语言，它对函数式编程主要体现在闭包上面。 1、函数式编程 VS 函数指针 函数是一等公民：参数、变量、返回值都可以是函数，在别的语言中大多不是这样的，比如在C++里面只有函数指针，在Java里面我们只能调用，不能把函数传给别人。 高阶函数：参数可以是函数，1.6.3里面的apply函数就是一个高阶函数。 函数 –&gt; 闭包：首先用个例子来了解一下闭包的用法 12345678910111213141516171819package mainimport \"fmt\"func adder() func(int) int &#123; sum := 0 return func(v int) int &#123; sum += v return sum &#125;&#125;func main() &#123; a := adder() for i := 0; i &lt; 10; i ++ &#123; fmt.Printf(\"0 + 1 + 2 + ... + %d = %d\\n\", i, a(i)) &#125;&#125; 结果输出为 123456789100 + 1 + 2 + ... + 0 = 00 + 1 + 2 + ... + 1 = 10 + 1 + 2 + ... + 2 = 30 + 1 + 2 + ... + 3 = 60 + 1 + 2 + ... + 4 = 100 + 1 + 2 + ... + 5 = 150 + 1 + 2 + ... + 6 = 210 + 1 + 2 + ... + 7 = 280 + 1 + 2 + ... + 8 = 360 + 1 + 2 + ... + 9 = 45 上述的 v 就称为局部变量， sum 称为自由变量，func(v int) int { sum += v return sum } 称为函数体，整个就叫做一个闭包。用一张图来概括就是： 2、“正统”函数式编程 不可变性：不能有状态，只有常量和函数；当然这和平常的函数不一样，连变量都没有，甚至连选择语句、循环语句都没有。 函数只能有一个参数 要是上面的累加想做一个稍微正统函数怎么做呢？ 1234567891011121314151617type iAdder func(int) (int, iAdder)func adderV2(base int) iAdder &#123; return func(v int) (int, iAdder) &#123; return base + v, adderV2(base + v) &#125;&#125;func main() &#123; a := adderV2(0) for i := 0; i &lt; 10; i ++ &#123; var s int s, a = a(i) fmt.Printf(\"0 + 1 + 2 + ... + %d = %d\\n\", i, s) &#125;&#125; 当然正统的不一定是最好的，正统式的写法经常导致代码的可读性变得不是很好。 5.1、函数式编程实例演示1、斐波那契数列Go语言的官方案列中，对闭包的讲解通过一个常见的例子：斐波那契数列，为了更好的理解闭包的感念，那这里我们就将这个例子再来演示一遍 12345678func Fibonacci() func() int &#123; a, b := 0, 1 return func() int &#123; a, b = b, a+b return a &#125;&#125; 比如我们要打印这一串斐波那契数列，我们就需要不停的调用上面的斐波那契数列的生成器。 12345678f := Fibonacci()f() // 1f() // 1f() // 2f() // 3f() // 5f() // 8 2、为函数实现接口这个斐波那契数列的调用的生成器跟文件有点像，我们可以把它包装成一个 io.Reader 这样就跟打印一个文件一样生成这个斐波那契数列。 首先我们先定义我们的类型 func() int ，就取名Generate好了 1type Generate func() int 同时需要将 Fibonacci() 函数的类型改掉 12345678func Fibonacci() Generate &#123; a, b := 0, 1 return func() int &#123; a, b = b, a+b return a &#125;&#125; 是一个类型就可以实现接口，这就是Go语言灵活的地方，下一步我们实现这个Reader接口 1234567func (gen Generate) Read(p []byte) (n int, err error) &#123; nextNum := gen() numString := fmt.Sprintf(\"%d \\n\", nextNum) return strings.NewReader(numString).Read(p)&#125; 这里我们会发现函数也可以实现接口，这就是Go语言的不一样的地方，因为函数是一等公民，它既可以作为参数，也可以作为接收者。首先我们要先取到下一个元素 nextNum ,然后将下一个元素写进 p 。然后我们直接用一个写好的文件打印的函数 1234567func printFileContents(reader io.Reader) &#123; scanner := bufio.NewScanner(reader) for scanner.Scan() &#123; fmt.Println(scanner.Text()) &#125;&#125; 最后我们就可以直接调用了 12345func main() &#123; f := Fibonacci() printFileContents(f)&#125; 当然，上述的代码是存在瑕疵的，比如这个 printFileContents 函数会一直读下去，就变成一个死循环了，我们需要设置其终止条件。比如上面的 p 太小的话，只读了一半，当然这边就留给读者后期拓展了。 6. 错误处理和资源管理我们实际的代码不止 Hello World ,我们的代码是要运行在服务器上的，要和各种各样的用户进行交互，所以我们这里就要了解一下Go语言的资源管理和出错处理。 6.0、defer调用1、确保在函数结束时调用比如一个常见的代码 123456789package mainimport \"fmt\"func main() &#123; fmt.Println(1) fmt.Println(2)&#125; 我要是想要让1在2后面输出该如何做呢？你说调换一下顺序呗，道理我都懂，但是我们今天要介绍的不是这个，我们只需要在打印1之前加一个 defer 就可以了 123456789package mainimport \"fmt\"func main() &#123; defer fmt.Println(1) fmt.Println(2)&#125; 要是有多个defer呢？它的输出顺序又是什么样的呢？ 12345678910package mainimport \"fmt\"func main() &#123; defer fmt.Println(1) defer fmt.Println(2) fmt.Println(3)&#125; 上面这段代码，输出的结果又是什么？ 123321 这里我们可以发现 defer 的调用实际是一个栈，先进后出。当然 defer 的最大的好处是什么呢？就是当程序中间有return返回甚至panic的时候，依然不影响 defer 后面的代码的执行。 123456789101112package mainimport \"fmt\"func main() &#123; defer fmt.Println(1) defer fmt.Println(2) fmt.Println(3) panic(\"whoops, something went wrong....\") fmt.Println(4)&#125; 上述的代码在panic之后，1 2 依然能够正常输出。 2、场景演示当然说了这么多，我们在代码中常见的使用defer的场景有哪些呢？比如我们创建文件，写文件这些，过去我们用别的语言经常会在处理文件的最后释放句柄，因为中间隔了很多的文件操作，经常可能会忘记释放句柄。那Go语言就针对这样的场景做了非常好的优化，通过defer关键字实现，下面我们就通过一个简单的写文件事例来演示一下： 12345678910111213141516171819202122package mainimport ( \"os\" \"bufio\" \"fmt\")func main() &#123; filename := \"demo.txt\" file, err := os.Create(filename) if err != nil &#123; panic(err) &#125; defer file.Close() writer := bufio.NewWriter(file) defer writer.Flush() fmt.Fprintln(writer, \"你好，杭州\")&#125; 一个完整的事例就演示到这边，比如常见的 Open／Close、Lock／Unlock这些成对出现的都可以使用 defer 6.1、错误处理概念因为在我们实际的程序中，有错直接panic中断程序执行，这时非常不友好的，通常我们会对其出错处理。比如上面的事例中 os.Create 函数返回的 err 不为 nil 的时候，我们需要做一个出错处理， 123456filename := \"demo.txt\"file, err := os.Create(filename)if err != nil &#123; fmt.Println(err.Error()) return&#125; 我们可以直接打印出相关的错误信息，然后直接返回。这就是常见的错误处理方式之一，当然在函数内部也可以将错误信息直接作为结果返回。 6.2、panic和recover1、panic 停止当前函数执行 panic和我们其他语言的throw exception很像 一直向上返回，执行每一层的defer 当然相对还是友好的，每层的defer还是会用到，一层一层的返回，返回到最后程序就会自动退出了 如果没有遇见recover，程序退出 2、recover 仅在defer调用中使用 获取panic的值 如果无法处理，可充新panic 主要的特性就可以用上述几句话概括，为了更好的理解上述的概念，下面用一个简短的代码来学以致用 12345678func tryDefer() &#123; for i := 0; i &lt; 100; i++ &#123; defer fmt.Println(i) if i == 10 &#123; panic(\"就打印到这吧\") &#125; &#125;&#125; 上面就是一个 panic 和 defer 的结合使用，他的输出结果会是什么样的呢？ 123456789101112131415161718109876543210panic: 就打印到这吧goroutine 1 [running]:main.tryDefer() /Users/verton/GoLangProject/src/shengguocun.com/web/web.go:11 +0x11dmain.main() /Users/verton/GoLangProject/src/shengguocun.com/web/web.go:18 +0x20 从上述输出结果我们可以看到panic的前两个特性，那结合recover又会是什么样的呢？ 12345678910// The recover built-in function allows a program to manage behavior of a// panicking goroutine. Executing a call to recover inside a deferred// function (but not any function called by it) stops the panicking sequence// by restoring normal execution and retrieves the error value passed to the// call of panic. If recover is called outside the deferred function it will// not stop a panicking sequence. In this case, or when the goroutine is not// panicking, or if the argument supplied to panic was nil, recover returns// nil. Thus the return value from recover reports whether the goroutine is// panicking.func recover() interface&#123;&#125; 123456789101112func tryRecover() &#123; defer func() &#123; r := recover() if err, ok := r.(error); ok &#123; fmt.Println(\"错误信息: \", err) &#125; else &#123; panic(r) &#125; &#125;() panic(errors.New(\"这是一个 error\"))&#125; 从上面我们可以看到 recover 是一个interface， 所以在判断的时候需要判断 r 是否是一个 error，结果自然会是输出 1错误信息: 这是一个 error 那我们再用一个实际一点的例子来测试一下，比如除数为0的例子 1234567891011121314func tryRecover() &#123; defer func() &#123; r := recover() if err, ok := r.(error); ok &#123; fmt.Println(\"错误信息: \", err) &#125; else &#123; panic(r) &#125; &#125;() b := 0 a := 5 / b fmt.Println(a)&#125; 结果输出 1错误信息: runtime error: integer divide by zero 上面的两个例子简单介绍了panic、recover的基本使用，下面通过一个稍微实际一点的例子来综合讲述一下一般的项目中是如何统一处理错误的。 6.3、服务器统一出错处理现在呢我们就通过一个Http服务来展开如何统一处理服务器出错这件事，结合一个实际读取目录内文件的例子来简单介绍一下 12345678910111213141516171819202122232425func main() &#123; http.HandleFunc(\"/list/\", func(writer http.ResponseWriter, request *http.Request) &#123; path := request.URL.Path[len(\"/list/\"):] file, err := os.Open(path) if err != nil &#123; panic(err) &#125; defer file.Close() all, err := ioutil.ReadAll(file) if err != nil &#123; panic(err) &#125; writer.Write(all) &#125;) err := http.ListenAndServe(\":2872\", nil) if err != nil &#123; panic(err) &#125;&#125; 因为在GOPATH下有一个 demo.txt 文件，浏览器输入一下地址 http://localhost:2872/list/demo.txt ,浏览器正确输出结果 万一我访问一个不存在的文件呢？会得到什么样的结果，比如我现在访问 http://localhost:2872/list/demo.txts GOPATH目录下没有demo.txts文件，自然你会想到会panic一个错误 123456789101112132018/05/04 17:08:54 http: panic serving [::1]:51946: open demo.txts: no such file or directorygoroutine 5 [running]:net/http.(*conn).serve.func1(0xc4200968c0) /usr/local/Cellar/go/1.10.2/libexec/src/net/http/server.go:1726 +0xd0panic(0x124fde0, 0xc420086fc0) /usr/local/Cellar/go/1.10.2/libexec/src/runtime/panic.go:502 +0x229main.main.func1(0x12d1420, 0xc42010e000, 0xc42010a000) /Users/verton/GoLangProject/src/shengguocun.com/web/web.go:52 +0x144net/http.HandlerFunc.ServeHTTP(0x12aff28, 0x12d1420, 0xc42010e000, 0xc42010a000) /usr/local/Cellar/go/1.10.2/libexec/src/net/http/server.go:1947 +0x44net/http.(*ServeMux).ServeHTTP(0x140b3e0, 0x12d1420, 0xc42010e000, 0xc42010a000) /usr/local/Cellar/go/1.10.2/libexec/src/net/http/server.go:2337 +0x130net/http.serverHandler.ServeHTTP(0xc420089110, 0x12d1420, 0xc42010e000, 0xc42010a000) 从上面的部分的报错信息来看， 相关的错误信息都是 /usr/local/Cellar/go/1.10.2/libexec/src/net/http/server.go 的 serve 函数报出的，具体是哪一步报出的我就不细说了，有兴趣的可以自己按照例子自己查阅相关的源码，说到这那错误统一处理又是如何处理呢？我们先把第一个panic替换成 1234567path := request.URL.Path[len(\"/list/\"):]file, err := os.Open(path)if err != nil &#123; http.Error(writer, err.Error(), http.StatusInternalServerError) return&#125; 我们再来访问上述地址 相比之前，提示稍微友好一点了，但是这对用户来讲还是不合适的，直接将程序内部错误信息输出给用户有些欠妥。我们可以包装成一个外部的Error，首先我们先定义一个函数appHandler, 返回一个error 1type appHandler func(writer http.ResponseWriter, request *http.Request) error 然后定义一个 errWrapper 函数, 返回一个handler 里面需要的函数 12345678910111213141516type appHandler func(writer http.ResponseWriter, request *http.Request) errorfunc errWrapper(handler appHandler) func(http.ResponseWriter, *http.Request) &#123; return func(writer http.ResponseWriter, request *http.Request) &#123; err := handler(writer, request) if err != nil &#123; switch &#123; case os.IsNotExist(err): http.Error(writer, http.StatusText(http.StatusNotFound), http.StatusNotFound) &#125; &#125; &#125;&#125; 然后将writer和request传进handler，通过switch判断err的类型，做一个统一的返回处理；这时我们需要将原来的业务逻辑的代码稍微做一下调整， 12345678910111213141516171819202122http.HandleFunc(\"/list/\", errWrapper(func(writer http.ResponseWriter, request *http.Request) error &#123; path := request.URL.Path[len(\"/list/\"):] file, err := os.Open(path) if err != nil &#123; return err &#125; defer file.Close() all, err := ioutil.ReadAll(file) if err != nil &#123; return err &#125; writer.Write(all) return nil &#125;))err := http.ListenAndServe(\":2872\", nil)if err != nil &#123; panic(err)&#125; http.HandleFunc 的第二个参数我们需要改为 errWrapper 同时将原来的函数作为参数传进去，当然这个函数为了代码的可读性应该单独抽离出来，相应的返回直接返回error就可以了，这时候我们再去访问之前的一个不存在的URL 这时候的错误就明显友好了很多，讲到这就是一个简单的统一错误处理的思路。 7. 测试和性能调优7.0、测试1、传统测试 VS 表格驱动测试测试的作用对于一个软件行业从业者而言都是毋庸置疑的，Go语言在测试这块它有自己独特的见解，下面我们先介绍一下这两种模式下的测试 传统测试 测试数据和测试逻辑混在一起 出错信息不明确 一旦一个数据出错测试全部结束 下面我们简单的举个例子： 123456public function testCase()&#123; assertEquals(2, add(1, 1)); assertEquals(1, add(1, 3)); assertEquals(0, add(1, -1));&#125; 很明显上面的几个特征它都占了，那下面我们来看一段Go语言的测试case 123456789101112tests := []struct&#123; a, b, c int32&#125;&#123; &#123;2, 1, 1&#125;, &#123;1, 1, 3&#125;, &#123;0, 1, -1&#125;,&#125;for _, test := range tests &#123; if act := add(test.a, test.b); act != test.c &#123; // 相应的错误处理... &#125;&#125; 上述就是一个典型的表格驱动测试 表格驱动测试 分离测试数据和测试逻辑 明确的出错信息 可以部分失败 Go语言的语法使得我们更容易使用表格驱动测试的测试模式 2、实例演示说了这么多，我们通常又是如何写测试用例呢？首先下面是一段加法的代码 123456package calculatorfunc Add(a, b int32) int32 &#123; return a + b&#125; 现在就写上面的函数的测试用例 12345678910111213141516171819202122package calculatorimport ( \"testing\")func TestAdd(t *testing.T) &#123; tests := []struct&#123; a, b, c int32 &#125;&#123; &#123;1, 1, 2&#125;, &#123;-1, 1, 0&#125;, &#125; for _, test := range tests &#123; if act := Add(test.a, test.b); act != test.c &#123; t.Errorf(\"%d + %d != %d 实际为 %d\", test.a, test.b, test.c, act) &#125; &#125;&#125; 用IDE的同学直接点击 Run Test 就可以了，当然也同样支持命令行运行,进入到指定的文件目录下面 12sheng$ go test ./ok shengguocun.com/functional/calculator 0.006s 运行相关的执行命令就可以了，要是有错误的case依然不影响相关的测试的执行，比如： 123456789101112131415161718192021222324package calculatorimport ( \"testing\" \"math\")func TestAdd(t *testing.T) &#123; tests := []struct&#123; a, b, c int32 &#125;&#123; &#123;1, 1, 2&#125;, &#123;-1, 1, 0&#125;, &#123;math.MaxInt32, 1, math.MaxInt32&#125;, &#125; for _, test := range tests &#123; if act := Add(test.a, test.b); act != test.c &#123; t.Errorf(\"%d + %d != %d 实际为 %d\", test.a, test.b, test.c, act) &#125; &#125;&#125; 测试用例的执行结果为 12345sheng$ go test ./--- FAIL: TestAdd (0.00s) add_test.go:21: 2147483647 + 1 != 2147483647 实际为 -2147483648FAILFAIL shengguocun.com/functional/calculator 0.006s 我们需要将不符合预期的case做出检查，看是否是代码逻辑有问题，还是case的问题，这就是一个完整的测试用例的编写的过程。 7.1、代码覆盖率和性能测试1、代码覆盖率用IDE的同学我们会发现点击 Run Test 按钮的时候还有一个 with coverage 的选项 123456=== RUN TestAdd--- PASS: TestAdd (0.00s)PASScoverage: 100.0% of statementsProcess finished with exit code 0 这就是一个测试用例的代码覆盖率的结果。 IDE这块有详细的覆盖率报告，可以看到左侧的绿色就是代码的覆盖的范围，右侧有详细的每个文件的覆盖率。当然除了IDE之外命令行也是同样支持的 1234sheng$ go test -coverprofile=a.outPASScoverage: 100.0% of statementsok shengguocun.com/functional/calculator 0.006s 直接查看这个 a.out 文件，似乎看得不是很明白，当然我们有一个工具叫 go tool cover 1sheng$ go tool cover -html=a.out 运行上面的命令，就会展现一个下面的静态页面 这就是一个详细的覆盖率报告 2、性能测试对于程序员而言，代码的性能是每个人都会去关注的，Go语言在性能测试这块依然有它的独特见解 Benchmark 12345678910111213141516func BenchmarkAdd(b *testing.B) &#123; aa := int32(math.MaxInt32 / 16) bb := int32(math.MaxInt32 / 16) cc := int32(math.MaxInt32 / 8) - 1 for i := 0; i &lt; b.N; i ++ &#123; act := Add(aa, bb) if act != cc &#123; b.Errorf(\"%d + %d != %d 实际为 %d\", aa, bb, cc, act) &#125; &#125;&#125; 上面就是一段性能测试代码，我们不需要关注这段代码具体要跑多少次，Go语言自身会帮你决定，IDE点击 Run Test 完，输出相关的结果 1234567goos: darwingoarch: amd64pkg: shengguocun.com/functional/calculator2000000000 0.35 ns/opPASSProcess finished with exit code 0 总共跑了多少次以及每次的平均耗时，都会给出结果。当然同样支持命令行的交互方式 1234567sheng$ go test -bench .goos: darwingoarch: amd64pkg: shengguocun.com/functional/calculatorBenchmarkAdd-4 2000000000 0.34 ns/opPASSok shengguocun.com/functional/calculator 0.721s 7.2、使用pprof进行性能调优上面我们刚提到了性能测试，下一步自然就是我们该如何优化代码的性能，这里我们需要介绍一下Go语言的性能分析工具 pprof ，就依然用上面的这个例子进行阐述它的基本用法，我们要是想了解一段代码具体它慢在哪里，首先呢我们先让它生成一个cpuprofile 1234567sheng$ go test -bench . -cpuprofile=cpu.outgoos: darwingoarch: amd64pkg: shengguocun.com/functional/calculatorBenchmarkAdd-4 2000000000 0.34 ns/opPASSok shengguocun.com/functional/calculator 0.916s 这时候我们发现现在多了一个 cpu.out 文件 12sheng$ lsa.out add.go add_test.go calculator.test cpu.out 查看之后你会发现是一个二进制文件，那我们该如何处理呢？Go语言的 pprof 就要登场了 12sheng$ less cpu.out\"cpu.out\" may be a binary file. See it anyway? 1234567sheng$ go tool pprof cpu.outMain binary filename not available.Type: cpuTime: May 9, 2018 at 5:40pm (CST)Duration: 907.82ms, Total samples = 600ms (66.09%)Entering interactive mode (type \"help\" for commands, \"o\" for options)(pprof) 这时候出现了一个交互式的命令行，我们可以通过输入 help 得到相关的使用说明 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172(pprof) help Commands: callgrind Outputs a graph in callgrind format comments Output all profile comments disasm Output assembly listings annotated with samples dot Outputs a graph in DOT format eog Visualize graph through eog evince Visualize graph through evince gif Outputs a graph image in GIF format gv Visualize graph through gv kcachegrind Visualize report in KCachegrind list Output annotated source for functions matching regexp pdf Outputs a graph in PDF format peek Output callers/callees of functions matching regexp png Outputs a graph image in PNG format proto Outputs the profile in compressed protobuf format ps Outputs a graph in PS format raw Outputs a text representation of the raw profile svg Outputs a graph in SVG format tags Outputs all tags in the profile text Outputs top entries in text form top Outputs top entries in text form topproto Outputs top entries in compressed protobuf format traces Outputs all profile samples in text form tree Outputs a text rendering of call graph web Visualize graph through web browser weblist Display annotated source in a web browser o/options List options and their current values quit/exit/^D Exit pprof Options: call_tree Create a context-sensitive call tree compact_labels Show minimal headers divide_by Ratio to divide all samples before visualization drop_negative Ignore negative differences edgefraction Hide edges below &lt;f&gt;*total focus Restricts to samples going through a node matching regexp hide Skips nodes matching regexp ignore Skips paths going through any nodes matching regexp mean Average sample value over first value (count) nodecount Max number of nodes to show nodefraction Hide nodes below &lt;f&gt;*total normalize Scales profile based on the base profile. output Output filename for file-based outputs positive_percentages Ignore negative samples when computing percentages prune_from Drops any functions below the matched frame. relative_percentages Show percentages relative to focused subgraph sample_index Sample value to report (0-based index or name) show Only show nodes matching regexp source_path Search path for source files tagfocus Restricts to samples with tags in range or matched by regexp taghide Skip tags matching this regexp tagignore Discard samples with tags in range or matched by regexp tagshow Only consider tags matching this regexp trim Honor nodefraction/edgefraction/nodecount defaults unit Measurement units to display Option groups (only set one per group): cumulative cum Sort entries based on cumulative weight flat Sort entries based on own weight granularity addresses Aggregate at the function level. addressnoinlines Aggregate at the function level, including functions' addresses in the output. files Aggregate at the file level. functions Aggregate at the function level. lines Aggregate at the source code line level. noinlines Aggregate at the function level. : Clear focus/ignore/hide/tagfocus/tagignore type \"help &lt;cmd|option&gt;\" for more information(pprof) 我们这里就介绍一个最简单的方式，敲入web回车,z这里做一个温馨提示 12(pprof) webFailed to execute dot. Is Graphviz installed? Error: exec: \"dot\": executable file not found in $PATH 出现上述报错的，是因为Graphviz没有安装，安装好了之后再敲入web会生成一个SVG文件,用浏览器打开它 一张图可以很明显的表现出哪边花的时间多哪边花的时间少，当然也可以从框框的大小来做判断，我们需要优化比较大的框框的部分。上述的代码因为太过于简单，大家可以试着用自己写的代码进行性能分析。 7.3、生成文档和事例代码在我们实际的开发过程中，文档的重要性不必多说，服务调用方、协同开发的小伙伴、QA都需要文档；其他的语言我们经常需要依赖其他的文档工具，比如：ApiDoc、doxmate、daux等等。首先我们先介绍一下 go doc 的常规的用法 1234sheng$ go docpackage calculator // import \"shengguocun.com/functional/calculator\"func Add(a, b int32) int32 12sheng$ go doc Addfunc Add(a, b int32) int32 除此之外呢，我们可以通过help来查看 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102sheng$ go help docusage: go doc [-u] [-c] [package|[package.]symbol[.methodOrField]]Doc prints the documentation comments associated with the item identified by itsarguments (a package, const, func, type, var, method, or struct field)followed by a one-line summary of each of the first-level items \"under\"that item (package-level declarations for a package, methods for a type,etc.).Doc accepts zero, one, or two arguments.Given no arguments, that is, when run as go docit prints the package documentation for the package in the current directory.If the package is a command (package main), the exported symbols of the packageare elided from the presentation unless the -cmd flag is provided.When run with one argument, the argument is treated as a Go-syntax-likerepresentation of the item to be documented. What the argument selects dependson what is installed in GOROOT and GOPATH, as well as the form of the argument,which is schematically one of these: go doc &lt;pkg&gt; go doc &lt;sym&gt;[.&lt;methodOrField&gt;] go doc [&lt;pkg&gt;.]&lt;sym&gt;[.&lt;methodOrField&gt;] go doc [&lt;pkg&gt;.][&lt;sym&gt;.]&lt;methodOrField&gt;The first item in this list matched by the argument is the one whose documentationis printed. (See the examples below.) However, if the argument starts with a capitalletter it is assumed to identify a symbol or method in the current directory.For packages, the order of scanning is determined lexically in breadth-first order.That is, the package presented is the one that matches the search and is nearestthe root and lexically first at its level of the hierarchy. The GOROOT tree isalways scanned in its entirety before GOPATH.If there is no package specified or matched, the package in the currentdirectory is selected, so \"go doc Foo\" shows the documentation for symbol Foo inthe current package.The package path must be either a qualified path or a proper suffix of apath. The go tool's usual package mechanism does not apply: package pathelements like . and ... are not implemented by go doc.When run with two arguments, the first must be a full package path (not just asuffix), and the second is a symbol, or symbol with method or struct field.This is similar to the syntax accepted by godoc: go doc &lt;pkg&gt; &lt;sym&gt;[.&lt;methodOrField&gt;]In all forms, when matching symbols, lower-case letters in the argument matcheither case but upper-case letters match exactly. This means that there may bemultiple matches of a lower-case argument in a package if different symbols havedifferent cases. If this occurs, documentation for all matches is printed.Examples: go doc Show documentation for current package. go doc Foo Show documentation for Foo in the current package. (Foo starts with a capital letter so it cannot match a package path.) go doc encoding/json Show documentation for the encoding/json package. go doc json Shorthand for encoding/json. go doc json.Number (or go doc json.number) Show documentation and method summary for json.Number. go doc json.Number.Int64 (or go doc json.number.int64) Show documentation for json.Number's Int64 method. go doc cmd/doc Show package docs for the doc command. go doc -cmd cmd/doc Show package docs and exported symbols within the doc command. go doc template.new Show documentation for html/template's New function. (html/template is lexically before text/template) go doc text/template.new # One argument Show documentation for text/template's New function. go doc text/template new # Two arguments Show documentation for text/template's New function. At least in the current tree, these invocations all print the documentation for json.Decoder's Decode method: go doc json.Decoder.Decode go doc json.decoder.decode go doc json.decode cd go/src/encoding/json; go doc decodeFlags: -c Respect case when matching symbols. -cmd Treat a command (package main) like a regular package. Otherwise package main's exported symbols are hidden when showing the package's top-level documentation. -u Show documentation for unexported as well as exported symbols, methods, and fields. 再比如我们可以查看系统的文档 12345678910111213sheng$ go doc json.Decoder.Decodefunc (dec *Decoder) Decode(v interface&#123;&#125;) error Decode reads the next JSON-encoded value from its input and stores it in the value pointed to by v. See the documentation for Unmarshal for details about the conversion of JSON into a Go value.sheng$ go doc fmt.Printffunc Printf(format string, a ...interface&#123;&#125;) (n int, err error) Printf formats according to a format specifier and writes to standard output. It returns the number of bytes written and any write error encountered. 当然我们最常用的命令是 godoc ，我们help看一下它的基本用法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849sheng$ godoc -helpusage: godoc package [name ...] godoc -http=:6060 -analysis string comma-separated list of analyses to perform (supported: type, pointer). See http://golang.org/lib/godoc/analysis/help.html -ex show examples in command line mode -goroot string Go root directory (default \"/usr/local/Cellar/go/1.10.2/libexec\") -html print HTML in command-line mode -http string HTTP service address (e.g., ':6060') -httptest.serve string if non-empty, httptest.NewServer serves on this address and blocks -index enable search index -index_files string glob pattern specifying index files; if not empty, the index is read from these files in sorted order -index_interval duration interval of indexing; 0 for default (5m), negative to only index once at startup -index_throttle float index throttle value; 0.0 = no time allocated, 1.0 = full throttle (default 0.75) -links link identifiers to their declarations (default true) -maxresults int maximum number of full text search results shown (default 10000) -notes string regular expression matching note markers to show (default \"BUG\") -play enable playground in web interface -q arguments are considered search queries -server string webserver address for command line searches -src print (exported) source in command-line mode -tabwidth int tab width (default 4) -templates string load templates/JS/CSS from disk in this directory -timestamps show timestamps with directory listings -url string print HTML for named URL -v verbose mode -write_index write index to a file; the file name must be specified with -index_files -zip string zip file providing the file system to serve; disabled if empty 我们看到有个http的用法，现在我们试一下 1sheng$ godoc -http :6060 打开浏览器，输入 http://localhost:6060 完整的Web版的Go语言的文档就可以使用了。当然不单单包含系统函数，同时还包含我们自己写的函数的文档，现在我们就演示一下 12345// 加法函数func Add(a, b int32) int32 &#123; return a + b&#125; 我们在函数前面加上了注释，这是我们重新启动 godoc -http :6060 我们会发现 相关的注释已经加上了。Go语言除此之外还提供了写示例代码的方法 12345678func ExampleAdd() &#123; c := Add(1, 3) fmt.Println(c) // Output: // 1&#125; 直接添加一个 ExampleAdd 函数，还是像之前一样写代码，最后我们要写一个 Output 的注释，那你现在是否有疑问，下面的 1 是什么意思？这里说下，这是我随便写的，这时候 Run Test 这段代码 123456789=== RUN ExampleAdd--- FAIL: ExampleAdd (0.00s)got:4want:1FAILProcess finished with exit code 1 我们再把正确的输出贴到上面的输出中，重启godoc 这时候完整的示例代码就已经生成到文档中了。 8. Goroutine8.0、Goroutine介绍协程 Coroutine轻量级”线程”上面的两个特征到底是什么意思呢？下面我们通过具体的事例详细的讲述一下， 1234567891011121314package mainimport \"fmt\"func main() &#123; for i := 0; i &lt; 10; i ++ &#123; func(i int)&#123; for &#123; fmt.Println(\"Goroutine :\" , i) &#125; &#125;(i) &#125;&#125; 上面这段代码有问题么? 这就是一个从 0 到 10 的调用，但是匿名函数内部没有中止条件，所以会进入一个死循环。要是我们在匿名函数前加上 go 关键字，就不是刚才的意思了，就变成并发执行这个函数。主程序继续向下跑，同时并发开了一个函数，就相当于开了一个线程，当然我们后面会继续介绍，这个叫 协程 1234567891011121314package mainimport \"fmt\"func main() &#123; for i := 0; i &lt; 10; i ++ &#123; go func(i int)&#123; for &#123; fmt.Println(\"Goroutine :\" , i) &#125; &#125;(i) &#125;&#125; 我们再执行这段代码，发现什么都没有输出，这又是为什么呢？因为这个 main 和 fmt.Println 是并发执行的，我们还来不及print结果， main 就执行完成退出了。Go语言一旦main函数退出了，所有的Goroutine就被杀掉了。当然要是想看到输出结果，main函数可以在最后sleep一下 123456789101112131415161718package mainimport ( \"fmt\" \"time\")func main() &#123; for i := 0; i &lt; 10; i ++ &#123; go func(i int)&#123; for &#123; fmt.Println(\"Goroutine :\" , i) &#125; &#125;(i) &#125; time.Sleep(time.Millisecond)&#125; 这时候就有相关的结果输出了。那我们将现在的10改成1000，又会怎样呢？当然还是可以正常输出的，熟悉操作系统的都知道正常的线程几十个上百个是没啥问题的，1000个还是有点难度的，其它语言通常使用异步IO的方式。在Go语言中我们不用管10个、100个、1000个代码还是一样的写法。 非抢占式多任务处理，由协程主动交出控制权非抢占式多任务 这又是什么意思呢？下面我们用一个例子来解释一下 1234567891011121314151617181920package mainimport ( \"time\" \"fmt\")func main() &#123; var a [10]int for i := 0; i &lt; 10; i ++ &#123; go func(i int)&#123; for &#123; a[i] ++ &#125; &#125;(i) &#125; time.Sleep(time.Millisecond) fmt.Println(a)&#125; 在运行之前，可以想一下会输出什么呢? 什么也没有输出，进入了死循环。 上图是我的活动监视器的截图，因为是4核的机器，几乎全部占满了。退不出的原因是因为Goroutine a[i] 交不出控制权，没有yield出去，同时main函数也是一个goroutine，因为没人交出控制权，所以下面的sleep永远也不会执行。那我该如何交出控制权呢？我们可以做一个IO操作可以交出控制权，当然也可以手动交出控制权 12345678910111213141516171819202122package mainimport ( \"time\" \"fmt\" \"runtime\")func main() &#123; var a [10]int for i := 0; i &lt; 10; i ++ &#123; go func(i int)&#123; for &#123; a[i] ++ runtime.Gosched() &#125; &#125;(i) &#125; time.Sleep(time.Millisecond) fmt.Println(a)&#125; 只需要加上 runtime.Gosched() ，这样大家都主动让出控制权，这时候代码可以正常输出了 123[321 986 890 880 831 881 919 904 861 904]Process finished with exit code 0 如果我们把goroutine的参数 i 去掉会怎样呢？直接的看语法上没有什么问题，就变成了一个闭包，使用外部的变量 i ， 12345678910111213141516171819202122package mainimport ( \"time\" \"fmt\" \"runtime\")func main() &#123; var a [10]int for i := 0; i &lt; 10; i ++ &#123; go func()&#123; for &#123; a[i] ++ runtime.Gosched() &#125; &#125;() &#125; time.Sleep(time.Millisecond) fmt.Println(a)&#125; 运行之后会出现什么问题呢？ 123456789panic: runtime error: index out of rangegoroutine 6 [running]:main.main.func1(0xc42001a0f0, 0xc42001c060) /Users/verton/GoLangProject/src/shengguocun.com/goroutine/route.go:15 +0x45created by main.main /Users/verton/GoLangProject/src/shengguocun.com/goroutine/route.go:13 +0x95Process finished with exit code 2 这里我们通过Go语言的 go run -race xxx.go ，执行分析一下 123456789101112131415sheng$ go run -race route.go==================WARNING: DATA RACERead at 0x00c420092008 by goroutine 6: main.main.func1() /Users/verton/GoLangProject/src/shengguocun.com/goroutine/route.go:15 +0x54Previous write at 0x00c420092008 by main goroutine: main.main() /Users/verton/GoLangProject/src/shengguocun.com/goroutine/route.go:12 +0x11bGoroutine 6 (running) created at: main.main() /Users/verton/GoLangProject/src/shengguocun.com/goroutine/route.go:13 +0xf1================== 这个地址 0x00c420092008 是谁呢，很显然就是 i ，原因是因为在最后跳出来的时候 i 会变成10，里面的 a[i] ++ 就会是a[10] ，所以出错的原因就在这。 123456789101112131415sheng$ go run -race route.go==================WARNING: DATA RACERead at 0x00c420092008 by goroutine 6: main.main.func1() /Users/verton/GoLangProject/src/shengguocun.com/goroutine/route.go:15 +0x54Previous write at 0x00c420092008 by main goroutine: main.main() /Users/verton/GoLangProject/src/shengguocun.com/goroutine/route.go:12 +0x11bGoroutine 6 (running) created at: main.main() /Users/verton/GoLangProject/src/shengguocun.com/goroutine/route.go:13 +0xf1================== 上面还剩一个的两个Goroutine读写的问题需要我们后面介绍的Channel来解决。 8.1、Go语言调度器多个协程可能在一个或多个线程上运行首先我们先看一张普通函数和协程的对比图 普通函数main函数和work函数都运行在一个线程里面，main函数在等work函数执行完才能执行其他的操作。可以看到普通函数 main 函数和 work 函数是单向的，但是发现协程的 main 和 work 是双向通道的，控制权可以在work也可以在main，不需要像普通函数那样等work函数执行完才交出控制权。协程中main和work可能执行在一个线程中，有可能执行在多个线程中。 上图就是Go语言的协程， 首先下面会有一个调度器，负责调度协程，有些是一个goroutine放在一个线程里面，有的是两个，有的是多个，这些我们都不需要关注。 goroutine定义 任何函数只需要加上go就能送给调度器运行 不需要在定义时区分是否是异步函数 调度器在合适的点进行切换 使用-race来检测数据访问冲突 goroutine可能的切换点 I/O 、select channel 等待锁 函数调用（有时） runtime.Gosched() 上述仅是参考，不能保证切换，不能保证在其他的地方不切换 9. Channel9.0、Channel介绍Channel 我们可以开很多个goroutine，goroutine和goroutine之间的双向通道就是channel。首先我们先来介绍一下channel的用法 1ch := make(chan int) 和其他类型类似，都是需要先创建声明 123456789101112131415161718192021package mainimport ( \"fmt\" \"time\")func main() &#123; ch := make(chan int) go func() &#123; for &#123; num := &lt;- ch fmt.Println(num) &#125; &#125;() ch &lt;- 1 ch &lt;- 2 time.Sleep(time.Millisecond)&#125; 这就是一个简单的channel示例，同时channel是一等公民，可以作为参数也可以作为返回值，那我们就用一个例子来简单的演示一下 1234567891011121314151617181920212223242526272829303132333435package mainimport ( \"fmt\" \"time\")func work(channels chan int, num int) &#123; for ch := range channels &#123; fmt.Println(\"Work ID :\", num) fmt.Println(ch) &#125;&#125;func createWork(num int) chan&lt;- int &#123; ch := make(chan int) go work(ch, num) return ch&#125;func main() &#123; var channels [10]chan&lt;- int for i := 0; i &lt; 10; i ++ &#123; channels[i] = createWork(i) &#125; for i := 0; i &lt; 10; i ++ &#123; channels[i] &lt;- 'M' + i &#125; time.Sleep(time.Millisecond)&#125; 输出结果为 1234567891011121314151617181920Work ID : 380Work ID : 077Work ID : 178Work ID : 6Work ID : 983Work ID : 4Work ID : 5828681Work ID : 885Work ID : 279Work ID : 784 结果为什么是乱序的呢？因为 fmt.Println 有I/O操作；上述例子，可以看到channel既可以作参数，也可以作为返回值。 Buffer Channel12ch := make(chan int)ch &lt;- 1 我们要是光发送，没有接收是不行的，程序会报错,比如上述代码运行之后 12345fatal error: all goroutines are asleep - deadlock!goroutine 1 [chan send]:main.main() /Users/verton/GoLangProject/src/shengguocun.com/channel/channel.go:42 +0x50 我们可以设置一个缓冲区 12ch := make(chan int, 5)ch &lt;- 1 缓冲区大小设置为5，只要发送不超过5个都不会报错，下面我们来演示一下buffer channel的使用 12345678910111213141516func main() &#123; channels := make(chan int, 5) go func() &#123; for ch := range channels &#123; fmt.Println(ch) &#125; &#125;() channels &lt;- 1 channels &lt;- 2 channels &lt;- 3 channels &lt;- 4 channels &lt;- 5 time.Sleep(time.Millisecond)&#125; 结果输出正常 123456712345Process finished with exit code 0 比如我们确定数据结束了，可以在最后进行close；同时只能是发送方close的 1234567891011121314151617func main() &#123; channels := make(chan int, 5) go func() &#123; for ch := range channels &#123; fmt.Println(ch) &#125; &#125;() channels &lt;- 1 channels &lt;- 2 channels &lt;- 3 channels &lt;- 4 channels &lt;- 5 close(channels) time.Sleep(time.Millisecond)&#125; 直观地从输出结果来看，加不加close这两者是没有区别的。 9.1、使用Channel等待任务结束前面的例子中我们等待任务结束是通过sleep来处理，因为打印的数据较少，1 毫秒足够；但是这种方式等待任务结束显然不是很优雅。对于任务结束首先我们需要确定的通知外面我们打印结束了，那我们又如何通知呢？在Go语言中我们不要通过共享内存来通信，而是要通过通信来共享内存。直接用Channel就可以，下面我们来改造上面的例子 123456789101112131415161718192021222324252627282930313233343536373839404142package mainimport ( \"fmt\")type worker struct &#123; in chan int done chan bool&#125;func work(in chan int, done chan bool, num int) &#123; for ch := range in &#123; fmt.Println(\"Work ID :\", num) fmt.Println(ch) done&lt;- true &#125;&#125;func createWork(num int) worker &#123; ch := worker&#123; in: make(chan int), done: make(chan bool), &#125; go work(ch.in, ch.done, num) return ch&#125;func main() &#123; var workers [10]worker for i := 0; i &lt; 10; i ++ &#123; workers[i] = createWork(i) &#125; for i := 0; i &lt; 10; i ++ &#123; workers[i].in &lt;- 'M' + i &lt;-workers[i].done &#125;&#125; 打印输出结果 1234567891011121314151617181920Work ID : 077Work ID : 178Work ID : 279Work ID : 380Work ID : 481Work ID : 582Work ID : 683Work ID : 784Work ID : 885Work ID : 986 虽然sleep部分的代码已经删除了，但是发现是顺序打印的，这显然不是我想要的结果。Go语言对等待多任务完成提供了一个库 WaitGroup，下面我们就用它继续重构上述的代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package mainimport ( \"fmt\" \"sync\")type worker struct &#123; in chan int done func()&#125;func work(worker worker, num int) &#123; for ch := range worker.in &#123; fmt.Println(\"Work ID :\", num) fmt.Println(ch) worker.done() &#125;&#125;func createWork(num int, wg *sync.WaitGroup) worker &#123; worker := worker&#123; in: make(chan int), done: func() &#123; wg.Done() // 每个任务做完了就调用Done &#125;, &#125; go work(worker, num) return worker&#125;func main() &#123; var wg sync.WaitGroup var workers [10]worker for i := 0; i &lt; 10; i ++ &#123; workers[i] = createWork(i, &amp;wg) &#125; wg.Add(10) // Add 总共有多少个任务 for i := 0; i &lt; 10; i ++ &#123; workers[i].in &lt;- 'M' + i &#125; wg.Wait() // 等待所有的任务做完&#125; 结果输出 12345678910111213141516171819202122Work ID : 481Work ID : 582Work ID : 178Work ID : 279Work ID : 6Work ID : 380Work ID : 0Work ID : 9868377Work ID : 784Work ID : 885Process finished with exit code 0 这样相应的结果才是我们想要的。 面试题实战1协程交替执行,使其能顺序输出1-20的自然数 这个问题就不做演示了，留给读者自行发挥。 9.2、用select进行调度1、select使用首先我们先来介绍一下select常规的应用场景，比如 1var ch1, ch2 chan int 我们有两个channel，我们想从 ch1、ch2 里面收数据， 123var ch1, ch2 chan intdata1 := &lt;- ch1data2 := &lt;- ch2 谁快我就要谁，这就是我们的select 12345678910111213141516171819package mainimport ( \"fmt\")func main() &#123; var ch1, ch2 chan int select &#123; case data := &lt;- ch1: fmt.Println(\"CH1 的数据：\", data) case data := &lt;-ch2: fmt.Println(\"CH2 的数据：\", data) default: fmt.Println(\"没收到 CH1、CH2 的数据\") &#125;&#125; 这就相当于做了一个非阻塞式的获取。下面我们就结合一个channel生成器来做一个例子演示 1234567891011121314151617181920212223242526272829303132333435package mainimport ( \"fmt\" \"time\" \"math/rand\")func genChan() chan int &#123; out := make(chan int) go func() &#123; i := 0 for &#123; time.Sleep(time.Millisecond * time.Duration(rand.Intn(1000))) out &lt;- i i ++ &#125; &#125;() return out&#125;func main() &#123; var ch1, ch2 = genChan(), genChan() for &#123; select &#123; case data := &lt;- ch1: fmt.Println(\"CH1 的数据：\", data) case data := &lt;-ch2: fmt.Println(\"CH2 的数据：\", data) &#125; &#125;&#125; 输出结果（部分） 1234567891011121314151617181920212223242526272829303132CH1 的数据： 0CH2 的数据： 0CH1 的数据： 1CH2 的数据： 1CH1 的数据： 2CH2 的数据： 2CH1 的数据： 3CH2 的数据： 3CH1 的数据： 4CH2 的数据： 4CH1 的数据： 5CH2 的数据： 5CH2 的数据： 6CH1 的数据： 6CH1 的数据： 7CH1 的数据： 8CH2 的数据： 7CH1 的数据： 9CH2 的数据： 8CH1 的数据： 10CH2 的数据： 9CH1 的数据： 11CH1 的数据： 12CH1 的数据： 13CH2 的数据： 10CH2 的数据： 11CH1 的数据： 14CH2 的数据： 12CH2 的数据： 13CH1 的数据： 15Process finished with exit code 130 (interrupted by signal 2: SIGINT) 这就是select的一个应用场景，从输出结果可以看到，CH1、CH2的输出结果不一样，谁先出数据就先选择谁；两个同时出就随机的选择一个。 2、定时器的使用比如上面的这段代码我想要在10秒之后程序就终止，我该如何处理呢？我们这里需要介绍一下Go语言的 time.After 123456789// After waits for the duration to elapse and then sends the current time// on the returned channel.// It is equivalent to NewTimer(d).C.// The underlying Timer is not recovered by the garbage collector// until the timer fires. If efficiency is a concern, use NewTimer// instead and call Timer.Stop if the timer is no longer needed.func After(d Duration) &lt;-chan Time &#123; return NewTimer(d).C&#125; 从源码来看，他的返回值类型是一个 &lt;-chan Time ,那就方便很多了 12345678910111213141516171819202122232425262728293031323334353637package mainimport ( \"fmt\" \"time\")func genChan() chan int &#123; out := make(chan int) go func() &#123; i := 0 for &#123; time.Sleep(time.Second) out &lt;- i i ++ &#125; &#125;() return out&#125;func main() &#123; var ch1, ch2 = genChan(), genChan() tm := time.After(10 * time.Second) // 加上10秒的定时 for &#123; select &#123; case data := &lt;- ch1: fmt.Println(\"CH1 的数据：\", data) case data := &lt;-ch2: fmt.Println(\"CH2 的数据：\", data) case &lt;-tm: return // 收到指令程序直接return &#125; &#125;&#125; 运行到10秒，代码自动退出。 9.3、传统同步机制Go语言除了CSP模型外，还是有传统同步机制的，比如互斥量 Mutex ，现在我们就用它举个例子：用互斥量实现 atomic 1234567891011121314151617181920212223242526272829303132333435package mainimport ( \"sync\" \"time\" \"fmt\")type atomicInt struct &#123; value int lock sync.Mutex&#125;func increment(a *atomicInt) &#123; a.lock.Lock() defer a.lock.Unlock() a.value ++&#125;func get(a *atomicInt) int &#123; a.lock.Lock() defer a.lock.Unlock() return a.value&#125;func main() &#123; var a atomicInt increment(&amp;a) go func() &#123; increment(&amp;a) &#125;() time.Sleep(time.Second) fmt.Println(get(&amp;a))&#125; 结果输出 1232Process finished with exit code 0 代码写完，可以用上面介绍的race来检查一下，是否有冲突，是否安全；当然这里还是不建议自己来造这些轮子的，直接使用系统的就可以了。系统提供了 atomic.AddInt32() 等等这些原子操作。 10. Http及其他标准库10.0、Http标准库介绍Go语言有很多的标准库，http库是最重要的之一，它对Http的封装也是非常完善的，之前我们有演示过服务端的一些基础使用，下面我们介绍一些客户端相关的使用 1、使用http客户端发送请求12345678910111213141516171819202122package mainimport ( \"net/http\" \"net/http/httputil\" \"fmt\")func main() &#123; response, err := http.Get(\"https://www.shengguocun.com\") if err != nil&#123; panic(err) &#125; defer response.Body.Close() ss, err := httputil.DumpResponse(response, true) if err != nil &#123; panic(err) &#125; fmt.Printf(\"%s \\n\", ss)&#125; 这里就把完整的头信息以及html的部分打印出来了。比如在我们现实的情境中，我们会根据UA做一些反作弊的策略，以及是否需要重定向到 M 端等等。这里的 http.Client 就能实现。 2、使用http.Client控制请求头请求头信息直接通过 request.Header.Add 添加就可以了 123456789101112131415161718192021222324package mainimport ( \"net/http\" \"net/http/httputil\" \"fmt\")func main() &#123; request, err := http.NewRequest(http.MethodGet,\"https://www.shengguocun.com\", nil) request.Header.Add(\"User-Agent\", \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36\") response, err := http.DefaultClient.Do(request) if err != nil&#123; panic(err) &#125; defer response.Body.Close() ss, err := httputil.DumpResponse(response, true) if err != nil &#123; panic(err) &#125; fmt.Printf(\"%s \\n\", ss)&#125; 上面我们都用的是 DefaultClient ，我们也可以自己创建 client， 首先我们先看一下 Client 内部都有些什么 查看源码我们发现有一个 CheckRedirect ，我们发现这是一个检查重定向的函数。那我们就用它做一下演示 123456789101112131415161718192021222324252627282930package mainimport ( \"net/http\" \"net/http/httputil\" \"fmt\")func main() &#123; request, err := http.NewRequest(http.MethodGet,\"https://jim-sheng.github.io\", nil) request.Header.Add(\"User-Agent\", \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36\") client := http.Client&#123; CheckRedirect: func(req *http.Request, via []*http.Request) error &#123; fmt.Println(\"重定向地址：\", req) return nil &#125;, &#125; response, err := client.Do(request) if err != nil&#123; panic(err) &#125; defer response.Body.Close() ss, err := httputil.DumpResponse(response, true) if err != nil &#123; panic(err) &#125; fmt.Printf(\"%s \\n\", ss)&#125; 输出结果（部分） 1234重定向地址： &amp;&#123;GET https://www.shengguocun.com/ 0 0 map[User-Agent:[Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36] Referer:[https://jim-sheng.github.io]] &lt;nil&gt; &lt;nil&gt; 0 [] false map[] map[] &lt;nil&gt; map[] &lt;nil&gt; &lt;nil&gt; 0xc42012c090 &lt;nil&gt;&#125;HTTP/2.0 200 OKAccept-Ranges: bytesAccess-Control-Allow-Origin: * 我们可以看到具体的重定向的地址 https://www.shengguocun.com/ ，其它的 1234// Transport specifies the mechanism by which individual// HTTP requests are made.// If nil, DefaultTransport is used.Transport RoundTripper 主要用于代理 12345678910// Jar specifies the cookie jar.//// The Jar is used to insert relevant cookies into every// outbound Request and is updated with the cookie values// of every inbound Response. The Jar is consulted for every// redirect that the Client follows.//// If Jar is nil, cookies are only sent if they are explicitly// set on the Request.Jar CookieJar 主要用于模拟登录用的 123456789101112131415161718// Timeout specifies a time limit for requests made by this// Client. The timeout includes connection time, any// redirects, and reading the response body. The timer remains// running after Get, Head, Post, or Do return and will// interrupt reading of the Response.Body.//// A Timeout of zero means no timeout.//// The Client cancels requests to the underlying Transport// using the Request.Cancel mechanism. Requests passed// to Client.Do may still set Request.Cancel; both will// cancel the request.//// For compatibility, the Client will also use the deprecated// CancelRequest method on Transport if found. New// RoundTripper implementations should use Request.Cancel// instead of implementing CancelRequest.Timeout time.Duration 主要设置超时的 3、http服务器性能分析还是使用之前的代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package mainimport ( \"net/http\" \"os\" \"io/ioutil\" _ \"net/http/pprof\")type appHandler func(writer http.ResponseWriter, request *http.Request) errorfunc errWrapper(handler appHandler) func(http.ResponseWriter, *http.Request) &#123; return func(writer http.ResponseWriter, request *http.Request) &#123; err := handler(writer, request) if err != nil &#123; switch &#123; case os.IsNotExist(err): http.Error(writer, http.StatusText(http.StatusNotFound), http.StatusNotFound) &#125; &#125; &#125;&#125;func main() &#123; http.HandleFunc(\"/list/\", errWrapper(func(writer http.ResponseWriter, request *http.Request) error &#123; path := request.URL.Path[len(\"/list/\"):] file, err := os.Open(path) if err != nil &#123; return err &#125; defer file.Close() all, err := ioutil.ReadAll(file) if err != nil &#123; return err &#125; writer.Write(all) return nil &#125;)) err := http.ListenAndServe(\":2872\", nil) if err != nil &#123; panic(err) &#125;&#125; 还是一样的代码，只不过import多了一个 import _ &quot;net/http/pprof&quot; , 为什么会多一个下划线呢？因为代码没有使用到，会报错，加一个下划线就可以了。重启代码，我们就可以访问 http://localhost:2872/debug/pprof/ 了 里面的 stacktrace 都可以查看到 我们可以查看 pprof 的源码，继续查看它的其他的使用方式 123// Or to look at a 30-second CPU profile://// go tool pprof http://localhost:6060/debug/pprof/profile 比如这一段，我们可以查看30秒的CPU的使用情况。可以终端敲下该命令（替换成自己的监听的端口），获取出结果后敲下 web 命令就可以看下具体的代码哪些地方需要优化。其他的使用使用方式就不一一罗列了，有兴趣可以继续查阅。 10.1、其他库其它的标准库就不过多罗列了， https://studygolang.com/pkgdoc 上面的中文版的文档已经非常详细了 。 11. 总结Go语言给我们展现了不一样的世界观，没有类、继承、多态、重载，没有构造函数，没有断言，没有try/catch等等；上面是在学习Go语言的过程中，记录下来的笔记；也可能有部分地方存在偏颇，还望指点～～～ 欢迎关注个人微信公众号","tags":[{"name":"Go语言","slug":"Go语言","permalink":"https://www.shengguocun.com/tags/Go语言/"},{"name":"入门","slug":"入门","permalink":"https://www.shengguocun.com/tags/入门/"}]},{"title":"GDB抓虫之旅","date":"2018-03-15T05:59:24.000Z","path":"/blog/2018/03/15/taste-gdb/","text":"前言1234567891011问: gdb是什么？答: 强大的UNIX下命令行调试工具。问: gdb能干什么？答: 让你随心所欲的驾驭你的程序；Start、Stop、Examine、Change。问: 我们为什么要学习gdb？答: 欲善其事，必先利其器；利用gdb进一步的定位程序异常。问: 本次分享的宗旨?答: gdb的介绍和使用入门，为大家抓虫多提供一个选择。 抓虫从0开始前期准备 1.包含有调试信息的可执行文件 2.编译时加-g选项即可，不建议开优化选项 GDB的启动1234gdb &lt;program&gt;gdb &lt;program&gt; coregdb &lt;program&gt; &lt;PID&gt;(gdb) file &lt;program&gt; 抓虫流程 实战1 : GDB基础命令的使用1.1、示例程序(example_1.cpp) 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int foo(int m, int n)&#123; return 1;&#125;int foo(int n)&#123; int result=0; for (int i=0;i&lt;=n;i++) &#123; result+=n; &#125; return result;&#125;int main()&#123; string s1=\"dafdf\"; char * s2;// s1=s2; int sum =0; for (int i=1;i&lt;=100;i++) &#123; sum+=i; &#125; cout&lt;&lt;\"result[1-100]=\"&lt;&lt;sum&lt;&lt;endl; cout&lt;&lt;\"result[1-250]=\"&lt;&lt;foo(250)&lt;&lt;endl; return 0;&#125; 1.2、调试准备编译命令：g++ -g -Wall -o example_1 example_1.cpp 1.3、启动gdb 12345678$ gdb example_1GNU gdb Red Hat Linux (6.3.0.0-1.96rh)Copyright 2004 Free Software Foundation, Inc.GDB is free software, covered by the GNU General Public License, and you arewelcome to change it and/or distribute copies of it under certain conditions.Type \"show copying\" to see the conditions.There is absolutely no warranty for GDB. Type \"show warranty\" for details.This GDB was configured as \"x86_64-redhat-linux-gnu\"...Using host libthread_db library \"/lib64/tls/libthread_db.so.1\". 1.4、辅助性命令 12345678910111213141516(gdb) cd ..Working directory /home/work/testers/sgc.(gdb) shell lsautotest client Makefile spanti spantispam_if.h study(gdb) cd study/Working directory /home/work/testers/sgc/study.(gdb) pwdWorking directory /home/work/testers/sgc/study.(gdb) help runStart debugged program. You may specify arguments to give it.Args may include \"*\", or \"[...]\"; they are expanded using \"sh\".Input and output redirection with \"&gt;\", \"&lt;\", or \"&gt;&gt;\" are also allowed.With no arguments, uses arguments last specified (with \"run\" or \"set args\").To cancel previous arguments and run with no arguments,use \"set args\" without arguments. 1.5、设置断点命令 123456789101112131415161718192021222324252627282930313233343536373839404142434445//查看源代码信息(gdb) l17 result+=n;18 &#125;19 return result;2021 &#125;2223 int main()24 &#123;2526 string s1=\"dafdf\";(gdb) l 11 #include &lt;iostream&gt;2 #include &lt;string&gt;345 using namespace std;6 int foo(int m, int n)7 &#123;89 return 1;10(gdb) l example_1.cpp:1611 &#125;12 int foo(int n)13 &#123;14 int result=0;15 for (int i=0;i&lt;=n;i++)16 &#123;17 result+=n;18 &#125;19 return result;20(gdb) l foo(int)89 return 1;1011 &#125;12 int foo(int n)13 &#123;14 int result=0;15 for (int i=0;i&lt;=n;i++)16 &#123;17 result+=n; 123456789//设置断点(gdb) b 17Breakpoint 1 at 0x400c07: file example_1.cpp, line 17.(gdb) b mainBreakpoint 2 at 0x400c27: file example_1.cpp, line 26.(gdb) info brNum Type Disp Enb Address What1 breakpoint keep y 0x0000000000400c07 in foo(int) at example_1.cpp:172 breakpoint keep y 0x0000000000400c27 in main at example_1.cpp:26 1.6、执行控制命令 12345678910111213(gdb) rStarting program: /home/work/testers/sgc/study/example_1Breakpoint 2, main () at example_1.cpp:2626 string s1=\"dafdf\";(gdb) cContinuing.result[1-100]=5050Breakpoint 1, foo (n=250) at example_1.cpp:1717 result+=n;(gdb) n15 for (int i=0;i&lt;=n;i++) 1.7、程序信息查看命令 123456789101112131415161718192021222324252627282930313233//查看变量信息(gdb) p result$1 = 250(gdb) p s1$2 = 1431655765 (gdb) disp result1: result = 250(gdb) cContinuing.Breakpoint 1, foo (n=250) at example_1.cpp:1717 result+=n;1: result = 250(gdb) info localsi = 1result = 250//查看栈信息(gdb) bt#0 foo (n=250) at example_1.cpp:17#1 0x0000000000400cc1 in main () at example_1.cpp:38(gdb) info fStack level 0, frame at 0x7fbffff8a0: rip = 0x400c07 in foo(int) (example_1.cpp:17); saved rip 0x400cc1 called by frame at 0x7fbffff910 source language c++. Arglist at 0x7fbffff890, args: n=250 Locals at 0x7fbffff890, Previous frame's sp is 0x7fbffff8a0 Saved registers: rbp at 0x7fbffff890, rip at 0x7fbffff898(gdb) f 0#0 foo (n=250) at example_1.cpp:1717 result+=n; 1.8、修改环境命令 1234567891011121314(gdb) set var i=97(gdb) p i$5 = 97(gdb) print i=98$6 = 98(gdb) ignore 1 300Will ignore next 300 crossings of breakpoint 1.(gdb) finishRun till exit from #0 foo (n=250) at example_1.cpp:170x0000000000400cc1 in main () at example_1.cpp:3838 cout&lt;&lt;\"result[1-250]=\"&lt;&lt;foo(250)&lt;&lt;endl;Value returned is $8 = 38500(gdb) quitThe program is running. Exit anyway? (y or n) y 不要放过core文件 问 ：Core文件是什么？答 ：a disk file containing an image of the process’s memory at the time of termination 问 ：Core的作用？答 ：&nbsp;&nbsp;&nbsp;&nbsp;1、让你在调试时，不用花费大量等待程序出错；&nbsp;&nbsp;&nbsp;&nbsp;2、让你避免了单步调试的烦恼&nbsp;&nbsp;&nbsp;&nbsp;3、让你定位错误所在 启动方式1$ gdb &lt;program&gt; core 查看程序信息的常用命令1、查看栈信息：bt, f n, up/down，info frame2、查看变量信息：info args|locals 实战2 : core文件调试2.1、示例程序(crash2.c) 123456789101112#include &lt;string.h&gt;void Strcpy(char *to , char *from)&#123; strcpy(to , from);&#125;int main()&#123; char *s = NULL; Strcpy(s, \"abcdefg\"); return 0;&#125; 2.2、查看信息 123456789101112131415161718192021222324252627282930$ gdb ./crash2 core.19562GNU gdb Red Hat Linux (6.3.0.0-1.96rh)Copyright 2004 Free Software Foundation, Inc.GDB is free software, covered by the GNU General Public License, and you arewelcome to change it and/or distribute copies of it under certain conditions.Type \"show copying\" to see the conditions.There is absolutely no warranty for GDB. Type \"show warranty\" for details.This GDB was configured as \"x86_64-redhat-linux-gnu\"...Using host libthread_db library \"/lib64/tls/libthread_db.so.1\".Core was generated by `./crash2'.Program terminated with signal 11, Segmentation fault.Reading symbols from /lib64/tls/libc.so.6...done.Loaded symbols for /lib64/tls/libc.so.6Reading symbols from /lib64/ld-linux-x86-64.so.2...done.Loaded symbols for /lib64/ld-linux-x86-64.so.2#0 0x000000302af6f9a4 in strcpy () from /lib64/tls/libc.so.6(gdb) bt#0 0x000000302af6f9a4 in strcpy () from /lib64/tls/libc.so.6#1 0x00000000004004c5 in Strcpy (to=0x0, from=0x4005dc \"abcdefg\") at crash2.c:5#2 0x00000000004004e5 in main () at crash2.c:10(gdb) f 0#0 0x000000302af6f9a4 in strcpy () from /lib64/tls/libc.so.6(gdb) up#1 0x00000000004004c5 in Strcpy (to=0x0, from=0x4005dc \"abcdefg\") at crash2.c:55 strcpy(to , from);(gdb) info argsto = 0x0from = 0x4005dc \"abcdefg\"//至此，已经清楚的发现了问题所在，to指针为空 进阶之多线程程序调试多线程调试常用命令123456$ info &lt;...&gt; // 强大的查看命令，如info threads$ attach/detach &lt;pid&gt; // 挂载到进程$ thread &lt;thread_no&gt; // 切换到线程$ thread apply &lt;thread_no_list&gt; &lt;cmd&gt; // 对于list中的thread，执行cmd$ break &lt;linenum&gt; thread &lt;threadno&gt; if ... 实战3 : 多线程程序调试3.1、正常的示例程序(good_thread.c) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/time.h&gt;#include &lt;string.h&gt;#define MAX 10pthread_t thread[2];pthread_mutex_t mut;int number=0, i;void *thread1()&#123; printf (\"thread1 : I'm thread 1\\n\"); for (i = 0; i &lt; MAX; i++) &#123; printf(\"thread1 : number = %d\\n\",number); pthread_mutex_lock(&amp;mut); number++; pthread_mutex_unlock(&amp;mut); sleep(2); &#125; printf(\"thread1 :主函数在等我完成任务吗？\\n\"); pthread_exit(NULL);&#125;void *thread2()&#123; printf(\"thread2 : I'm thread 2\\n\"); for (i = 0; i &lt; MAX; i++) &#123; printf(\"thread2 : number = %d\\n\",number); pthread_mutex_lock(&amp;mut); number++; pthread_mutex_unlock(&amp;mut); sleep(3); &#125; printf(\"thread2 :主函数在等我完成任务吗？\\n\"); pthread_exit(NULL);&#125;void thread_create(void)&#123; int temp; memset(&amp;thread, 0, sizeof(thread)); //comment1 /*创建线程*/ if((temp = pthread_create(&amp;thread[0], NULL, thread1, NULL)) != 0) //comment2 printf(\"线程1创建失败!\\n\"); else printf(\"线程1被创建\\n\"); if((temp = pthread_create(&amp;thread[1], NULL, thread2, NULL)) != 0) //comment3 printf(\"线程2创建失败\"); else printf(\"线程2被创建\\n\");&#125;void thread_wait(void)&#123; /*等待线程结束*/ if(thread[0] !=0) &#123; //comment4 pthread_join(thread[0],NULL); printf(\"线程1已经结束\\n\"); &#125; if(thread[1] !=0) &#123; //comment5 pthread_join(thread[1],NULL); printf(\"线程2已经结束\\n\"); &#125;&#125;int main()&#123; /*用默认属性初始化互斥锁*/ pthread_mutex_init(&amp;mut,NULL); printf(\"我是主函数哦，我正在创建线程，呵呵\\n\"); thread_create(); printf(\"我是主函数哦，我正在等待线程完成任务阿，呵呵\\n\"); thread_wait(); return 0;&#125; 3.2、演示过程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354(gdb)21 printf (\"thread1 : I'm thread 1\\n\");2223 for (i = 0; i &lt; MAX; i++)2425 &#123;2627 printf(\"thread1 : number = %d\\n\",number);2829 pthread_mutex_lock(&amp;mut);(gdb) b 27Breakpoint 1 at 0x40079e: file good_thread.c, line 27.(gdb)51 for (i = 0; i &lt; MAX; i++)5253 &#123;5455 printf(\"thread2 : number = %d\\n\",number);5657 pthread_mutex_lock(&amp;mut);5859 number++;(gdb) b 57Breakpoint 2 at 0x400838: file good_thread.c, line 57.(gdb) rStarting program: /home/work/testers/sgc/study/goodthread[Thread debugging using libthread_db enabled][New Thread 182894112416 (LWP 22783)]ÎÒÊÇÖ÷º¯ÊýÅ¶£¬ÎÒÕýÔÚ´´½¨Ïß³Ì£¬ºÇºÇ[New Thread 1084229984 (LWP 22786)]Ïß³Ì1±»´´½¨thread1 : I'm thread 1[Switching to Thread 1084229984 (LWP 22786)]Breakpoint 1, thread1 () at good_thread.c:2727 printf(\"thread1 : number = %d\\n\",number);(gdb) bt#0 thread1 () at good_thread.c:27#1 0x000000302b80610a in start_thread () from /lib64/tls/libpthread.so.0#2 0x000000302afc6003 in clone () from /lib64/tls/libc.so.6#3 0x0000000000000000 in ?? ()(gdb) info threads[New Thread 1094719840 (LWP 22787)] 3 Thread 1094719840 (LWP 22787) 0x000000302afc5fc4 in clone () from /lib64/tls/libc.so.6* 2 Thread 1084229984 (LWP 22786) thread1 () at good_thread.c:27 1 Thread 182894112416 (LWP 22783) 0x000000302afc5fc4 in clone () from /lib64/tls/libc.so.6(gdb) thread 1[Switching to thread 1 (Thread 182894112416 (LWP 22783))]#0 0x000000302afc5fc4 in clone () from /lib64/tls/libc.so.6(gdb) bt#0 0x000000302afc5fc4 in clone () from /lib64/tls/libc.so.6#1 0x000000302b805d86 in do_clone () from /lib64/tls/libpthread.so.0#2 0x000000302b806846 in pthread_create@@GLIBC_2.2.5 () from /lib64/tls/libpthread.so.0#3 0x00000000004008fd in thread_create () at good_thread.c:91#4 0x00000000004009a9 in main () at good_thread.c:135 3.3、死锁示例程序（multi_thread.c） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#define THREAD_NUM 20pthread_mutex_t AccountA_mutex;pthread_mutex_t AccountB_mutex;struct Account &#123; char account_name[1]; int balance;&#125;;struct Account accountA = &#123;'A', 100000&#125;;struct Account accountB = &#123;'B', 200000&#125;;void * accountAB (void* amount_ptr) &#123; int amount = *((int*)amount_ptr); pthread_mutex_lock(&amp;AccountA_mutex); if (accountA.balance &lt; amount) &#123; printf(\"There is not enough memory in Account A!\\n\"); pthread_mutex_unlock(&amp;AccountA_mutex); pthread_exit((void *)1); &#125; accountA.balance -=amount; sleep(2); pthread_mutex_lock(&amp;AccountB_mutex); accountB.balance +=amount; pthread_mutex_unlock(&amp;AccountA_mutex); pthread_mutex_unlock(&amp;AccountB_mutex);&#125;void * accountBA (void* amount_ptr) &#123; int amount = *((int*)amount_ptr); pthread_mutex_lock(&amp;AccountB_mutex); if (accountB.balance &lt; amount) &#123; printf(\"There is not enough memory in Account B!\\n\"); pthread_mutex_unlock(&amp;AccountB_mutex); pthread_exit((void *)1); &#125; accountB.balance -=amount; pthread_mutex_lock(&amp;AccountA_mutex); accountA.balance +=amount; pthread_mutex_unlock(&amp;AccountB_mutex); pthread_mutex_unlock(&amp;AccountA_mutex);&#125;int main(int argc, char* argv[]) &#123; int threadid[THREAD_NUM]; pthread_t pthread[THREAD_NUM]; void* thResState; int res, flag; int transfer_amount[THREAD_NUM] = &#123;100, 200, 300, 400,100,200,300,400,500,600,700,800,900,800,700,600,500,400,300,200&#125;; pthread_attr_t attr; pthread_attr_init(&amp;attr); pthread_attr_setscope(&amp;attr, PTHREAD_SCOPE_SYSTEM); for(flag=0; flag&lt;THREAD_NUM; flag++)&#123; if(flag%2 == 0)&#123; if (threadid[flag] = pthread_create(&amp;pthread[flag], &amp;attr , accountAB, \\ (void*)&amp;transfer_amount[flag]) &lt; 0)&#123; printf(\"Thread %d creation failed\\n\", flag); exit (1); &#125; &#125; else&#123; if (threadid[flag] = pthread_create(&amp;pthread[flag], &amp;attr , accountBA, \\ (void*)&amp;transfer_amount[flag]) &lt; 0) &#123; printf(\"Thread %d creation failed\\n\", flag); exit (1); &#125; &#125; &#125; for(flag=0; flag&lt;THREAD_NUM; flag++)&#123; res = pthread_join(pthread[flag], &amp;thResState); if (res != 0)&#123; perror(\"Thread join failed\"); exit(-1); &#125; printf(\"thread success id %u state code %d\\n\",threadid[flag],thResState); &#125; printf(\"Transitions are in progress..\"); printf(\"\\nAll the money is transferred !!\\n\");&#125; 3.4、错误定位 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240$ gcc -g -o multi_thread multi_thread.c –lpthread$ ./multi_thread$ ps -eLF |grep multiwork 21675 19997 21675 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21676 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21677 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21678 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21679 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21680 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21681 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21682 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21683 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21684 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21685 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21686 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21687 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21688 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21689 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21690 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21691 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21692 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21693 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21694 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_threadwork 21675 19997 21695 0 21 52124 464 0 00:25 pts/8 00:00:00 ./multi_thread$ gdbGNU gdb Red Hat Linux (6.3.0.0-1.96rh)Copyright 2004 Free Software Foundation, Inc.GDB is free software, covered by the GNU General Public License, and you arewelcome to change it and/or distribute copies of it under certain conditions.Type \"show copying\" to see the conditions.There is absolutely no warranty for GDB. Type \"show warranty\" for details.This GDB was configured as \"x86_64-redhat-linux-gnu\".(gdb) attach 21680Attaching to process 21680Reading symbols from /home/work/testers/sgc/study/multi_thread...done.Using host libthread_db library \"/lib64/tls/libthread_db.so.1\".Reading symbols from /lib64/tls/libpthread.so.0...done.[Thread debugging using libthread_db enabled][New Thread 182894112416 (LWP 21675)][New Thread 1283537248 (LWP 21695)][New Thread 1273047392 (LWP 21694)][New Thread 1262557536 (LWP 21693)][New Thread 1252067680 (LWP 21692)][New Thread 1241577824 (LWP 21691)][New Thread 1231087968 (LWP 21690)][New Thread 1220598112 (LWP 21689)][New Thread 1210108256 (LWP 21688)][New Thread 1199618400 (LWP 21687)][New Thread 1189128544 (LWP 21686)][New Thread 1178638688 (LWP 21685)][New Thread 1168148832 (LWP 21684)][New Thread 1157658976 (LWP 21683)][New Thread 1147169120 (LWP 21682)][New Thread 1136679264 (LWP 21681)][New Thread 1126189408 (LWP 21680)][New Thread 1115699552 (LWP 21679)][New Thread 1105209696 (LWP 21678)][New Thread 1094719840 (LWP 21677)][New Thread 1084229984 (LWP 21676)]Loaded symbols for /lib64/tls/libpthread.so.0Reading symbols from /lib64/tls/libc.so.6...done.Loaded symbols for /lib64/tls/libc.so.6Reading symbols from /lib64/ld-linux-x86-64.so.2...done.Loaded symbols for /lib64/ld-linux-x86-64.so.20x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0(gdb) bt#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x00000000432041e0 in ?? ()#2 0x00000000432049f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()(gdb) info threads 21 Thread 1084229984 (LWP 21676) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 20 Thread 1094719840 (LWP 21677) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 19 Thread 1105209696 (LWP 21678) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 18 Thread 1115699552 (LWP 21679) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 17 Thread 1126189408 (LWP 21680) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 16 Thread 1136679264 (LWP 21681) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 15 Thread 1147169120 (LWP 21682) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 14 Thread 1157658976 (LWP 21683) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 13 Thread 1168148832 (LWP 21684) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 12 Thread 1178638688 (LWP 21685) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 11 Thread 1189128544 (LWP 21686) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 10 Thread 1199618400 (LWP 21687) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 9 Thread 1210108256 (LWP 21688) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 8 Thread 1220598112 (LWP 21689) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 7 Thread 1231087968 (LWP 21690) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 6 Thread 1241577824 (LWP 21691) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 5 Thread 1252067680 (LWP 21692) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 4 Thread 1262557536 (LWP 21693) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 3 Thread 1273047392 (LWP 21694) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 2 Thread 1283537248 (LWP 21695) 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0 1 Thread 182894112416 (LWP 21675) 0x000000302b806ffb in pthread_join () from /lib64/tls/libpthread.so.0(gdb) thread apply all btThread 21 (Thread 1084229984 (LWP 21676)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x0000000000000000 in ?? ()Thread 20 (Thread 1094719840 (LWP 21677)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x00000000414011e0 in ?? ()#2 0x00000000414019f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 19 (Thread 1105209696 (LWP 21678)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x0000000041e021e0 in ?? ()#2 0x0000000041e029f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 18 (Thread 1115699552 (LWP 21679)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x00000000428031e0 in ?? ()#2 0x00000000428039f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 17 (Thread 1126189408 (LWP 21680)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x00000000432041e0 in ?? ()#2 0x00000000432049f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 16 (Thread 1136679264 (LWP 21681)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x0000000043c051e0 in ?? ()#2 0x0000000043c059f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 15 (Thread 1147169120 (LWP 21682)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x00000000446061e0 in ?? ()#2 0x00000000446069f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---Thread 14 (Thread 1157658976 (LWP 21683)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x00000000450071e0 in ?? ()#2 0x00000000450079f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 13 (Thread 1168148832 (LWP 21684)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x0000000045a081e0 in ?? ()#2 0x0000000045a089f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 12 (Thread 1178638688 (LWP 21685)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x00000000464091e0 in ?? ()#2 0x00000000464099f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 11 (Thread 1189128544 (LWP 21686)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x0000000046e0a1e0 in ?? ()#2 0x0000000046e0a9f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 10 (Thread 1199618400 (LWP 21687)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x000000004780b1e0 in ?? ()#2 0x000000004780b9f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 9 (Thread 1210108256 (LWP 21688)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x000000004820c1e0 in ?? ()#2 0x000000004820c9f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 8 (Thread 1220598112 (LWP 21689)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x0000000048c0d1e0 in ?? ()---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---#2 0x0000000048c0d9f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 7 (Thread 1231087968 (LWP 21690)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x000000004960e1e0 in ?? ()#2 0x000000004960e9f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 6 (Thread 1241577824 (LWP 21691)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x000000004a00f1e0 in ?? ()#2 0x000000004a00f9f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 5 (Thread 1252067680 (LWP 21692)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x000000004aa101e0 in ?? ()#2 0x000000004aa109f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 4 (Thread 1262557536 (LWP 21693)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x000000004b4111e0 in ?? ()#2 0x000000004b4119f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 3 (Thread 1273047392 (LWP 21694)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x000000004be121e0 in ?? ()#2 0x000000004be129f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()Thread 2 (Thread 1283537248 (LWP 21695)):#0 0x000000302b80adfb in __lll_mutex_lock_wait () from /lib64/tls/libpthread.so.0#1 0x000000004c8131e0 in ?? ()#2 0x000000004c8139f0 in ?? ()#3 0x000000302b807bd4 in pthread_mutex_lock () from /lib64/tls/libpthread.so.0#4 0x0000000000000000 in ?? ()---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---Thread 1 (Thread 182894112416 (LWP 21675)):#0 0x000000302b806ffb in pthread_join () from /lib64/tls/libpthread.so.0#1 0x0000000000400b69 in main (argc=1, argv=0x7fbffffa08) at multi_thread.c:76 总结GDB是一个好用的抓虫工具，随意控制进程，随便查看内存和环境；上述只是新手学习过程中的一些记录，欢迎深入探讨。","tags":[{"name":"GDB","slug":"GDB","permalink":"https://www.shengguocun.com/tags/GDB/"}]},{"title":"Hello World","date":"2018-01-12T06:29:51.000Z","path":"/blog/2018/01/12/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]